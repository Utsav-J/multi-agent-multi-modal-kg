{"nodes": [{"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, {"id": "Waleed Razzaq", "type": "Person"}, {"id": "Izis Kankaraway", "type": "Person"}, {"id": "Yun-Bo Zhao", "type": "Person"}, {"id": "Attention", "type": "Concept"}, {"id": "Representation Learning", "type": "Concept"}, {"id": "RNNs", "type": "Model"}, {"id": "Continuous-time (CT) modeling", "type": "Concept"}, {"id": "Biologically Plausible CT-Attention Mechanism", "type": "Concept"}, {"id": "Attention Logits Computation", "type": "Concept"}, {"id": "Linear First-Order ODE", "type": "Mathematical Model"}, {"id": "Nonlinear Interlinked Gates", "type": "Component"}, {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, {"id": "Sparse Sensory Gates", "type": "Component"}, {"id": "Sparse Backbone Network", "type": "Component"}, {"id": "Content-Target Gate", "type": "Component"}, {"id": "Learnable Time-Constant Gate", "type": "Component"}, {"id": "Explicit Euler Integration", "type": "Algorithm"}, {"id": "Exact Closed-Form Solution", "type": "Concept"}, {"id": "Steady-State Approximation", "type": "Concept"}, {"id": "Sparse Top-K Pairwise Concatenation Scheme", "type": "Algorithm"}, {"id": "Irregular Time-Series Classification", "type": "Task"}, {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, {"id": "Industrial Prognostics", "type": "Task"}, {"id": "CT Baselines", "type": "Model"}, {"id": "Department of Automation, University of Science & Technology of China", "type": "Organization"}, {"id": "University of Science & Technology of China", "type": "Organization"}, {"id": "Hefei", "type": "Location"}, {"id": "Institute of Artificial Intelligence, Hefei Comprehensive National Science Center", "type": "Organization"}, {"id": "Hefei Comprehensive National Science Center", "type": "Organization"}, {"id": "Sequential Data", "type": "Concept"}, {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, {"id": "RNN", "type": "Model"}, {"id": "Rumelhart et al., 1985", "type": "Publication"}, {"id": "Jordan, 1997", "type": "Publication"}, {"id": "Long-short term memory (LSTM)", "type": "Model"}, {"id": "Hochreiter & Schmidhuber, 1997", "type": "Publication"}, {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, {"id": "Cho et al., 2014", "type": "Publication"}, {"id": "Irregularly Sampled Data", "type": "Concept"}, {"id": "Vanishing Gradients", "type": "Concept"}, {"id": "Continuous-time RNNs (CT-RNNs)", "type": "Model"}, {"id": "Rubanova et al., 2019", "type": "Publication"}, {"id": "Ordinary Differential Equations (ODEs)", "type": "Mathematical Model"}, {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Model"}, {"id": "Lechner & Hasani, 2022", "type": "Publication"}, {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, {"id": "Hasani et al., 2021", "type": "Publication"}, {"id": "Hasani et al., 2022", "type": "Publication"}, {"id": "Attention Mechanisms", "type": "Concept"}, {"id": "Vaswani et al., 2017", "type": "Publication"}, {"id": "Multi-Head Attention (MHA)", "type": "Model"}, {"id": "Sparse Attention", "type": "Model"}, {"id": "Tay et al., 2020", "type": "Publication"}, {"id": "Roy et al., 2021", "type": "Publication"}, {"id": "BigBird", "type": "Model"}, {"id": "Zaheer et al., 2020", "type": "Publication"}, {"id": "Longformer", "type": "Model"}, {"id": "Beltagy et al., 2020", "type": "Publication"}, {"id": "NeuralODE", "type": "Model"}, {"id": "Chen et al., 2018", "type": "Publication"}, {"id": "mTAN", "type": "Model"}, {"id": "Shukla & Marlin, 2021", "type": "Publication"}, {"id": "Time-Based Attention", "type": "Concept"}, {"id": "ODEFormer", "type": "Model"}, {"id": "d\u2019Ascoli et al., 2023", "type": "Publication"}, {"id": "Continuous-time Attention (CTA)", "type": "Model"}, {"id": "Chien & Chen, 2021", "type": "Publication"}, {"id": "ContiFormer", "type": "Model"}, {"id": "Chen et al., 2023", "type": "Publication"}, {"id": "CT-transformer", "type": "Model"}, {"id": "Nervous System of C. elegans", "type": "Organism Part"}, {"id": "C. elegans", "type": "Organism"}, {"id": "Standard Attention", "type": "Concept"}, {"id": "Attention Logits", "type": "Concept"}, {"id": "Biologically Inspired Approach", "type": "Concept"}, {"id": "Biological Nervous Systems", "type": "Concept"}, {"id": "Synaptic Transmission", "type": "Concept"}, {"id": "Explicit Euler Solver", "type": "Algorithm"}, {"id": "Runge-Kutta", "type": "Algorithm"}, {"id": "Learnable Time-Constant Gate Head", "type": "Component"}, {"id": "Nonlinear Content-Target Head", "type": "Component"}, {"id": "Backbone Network", "type": "Component"}, {"id": "Theorem 1", "type": "Theorem"}, {"id": "State Stability", "type": "Concept"}, {"id": "Boundedness of Attention Logit State Trajectory", "type": "Concept"}, {"id": "Corollary 1", "type": "Corollary"}, {"id": "Exponential Decay Bound", "type": "Concept"}, {"id": "Corollary 2", "type": "Corollary"}, {"id": "Uniform Initialization Bound", "type": "Concept"}, {"id": "Corollary 3", "type": "Corollary"}, {"id": "Sample Complexity to \u03b4-accuracy", "type": "Concept"}, {"id": "Repurposed NCPCell", "type": "Algorithm"}], "relationships": [{"source": {"id": "Waleed Razzaq", "type": "Person"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "AUTHORED"}, {"source": {"id": "Izis Kankaraway", "type": "Person"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "AUTHORED"}, {"source": {"id": "Yun-Bo Zhao", "type": "Person"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "AUTHORED"}, {"source": {"id": "Attention", "type": "Concept"}, "target": {"id": "Representation Learning", "type": "Concept"}, "type": "IMPROVES"}, {"source": {"id": "Attention", "type": "Concept"}, "target": {"id": "Continuous-time (CT) modeling", "type": "Concept"}, "type": "LIMITS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Biologically Plausible CT-Attention Mechanism", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Attention Logits Computation", "type": "Concept"}, "type": "REFORMULATES"}, {"source": {"id": "Attention Logits Computation", "type": "Concept"}, "target": {"id": "Linear First-Order ODE", "type": "Mathematical Model"}, "type": "IS_SOLUTION_TO"}, {"source": {"id": "Linear First-Order ODE", "type": "Mathematical Model"}, "target": {"id": "Nonlinear Interlinked Gates", "type": "Component"}, "type": "WITH"}, {"source": {"id": "Nonlinear Interlinked Gates", "type": "Component"}, "target": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "type": "DERIVED_FROM"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Sparse Sensory Gates", "type": "Component"}, "type": "REPLACES_PROJECTIONS_WITH"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Sparse Backbone Network", "type": "Component"}, "type": "USES"}, {"source": {"id": "Sparse Backbone Network", "type": "Component"}, "target": {"id": "Content-Target Gate", "type": "Component"}, "type": "COMPUTES"}, {"source": {"id": "Sparse Backbone Network", "type": "Component"}, "target": {"id": "Learnable Time-Constant Gate", "type": "Component"}, "type": "COMPUTES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Explicit Euler Integration", "type": "Algorithm"}, "type": "SUPPORTS_MODE"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Exact Closed-Form Solution", "type": "Concept"}, "type": "SUPPORTS_MODE"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Steady-State Approximation", "type": "Concept"}, "type": "SUPPORTS_MODE"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Sparse Top-K Pairwise Concatenation Scheme", "type": "Algorithm"}, "type": "IMPLEMENTS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Irregular Time-Series Classification", "type": "Task"}, "type": "APPLIED_IN"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "type": "APPLIED_IN"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Industrial Prognostics", "type": "Task"}, "type": "APPLIED_IN"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "CT Baselines", "type": "Model"}, "type": "COMPARED_WITH"}, {"source": {"id": "Waleed Razzaq", "type": "Person"}, "target": {"id": "Department of Automation, University of Science & Technology of China", "type": "Organization"}, "type": "AFFILIATED_WITH"}, {"source": {"id": "Izis Kankaraway", "type": "Person"}, "target": {"id": "Department of Automation, University of Science & Technology of China", "type": "Organization"}, "type": "AFFILIATED_WITH"}, {"source": {"id": "Yun-Bo Zhao", "type": "Person"}, "target": {"id": "Department of Automation, University of Science & Technology of China", "type": "Organization"}, "type": "AFFILIATED_WITH"}, {"source": {"id": "Yun-Bo Zhao", "type": "Person"}, "target": {"id": "Institute of Artificial Intelligence, Hefei Comprehensive National Science Center", "type": "Organization"}, "type": "AFFILIATED_WITH"}, {"source": {"id": "Department of Automation, University of Science & Technology of China", "type": "Organization"}, "target": {"id": "University of Science & Technology of China", "type": "Organization"}, "type": "PART_OF"}, {"source": {"id": "University of Science & Technology of China", "type": "Organization"}, "target": {"id": "Hefei", "type": "Location"}, "type": "LOCATED_AT"}, {"source": {"id": "Institute of Artificial Intelligence, Hefei Comprehensive National Science Center", "type": "Organization"}, "target": {"id": "Hefei Comprehensive National Science Center", "type": "Organization"}, "type": "PART_OF"}, {"source": {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, "target": {"id": "RNN", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, "target": {"id": "Long-short term memory (LSTM)", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, "target": {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "Rumelhart et al., 1985", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "Jordan, 1997", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Long-short term memory (LSTM)", "type": "Model"}, "target": {"id": "Hochreiter & Schmidhuber, 1997", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, "target": {"id": "Cho et al., 2014", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, "target": {"id": "Irregularly Sampled Data", "type": "Concept"}, "type": "FACE_CHALLENGES"}, {"source": {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, "target": {"id": "Vanishing Gradients", "type": "Concept"}, "type": "FACE_CHALLENGES"}, {"source": {"id": "Continuous-time RNNs (CT-RNNs)", "type": "Model"}, "target": {"id": "Ordinary Differential Equations (ODEs)", "type": "Mathematical Model"}, "type": "MODEL_HIDDEN_STATES_AS"}, {"source": {"id": "Continuous-time RNNs (CT-RNNs)", "type": "Model"}, "target": {"id": "Rubanova et al., 2019", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Model"}, "target": {"id": "Continuous-time RNNs (CT-RNNs)", "type": "Model"}, "type": "BUILDS_ON"}, {"source": {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Model"}, "target": {"id": "Lechner & Hasani, 2022", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, "target": {"id": "Biologically Inspired Approach", "type": "Concept"}, "type": "TAKE_APPROACH"}, {"source": {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, "target": {"id": "Hasani et al., 2021", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, "target": {"id": "Hasani et al., 2022", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "Vanishing Gradients", "type": "Concept"}, "type": "MITIGATES"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "Vaswani et al., 2017", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Multi-Head Attention (MHA)", "type": "Model"}, "target": {"id": "Attention Mechanisms", "type": "Concept"}, "type": "EXTENDS"}, {"source": {"id": "Multi-Head Attention (MHA)", "type": "Model"}, "target": {"id": "Vaswani et al., 2017", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Sparse Attention", "type": "Model"}, "target": {"id": "Attention Pattern", "type": "Concept"}, "type": "MODIFIES"}, {"source": {"id": "Sparse Attention", "type": "Model"}, "target": {"id": "Tay et al., 2020", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Sparse Attention", "type": "Model"}, "target": {"id": "Roy et al., 2021", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "BigBird", "type": "Model"}, "target": {"id": "Sparse Attention", "type": "Model"}, "type": "IS_A_VARIANT_OF"}, {"source": {"id": "BigBird", "type": "Model"}, "target": {"id": "Zaheer et al., 2020", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Longformer", "type": "Model"}, "target": {"id": "Sparse Attention", "type": "Model"}, "type": "IS_A_VARIANT_OF"}, {"source": {"id": "Longformer", "type": "Model"}, "target": {"id": "Beltagy et al., 2020", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "NeuralODE", "type": "Model"}, "target": {"id": "Chen et al., 2018", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "CT Embeddings", "type": "Concept"}, "type": "LEARNS"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "Time-Based Attention", "type": "Concept"}, "type": "USES"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "Shukla & Marlin, 2021", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "ODEFormer", "type": "Model"}, "target": {"id": "Symbolic ODE Systems", "type": "Mathematical Model"}, "type": "INFERS"}, {"source": {"id": "ODEFormer", "type": "Model"}, "target": {"id": "d\u2019Ascoli et al., 2023", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Continuous-time Attention (CTA)", "type": "Model"}, "target": {"id": "CT Attention Mechanism", "type": "Concept"}, "type": "EMBEDS"}, {"source": {"id": "Continuous-time Attention (CTA)", "type": "Model"}, "target": {"id": "NeuralODE", "type": "Model"}, "type": "EMBEDS_WITHIN"}, {"source": {"id": "Continuous-time Attention (CTA)", "type": "Model"}, "target": {"id": "Chien & Chen, 2021", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "CT-transformer", "type": "Model"}, "type": "BUILDS"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Chen et al., 2023", "type": "Publication"}, "type": "INTRODUCED_BY"}, {"source": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "target": {"id": "Nervous System of C. elegans", "type": "Organism Part"}, "type": "FROM"}, {"source": {"id": "C. elegans", "type": "Organism"}, "target": {"id": "Nervous System of C. elegans", "type": "Organism Part"}, "type": "HAS_PART"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, "type": "MOTIVATED_BY"}, {"source": {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, "target": {"id": "Biological Nervous Systems", "type": "Concept"}, "type": "INSPIRED_BY"}, {"source": {"id": "Liquid Neural Networks (LNNs)", "type": "Model"}, "target": {"id": "Synaptic Transmission", "type": "Concept"}, "type": "INSPIRED_BY"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Explicit Euler Solver", "type": "Algorithm"}, "type": "USES"}, {"source": {"id": "Explicit Euler Solver", "type": "Algorithm"}, "target": {"id": "Numerical ODE Solver", "type": "Algorithm"}, "type": "IS_A"}, {"source": {"id": "Runge-Kutta", "type": "Algorithm"}, "target": {"id": "Higher Accuracy", "type": "Concept"}, "type": "OFFERS"}, {"source": {"id": "Runge-Kutta", "type": "Algorithm"}, "target": {"id": "Computational Overhead", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Learnable Time-Constant Gate Head", "type": "Component"}, "target": {"id": "Backbone Network", "type": "Component"}, "type": "PARAMETERIZED_BY"}, {"source": {"id": "Nonlinear Content-Target Head", "type": "Component"}, "target": {"id": "Backbone Network", "type": "Component"}, "type": "PARAMETERIZED_BY"}, {"source": {"id": "Theorem 1", "type": "Theorem"}, "target": {"id": "State Stability", "type": "Concept"}, "type": "ANALYZES"}, {"source": {"id": "Theorem 1", "type": "Theorem"}, "target": {"id": "Boundedness of Attention Logit State Trajectory", "type": "Concept"}, "type": "ESTABLISHES"}, {"source": {"id": "Corollary 1", "type": "Corollary"}, "target": {"id": "Exponential Decay Bound", "type": "Concept"}, "type": "DESCRIBES"}, {"source": {"id": "Corollary 2", "type": "Corollary"}, "target": {"id": "Uniform Initialization Bound", "type": "Concept"}, "type": "DESCRIBES"}, {"source": {"id": "Corollary 3", "type": "Corollary"}, "target": {"id": "Sample Complexity to \u03b4-accuracy", "type": "Concept"}, "type": "DESCRIBES"}], "source": {"page_content": "Neuronal Attention Circuit (NAC) for Representation Learning\n\nWaleed Razzaq [1] Izis Kankaraway [1] Yun-Bo Zhao [1 2]\n\n\n\nAbstract\n\nAttention improves representation learning over\nRNNs, but its discrete nature limits continuoustime (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates\n\nattention logits computation as the solution to a\nlinear first-order ODE with nonlinear interlinked\ngates derived from repurposing _C. elegans_ Neuronal Circuit Policies (NCPs) wiring mechanism.\nNAC replaces dense projections with sparse sensory gates for key-query projections and a sparse\nbackbone network with two heads for computing\n_content-target_ and _learnable time-constant_ gates,\nenabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i)\nexplicit Euler integration, (ii) exact closed-form\nsolution, and (iii) steady-state approximation. To\nimprove memory intensity, we implemented a\nsparse Top- _K_ pairwise concatenation scheme that\nselectively curates key-query interactions. We\nprovide rigorous theoretical guarantees, including\nstate stability, bounded approximation errors, and\nuniversal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for\nautonomous vehicles, and industrial prognostics.\nzWe observed that NAC matches or outperforms\ncompeting baselines in accuracy and occupies an\nintermediate position in runtime and memory efficiency compared with several CT baselines.\n\n\n1. Introduction\n\n\nLearning representations of sequential data in temporal or\nspatio-temporal domains is essential for capturing patterns\nand enabling accurate forecasting. Discrete-time Recurrent neural networks (DT-RNNs) such as RNN (Rumelhart et al., 1985; Jordan, 1997), Long-short term memory\n\n\n1Department of Automation, University of Science & Technology of China, Hefei, China [2] Institute of Artificial Intelligence,\nHefei Comprehensive National Science Center. Correspondence to:\nYun-Bo Zhao _<_ ybzhao@ustc.edu.cn _>_, Waleed Razzaq _<_ waleedrazzaq@mail.ustc.edu.cn _>_ .\n\n\n_Preprint. December 12, 2025._\n\n\n\n(LSTM) (Hochreiter & Schmidhuber, 1997), and Gated Recurrent Unit (GRU) (Cho et al., 2014) model sequential dependencies by iteratively updating hidden states to represent\nor predict future elements in a sequence. While effective\nfor regularly sampled sequences, DT-RNNs face challenges\nwith irregularly sampled data because they assume uniform\ntime intervals. In addition, vanishing gradients can make\nit difficult to capture long-term dependencies (Hochreiter,\n1998).\nContinuous-time RNNs (CT-RNNs) (Rubanova et al., 2019)\nmodel hidden states as ordinary differential equations\n(ODEs), allowing them to process inputs that arrive at arbitrary or irregular time intervals. Mixed-memory RNNs\n(mmRNNs) (Lechner & Hasani, 2022) build on this idea\nby separating memory compartments from time-continuous\nstates, helping maintain stable error propagation while capturing continuous-time dynamics. Liquid neural networks\n(LNNs) (Hasani et al., 2021; 2022) take a biologically inspired approach by assigning variable time-constants to hidden states, improving adaptability and robustness, though\nvanishing gradients can still pose challenges during training.\nThe attention mechanisms (Vaswani et al., 2017) mitigate\nthis limitation by treating all time steps equally and allowing models to focus on the most relevant observations. It\ncomputes the similarity between queries ( _q_ ) and keys ( _k_ ),\nscaling by the key dimension to keep gradients stable. MultiHead Attention (MHA) (Vaswani et al., 2017) extends this\nby allowing the model to attend to different representation\nsubspaces in parallel. Variants like Sparse Attention (Tay\net al., 2020; Roy et al., 2021), BigBird (Zaheer et al., 2020),\nand Longformer (Beltagy et al., 2020) modify the attention\npattern to reduce computational cost, particularly for long sequences, by attending only to selected positions rather than\nall pairs. Even with these improvements, attention-based\nmethods still rely on discrete scaled dot-product operations,\nlimiting their ability to model continuous trajectories often\ncaptured by CT counterparts.\nRecent work has explored bridging this gap through NeuralODE (Chen et al., 2018) formulation. mTAN (Shukla &\nMarlin, 2021) learns CT embeddings and uses time-based\nattention to interpolate irregular observations into a fixedlength representation for downstream encoder-decoder modeling. ODEFormer (d\u2019Ascoli et al., 2023) trains a sequenceto-sequence transformer on synthetic trajectories to directly\ninfer symbolic ODE systems from noisy, irregular data,\nthough it struggles with chaotic systems and generalization\n\n\n\n1\n\n\nNeuronal Attention Circuit (NAC) for Representation Learning\n\n\nbeyond observed conditions. Continuous-time Attention\n(CTA) (Chien & Chen, 2021) embeds a continuous-time\nattention mechanism within a Neural ODE, allowing attention weights and hidden states to evolve jointly over time.\nStill, it remains computationally intensive and sensitive to\nthe accuracy of the ODE solver. ContiFormer (Chen et al.,\n2023) builds a CT-transformer by pairing ODE-defined latent trajectories with a time-aware attention mechanism to\nmodel dynamic relationships in data.\nDespite these innovations, a persistent and underexplored\ngap remains in developing a biologically plausible attention\nmechanism that seamlessly integrates CT dynamics with the\nabstraction of the brain\u2019s connectome to handle irregular sequences without prohibitive computational costs. Building\non this, we propose a novel attention mechanism called the\n_Neuronal Attention Circuit_ (NAC), in which attention logits\nare computed as the solution to a first-order ODE modulated\nby nonlinear, interlinked gates derived from repurposing\nNeuronal Circuit Policies (NCPs) from the nervous system\nof _C. elegans_ nematode (refer to Appendix A.2 for more\ninformation). Unlike standard attention, which projects keyquery pairs through a dense layer, NAC employs a sensory\ngate to transform input features and a backbone to model\nnonlinear interactions, with multiple heads producing outputs structured for attention logits computation. Based on\nthe solutions to ODE, we define three computation modes:\n(i) Exact, using the closed-form ODE solution; (ii) Euler,\napproximating the solution via _explicit Euler_ integration;\nand (iii) Steady, using only the steady-state solution, analogous to standard attention scores. To reduce computational\ncomplexity, we implemented a sparse Top- _K_ pairwise concatenation algorithm that selectively curates key-query inputs. We evaluate NAC across multiple domains, including\nirregularly sampled time series, autonomous vehicle lanekeeping, and Industry 4.0, comparing it to state-of-the-art\nbaselines. NAC consistently matches or outperforms these\nmodels, while runtime and peak memory benchmarks place\nit between CT-RNNs in terms of speed and CT-Attentions\nin terms of memory requirements.\n\n\n2. Neuronal Attention Circuit (NAC)\n\n\nWe propose a simple alternative formulation of the attention\nlogits _a_ (refer to Appendix A.1 for more information), interpreting them as the solution to a first-order linear ODE\nmodulated by nonlinear, interlinked gates:\n\n\nfrom repurposing NCPs. We refer to this formulation as\nthe Neuronal Attention Circuit (NAC). It enables the logits\n_at_ to evolve dynamically with input-dependent, variable\ntime constants, mirroring the adaptive temporal dynamics\nfound in _C. elegans_ nervous systems while improving\ncomputational efficiency and expressiveness. Moreover, it\nintroduces continuous depth into the attention mechanism,bridging discrete-layer computation with dynamic temporal\nevolution.\n\n**Motivation behind this formulation:** The proposed\nformulation is loosely motivated by the input-dependent\ntime-constant mechanism of Liquid Neural Networks\n(LNNs), a class of CT-RNNs inspired by biological nervous\nsystems and synaptic transmission. In this framework, the\ndynamics of non-spiking neurons are described by a linear\nODE with nonlinear, interlinked gates: _ddt_ **xt** = **[x]** _\u03c4_ **[t]** [+] **[ S][t]** _[,]_\n\nwhere **xt** denotes the hidden state and **St** _\u2208_ R _[M]_ represents\na nonlinear contribution defined as _f_ ( **xt** _,_ **u** _, t, \u03b8_ )( _A \u2212_ **xt** ).\nHere, _A_ and _\u03b8_ are learnable parameters. Plugging **St**\nyields _[d]_ **[x][t]** [=] _[ \u2212]_ \ufffd _\u2212_ [1] _[\u2212]_ _[f]_ [(] **[x][t]** _[,]_ **[ u]** _[, t, \u03b8]_ [)] \ufffd **xt** + _f_ ( **xt** _,_ **u** _, t, \u03b8_ ) _A_ .\n\n\n\n_an_ +1 = _an_ + \u2206 _t_ ( _\u2212\u03c9\u03c4_ _an_ + _\u03d5_ ) _._ (2)\n\n\n**Closed-form (Exact) Computation of NAC:** We now devise the analytical solution for Eqn. 1. Let both _\u03c9\u03c4_ and\n_\u03d5_ be fixed in pseudo-time interval (frozen-coefficient approximation (John, 1952)) with initial condition _a_ 0, then\nclosed-form solution is:\n\n\n\n**xt** = **[x][t]**\n\n_dt_ _\u03c4_\n\n\n\n\n**[x][t]** _\u2212_ [1]\n\n_dt_ [=] _[ \u2212]_ \ufffd _\u03c4_\n\n\n\nyields _[d]_ _dt_ **[x][t]** [=] _[ \u2212]_ \ufffd _\u2212_ _\u03c4_ [1] _[\u2212]_ _[f]_ [(] **[x][t]** _[,]_ **[ u]** _[, t, \u03b8]_ [)] \ufffd **xt** + _f_ ( **xt** _,_ **u** _, t, \u03b8_ ) _A_ .\n\nLNNs are known for their strong expressivity, stability, and\nperformance in irregularly sampled time-series modeling\n(Hasani et al., 2021; 2022).\n**NAC\u2019s forward-pass update using ODE solver:** The\nstate of NAC at time _t_ can be computed using a numerical\nODE solver that simulates the dynamics from an initial\nstate _a_ 0 to _at_ . The solver discretizes the continuous interval\n\n[0 _, T_ ] into steps [ _t_ 0 _, t_ 1 _, t_ 2 _, . . ., tn_ ], with each step updating\nthe state from _ti_ to _ti_ +1. For our purposes, we use the\n_explicit Euler_ solver, which is simple, efficient, and easy to\nimplement. Although methods such as Runge-Kutta may\noffer higher accuracy, their computational overhead makes\nthem less suitable for large-scale neural simulations that\nrequire numerous updates, especially since the logits are\nnormalized, and exact precision is not necessary. Let the\nstep size be \u2206 _t_, with discrete times _tn_ = _n_ \u2206 _t_ and logit\nstates _an_ = _a_ ( _tn_ ). Using the _explicit Euler_ method, the\nupdate is\n\n\n\n_dat_\n\n_dt_ [=] _[ \u2212]_ ~~\ufffd~~ _[f][\u03c9][\u03c4]_ [ ([] **[q]** \ufffd [;] **[ k]** ~~\ufffd~~ []] _[, \u03b8][\u03c9][\u03c4]_ [ )] ~~\ufffd~~\n_\u03c9\u03c4_ ( **u** )\n\n\n\n_at_ + _f\u03d5_ ([ **q** ; **k** ] _, \u03b8\u03d5_ ) _,_ (1)\n\ufffd ~~\ufffd~~ \ufffd ~~\ufffd~~\n_\u03d5_ ( **u** )\n\n\n\n_at_ = _a_ _[\u2217]_ + ( _a_ 0 _\u2212_ _a_ _[\u2217]_ ) _e_ _[\u2212][\u03c9][\u03c4][ t]_\n\ufffd\ufffd\ufffd\ufffd ~~\ufffd~~ ~~\ufffd\ufffd~~ ~~\ufffd~~\nsteady-state transient\n\n\n\n(3)\n\n\n\nwhere **u** = [ **q** ; **k** ] denotes the sparse Top- _K_ concatenated\nquery\u2013key input. _\u03c9\u03c4_ represents a learnable time-constant\ngate head, _\u03d5_ denotes a nonlinear content-target head. Both\ngates are parameterized by a backbone network derived\n\n\n\nHere, _a_ _[\u2217]_ = _\u03d5/\u03c9\u03c4_ is the steady-state solution. The full\nderivation is provided in Appendix B.1.\n\n\n\n2\n\n\nNeuronal Attention Circuit (NAC) for Representation Learning\n\n\n2.1. Stability Analysis of NAC\n\n\nWe now investigate the stability bounds of _NAC_ under both\nthe ODE-based and the Closed-Form formulations.\n\n\n2.1.1. STATE STABILITY\n\n\nWe analyze state stability in both single-connection and\nmulti-connection settings. This analysis establishes the\nboundedness of the attention logit state trajectory, ensuring that, under positive decay rates, the dynamics remain\nwell-behaved without divergence or overshoot.\n\n**Theorem 1** (State Stability) **.** _Let a_ [(] _t_ _[i]_ [)] _denote the state of_\n_the i-th attention logit governed by da_ [(] _t_ _[i]_ [)] _[/dt]_ [ =] _[ \u2212][\u03c9][\u03c4]_ _[a]_ [(] _t_ _[i]_ [)] +_\u03d5. Assume that \u03d5 and \u03c9\u03c4 decompose across M incom-_\n_ing connections as \u03d5_ = [\ufffd] _[M]_ _j_ =1 _[f][\u03d5]_ [([] **[q]** _[i]_ [;] **[ k]** _[j]_ [])] _[, and][ \u03c9][\u03c4]_ [ =]\n_M_\n\ufffd _j_ =1 _[f][\u03c9]_ _\u03c4_ [([] **[q]** _[i]_ [;] **[ k]** _[j]_ [])] _[,][ with][ f][\u03c9]_ _\u03c4_ _>_ 0 _._ _Define the per-_\n_connection equilibrium Ai,j_ = _f\u03d5_ ([ **q** _i_ ; **k_j_** ]) _/f\u03c9\u03c4_ ([ **q** _i_ ; **k** _j_ ]) _,\nand let A_ [min] _i_ = min _j Ai,j and A_ [max] _i_ = max _j Ai,j. Then_\n_for any finite horizon t \u2208_ [0 _, T_ ] _, the state trajectory satisfies_\n\n\nmin(0 _, A_ [min] _i_ ) _\u2264_ _a_ [(] _t_ _[i]_ [)] _\u2264_ max(0 _, A_ [max] _i_ ) _,_ (4)\n\n\n_provided the initial condition ai_ (0) _lies within this range. In_\n_the special case of a single connection (M_ = 1 _), the bounds_\n_collapse to_\n\n\nmin(0 _, Ai_ ) _\u2264_ _a_ [(] _t_ _[i]_ [)] _\u2264_ max(0 _, Ai_ ) _,_ (5)\n\n\n_where Ai_ = _f\u03d5/\u03c9\u03c4 is exactly the steady-state solution from_\n_Eqn. 3. The proof is provided in the Appendix B.2._\n\n\n2.1.2. CLOSED-FORM ERROR & EXPONENTIAL BOUNDS\n\n\nWe now examine the asymptotic stability, error characterization, and exponential boundedness of the closed-form\nformulation. We begin by quantifying the deviation of the\ntrajectory from its steady-state solution. Define the instanta\nneous error\n_\u03b5t_ = _at \u2212_ _a_ _[\u2217]_ _,_ (6)\n\n\nwhich measures the distance of the system state to equilibrium at time _t_ . From Eqn. 3, the error admits the exact\nrepresentation\n\n\n_\u03b5t_ = ( _a_ 0 _\u2212_ _a_ _[\u2217]_ ) _e_ _[\u2212][\u03c9][\u03c4][ t]_ (7)\n\n\nIn particular, the pointwise absolute error is given by\n\n\n_|\u03b5t|_ = _|a_ 0 _\u2212_ _a_ _[\u2217]_ _| e_ _[\u2212][\u03c9][\u03c4][ t]_ (8)\n\n\nThis reveals that convergence is not merely asymptotic but\nfollows an exact exponential law, controlled by the rate parameter _\u03c9\u03c4_ . This yields the following finite-time guarantee.\n\n**Corollary 1** (Exponential decay bound) **.** _If \u03c9\u03c4 >_ 0 _, then_\n_for all t \u2265_ 0 _,\n\n\n_|at \u2212_ _a_ _[\u2217]_ _| \u2264|a_ 0 _\u2212_ _a_ _[\u2217]_ _| e_ _[\u2212][\u03c9][\u03c4][ t]_ _._ (9)\n\n\n\n_Remark:_ If _\u03c9\u03c4 >_ 0 then lim _t\u2192\u221e_ _e_ _[\u2212][\u03c9][\u03c4][ t]_ = 0, therefore\n_at \u2192_ _a_ _[\u2217]_ . The convergence is exponential with rate _\u03c9\u03c4_ .\nIf _\u03c9\u03c4 <_ 0 then _e_ _[\u2212][\u03c9][\u03c4][ t]_ = _e_ _[|][\u03c9][\u03c4][ |][t]_ diverges so _at_ grows\nexponentially away from _a_ _[\u2217]_ in magnitude (unless initial\noffset _a_ 0 _\u2212_ _a_ _[\u2217]_ = 0, a measure-zero case). If _\u03c9\u03c4_ = 0 the\nODE is \u02d9 _a_ = _\u03d5_ and the solution is linear in _t_ (unless _\u03d5_ = 0).\nFor bounded dynamics that converge to an interpretable\nsteady-state, it is required that _\u03c9\u03c4 >_ 0.\n\n\n**Corollary 2** (Uniform initialization) **.** _If the initialization is_\n_only known to belong to a bounded set, i.e., |a_ 0 _\u2212_ _a_ _[\u2217]_ _| \u2264_ _M_\n_for some M >_ 0 _, then the error admits the uniform bound_\n\n\n_|at \u2212_ _a_ _[\u2217]_ _| \u2264_ _Me_ _[\u2212][\u03c9][\u03c4][ t]_ _._ (10)\n\n\n_Remark:_ This bound highlights that exponential convergence holds uniformly across all admissible initial\nconditions, with the constant _M_ capturing the worst-case\ndeviation.\n\n\n**Corollary 3** (Sample complexity to _\u03b4_ -accuracy) **.** _A natural_\n_operational question is the time required to achieve a target_\n_tolerance \u03b4 >_ 0 _. Solving_\n\n\n_|a_ 0 _\u2212_ _a_ _[\u2217]_ _|e_ _[\u2212][\u03c9][\u03c4][ t]_ _\u2264_ _\u03b4,_ (11)\n\n\n_We obtain the threshold_\n\n\n\n[1] ln _[|][a]_ [0] _[ \u2212]_ _[a][\u2217][|]_\n\n_\u03c9\u03c4_ _\u03b4_\n\n\n\n_t \u2265_ [1]\n\n\n._ (12)\n_\u03b4_\n\n\n\n_Remark:_ The convergence rate is inversely proportional to\n_\u03c9\u03c4_, and the required time scales only logarithmically in\nthe accuracy level 1 _/\u03b4_ . Intuitively, larger _\u03c9\u03c4_ accelerates\ncontraction towards equilibrium, yielding faster attainment\nof any prescribed tolerance.\n\n\n_Figure 1._ Illustration of **(a)** NCPs with pre-determined wiring; **(b)**\nSensory gate, where sensory neurons are active, and the remaining\nneurons are disabled for the _q_, _k_, and _v_ projections; **(c)** Backbone,\nshowing inter-motor projections with sensory neurons disabled in\nextended heads for computing _\u03d5_ and _\u03c9\u03c4_ .\n\n\n\n3\n\n\n\n![](E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/neuronal_attention_circuits.pdf-2-0.png)\n**Neuronal Attention Circuit (NAC) for Representation Learning**\n\n\n\n**Algorithm 1** Repurposed NCPCell\n", "metadata": []}}
{"nodes": [{"id": "Exponential Convergence", "type": "Concept"}, {"id": "Corollary 3", "type": "Concept"}, {"id": "Sample Complexity to \u03b4-accuracy", "type": "Concept"}, {"id": "\u03c9\u03c4", "type": "Parameter"}, {"id": "Convergence Rate", "type": "Concept"}, {"id": "Accuracy Level", "type": "Concept"}, {"id": "Figure 1", "type": "Figure"}, {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, {"id": "Sensory Gate", "type": "Component"}, {"id": "Sensory Neurons", "type": "Component"}, {"id": "q", "type": "Parameter"}, {"id": "k", "type": "Parameter"}, {"id": "v", "type": "Parameter"}, {"id": "Backbone Network", "type": "Component"}, {"id": "\u03d5", "type": "Parameter"}, {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, {"id": "Representation Learning", "type": "Task"}, {"id": "Algorithm 1", "type": "Algorithm"}, {"id": "Repurposed NCPCell", "type": "Algorithm"}, {"id": "Algorithm 2", "type": "Algorithm"}, {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, {"id": "Neural Network Layer Design", "type": "Process"}, {"id": "Input Curation", "type": "Process"}, {"id": "Time Vector Construction", "type": "Process"}, {"id": "t", "type": "Parameter"}, {"id": "Attention Logits", "type": "Concept"}, {"id": "Attention Weights", "type": "Concept"}, {"id": "Attention Output", "type": "Concept"}, {"id": "Figure 2", "type": "Figure"}, {"id": "Flexible Recurrent Architecture", "type": "Architecture"}, {"id": "Adjacency Matrices", "type": "Concept"}, {"id": "Sparse Input", "type": "Concept"}, {"id": "Recurrent Connections", "type": "Concept"}, {"id": "Sparsity s", "type": "Parameter"}, {"id": "Group-Wise Masking", "type": "Technique"}, {"id": "Adaptive Remapping", "type": "Technique"}, {"id": "NN sensory", "type": "Component"}, {"id": "Inter-to-Motor Pathways", "type": "Concept"}, {"id": "Shared Representations", "type": "Concept"}, {"id": "Head Layers", "type": "Component"}, {"id": "Temporal Dependencies", "type": "Concept"}, {"id": "Structural Dependencies", "type": "Concept"}, {"id": "Accelerates Convergence During Training", "type": "Benefit"}, {"id": "Content-Target Gate", "type": "Component"}, {"id": "Learnable Time-Constant Gate Head", "type": "Component"}, {"id": "Sigmoid Function", "type": "Function"}, {"id": "Target Signal Strength", "type": "Concept"}, {"id": "Rate of Convergence", "type": "Concept"}, {"id": "Steady-State Amplitude", "type": "Concept"}, {"id": "Expression Speed", "type": "Concept"}, {"id": "Expression Extent", "type": "Concept"}, {"id": "Full Pairwise Concatenation", "type": "Technique"}, {"id": "Q", "type": "Parameter"}, {"id": "K", "type": "Parameter"}, {"id": "U", "type": "Parameter"}, {"id": "S", "type": "Parameter"}, {"id": "U topk", "type": "Parameter"}, {"id": "Memory Requirements", "type": "Concept"}, {"id": "Sequence Length", "type": "Concept"}, {"id": "Continuous-depth Models", "type": "Model Type"}, {"id": "Hasani et al., 2022", "type": "Publication"}, {"id": "Pseudo-Time Vector", "type": "Parameter"}, {"id": "Sigmoidal Transformation", "type": "Technique"}, {"id": "ta", "type": "Parameter"}, {"id": "tb", "type": "Parameter"}, {"id": "Time-Varying Datasets", "type": "Dataset Type"}, {"id": "Irregularly Sampled Series", "type": "Data Type"}, {"id": "Timestamp", "type": "Concept"}, {"id": "Bounded Representation of Time", "type": "Concept"}, {"id": "Query-Key Pair", "type": "Concept"}, {"id": "Softmax Normalization", "type": "Technique"}, {"id": "Value Matrix", "type": "Concept"}, {"id": "Head-specific Attention Outputs", "type": "Concept"}, {"id": "Multi-Head Attention (MHA)", "type": "Mechanism"}, {"id": "Model Dimension", "type": "Concept"}, {"id": "Probability Distribution", "type": "Concept"}, {"id": "Content Alignments", "type": "Concept"}, {"id": "Speed of Preferences", "type": "Concept"}, {"id": "Saturation of Preferences", "type": "Concept"}, {"id": "Steady State", "type": "Concept"}, {"id": "Scaled-Dot Attention", "type": "Mechanism"}, {"id": "Linear Projection", "type": "Technique"}, {"id": "Nonlinear Backbone", "type": "Component"}, {"id": "Expressive Similarities", "type": "Concept"}, {"id": "Riemann-Style Approach", "type": "Technique"}, {"id": "Pseudo-Time Step", "type": "Parameter"}, {"id": "Hyperparameter", "type": "Concept"}, {"id": "Continuous Analogue of Standard Weighted Sums", "type": "Concept"}, {"id": "Attention Trajectory", "type": "Concept"}, {"id": "Input Sequence", "type": "Concept"}, {"id": "H", "type": "Parameter"}, {"id": "Independent Subspaces", "type": "Concept"}, {"id": "Heads", "type": "Component"}, {"id": "Query Tensors", "type": "Concept"}, {"id": "Key Tensors", "type": "Concept"}, {"id": "Value Tensors", "type": "Concept"}, {"id": "q(h)", "type": "Parameter"}, {"id": "k(h)", "type": "Parameter"}, {"id": "v(h)", "type": "Parameter"}, {"id": "Pairwise Logits", "type": "Concept"}, {"id": "Dynamic Compatibilities", "type": "Concept"}, {"id": "Universal Approximator", "type": "Concept"}, {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, {"id": "Nishijima, 2021", "type": "Publication"}, {"id": "NAC Layer", "type": "Component"}, {"id": "Theorem 2", "type": "Theorem"}, {"id": "Universal Approximation by NAC", "type": "Concept"}, {"id": "Nonlinear Activations", "type": "Concept"}, {"id": "Evaluation", "type": "Process"}, {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, {"id": "Continuous-time RNNs (CT-RNNs)", "type": "Model"}, {"id": "DT Attention", "type": "Mechanism"}, {"id": "Continuous-time Attention (CTA)", "type": "Mechanism"}, {"id": "NAC Ablation Configurations", "type": "Concept"}, {"id": "Irregular Time-Series Classification", "type": "Task"}, {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, {"id": "Industrial Prognostics", "type": "Task"}, {"id": "5-fold Cross-Validation", "type": "Technique"}, {"id": "BPTT", "type": "Algorithm"}, {"id": "Table 1", "type": "Table"}, {"id": "Results", "type": "Concept"}, {"id": "Event-based MNIST", "type": "Dataset"}, {"id": "Person Activity Recognition (PAR)", "type": "Task"}, {"id": "MNIST Dataset", "type": "Dataset"}, {"id": "Irregular Sampling", "type": "Technique"}, {"id": "Lechner & Hasani, 2022", "type": "Publication"}, {"id": "Time Series", "type": "Data Type"}, {"id": "Event-based Format", "type": "Format"}, {"id": "NAC-PW", "type": "Model"}, {"id": "Accuracy", "type": "Metric"}, {"id": "First Place", "type": "Rank"}, {"id": "NAC-Exact/05s/8k", "type": "Model"}, {"id": "Second Place", "type": "Rank"}, {"id": "GRU-ODE", "type": "Model"}, {"id": "ContiFormer", "type": "Model"}, {"id": "Third Place", "type": "Rank"}, {"id": "Localized Person Activity Dataset", "type": "Dataset"}, {"id": "UC Irvine", "type": "Organization"}, {"id": "Vidulin et al., 2010", "type": "Publication"}, {"id": "Inertial Measurement Sensors", "type": "Device"}, {"id": "Classification Task", "type": "Task"}, {"id": "NAC-02s", "type": "Model"}, {"id": "Autonomous Vehicles (AVs)", "type": "Concept"}, {"id": "Robotics", "type": "Field"}, {"id": "AI", "type": "Field"}, {"id": "Tiang et al., 2018", "type": "Publication"}, {"id": "Park et al., 2021", "type": "Publication"}, {"id": "Lechner et al., 2020", "type": "Publication"}, {"id": "Razzaq & Hongwei, 2023", "type": "Publication"}, {"id": "Compact Architectures", "type": "Architecture Type"}, {"id": "Resource-Constrained Devices", "type": "Device Type"}, {"id": "Road's Horizon", "type": "Concept"}, {"id": "Steering Commands", "type": "Concept"}, {"id": "OpenAI CarRacing", "type": "Environment"}, {"id": "Brockman et al., 2016", "type": "Publication"}, {"id": "Udacity Self-Driving Car Simulator", "type": "Environment"}, {"id": "Early Works", "type": "Research Area"}, {"id": "Recent Research", "type": "Research Area"}, {"id": "Causal Structure", "type": "Concept"}, {"id": "Classifying Steering Actions", "type": "Task"}, {"id": "Predicting Steering Values", "type": "Task"}, {"id": "AI Models", "type": "Model Type"}, {"id": "Recurrent Layer", "type": "Component"}, {"id": "NAC-Steady", "type": "Model"}, {"id": "Long-short term memory (LSTM)", "type": "Model"}, {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, {"id": "MSE", "type": "Metric"}, {"id": "NAC-32k", "type": "Model"}, {"id": "NAC-Exact", "type": "Model"}, {"id": "Multi-Head Extension", "type": "Concept"}], "relationships": [{"source": {"id": "Corollary 3", "type": "Concept"}, "target": {"id": "Sample Complexity to \u03b4-accuracy", "type": "Concept"}, "type": "DISCUSSES"}, {"source": {"id": "Convergence Rate", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Parameter"}, "type": "IS_INVERSELY_PROPORTIONAL_TO"}, {"source": {"id": "Convergence Rate", "type": "Concept"}, "target": {"id": "Accuracy Level", "type": "Concept"}, "type": "SCALES_LOGARITHMICALLY_IN"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Convergence Rate", "type": "Concept"}, "type": "ACCELERATES"}, {"source": {"id": "Figure 1", "type": "Figure"}, "target": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "type": "ILLUSTRATES"}, {"source": {"id": "Figure 1", "type": "Figure"}, "target": {"id": "Sensory Gate", "type": "Component"}, "type": "ILLUSTRATES"}, {"source": {"id": "Figure 1", "type": "Figure"}, "target": {"id": "Backbone Network", "type": "Component"}, "type": "ILLUSTRATES"}, {"source": {"id": "Sensory Gate", "type": "Component"}, "target": {"id": "Sensory Neurons", "type": "Component"}, "type": "USES"}, {"source": {"id": "Sensory Gate", "type": "Component"}, "target": {"id": "q", "type": "Parameter"}, "type": "FOR_PROJECTIONS"}, {"source": {"id": "Sensory Gate", "type": "Component"}, "target": {"id": "k", "type": "Parameter"}, "type": "FOR_PROJECTIONS"}, {"source": {"id": "Sensory Gate", "type": "Component"}, "target": {"id": "v", "type": "Parameter"}, "type": "FOR_PROJECTIONS"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "Inter-to-Motor Pathways", "type": "Concept"}, "type": "SHOWS"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "\u03d5", "type": "Parameter"}, "type": "COMPUTES"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "\u03c9\u03c4", "type": "Parameter"}, "type": "COMPUTES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Representation Learning", "type": "Task"}, "type": "FOR"}, {"source": {"id": "Algorithm 1", "type": "Algorithm"}, "target": {"id": "Repurposed NCPCell", "type": "Algorithm"}, "type": "DESCRIBES"}, {"source": {"id": "Algorithm 2", "type": "Algorithm"}, "target": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "type": "DESCRIBES"}, {"source": {"id": "Neural Network Layer Design", "type": "Process"}, "target": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "type": "INVOLVES_REPURPOSING"}, {"source": {"id": "Neural Network Layer Design", "type": "Process"}, "target": {"id": "Input Curation", "type": "Process"}, "type": "INVOLVES"}, {"source": {"id": "Neural Network Layer Design", "type": "Process"}, "target": {"id": "Time Vector Construction", "type": "Process"}, "type": "INVOLVES"}, {"source": {"id": "Neural Network Layer Design", "type": "Process"}, "target": {"id": "Attention Logits", "type": "Concept"}, "type": "INVOLVES_COMPUTING"}, {"source": {"id": "Neural Network Layer Design", "type": "Process"}, "target": {"id": "Attention Weights", "type": "Concept"}, "type": "INVOLVES_COMPUTING"}, {"source": {"id": "Neural Network Layer Design", "type": "Process"}, "target": {"id": "Attention Output", "type": "Concept"}, "type": "INVOLVES_GENERATING"}, {"source": {"id": "Time Vector Construction", "type": "Process"}, "target": {"id": "t", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Figure 2", "type": "Figure"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "PROVIDES_OVERVIEW_OF"}, {"source": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "target": {"id": "Flexible Recurrent Architecture", "type": "Architecture"}, "type": "REPURPOSED_INTO"}, {"source": {"id": "Flexible Recurrent Architecture", "type": "Architecture"}, "target": {"id": "Adjacency Matrices", "type": "Concept"}, "type": "USES"}, {"source": {"id": "Adjacency Matrices", "type": "Concept"}, "target": {"id": "Sparse Input", "type": "Concept"}, "type": "DEFINES"}, {"source": {"id": "Adjacency Matrices", "type": "Concept"}, "target": {"id": "Recurrent Connections", "type": "Concept"}, "type": "DEFINES"}, {"source": {"id": "Algorithm 1", "type": "Algorithm"}, "target": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "type": "SUMMARIZES_REPURPOSING_FOR"}, {"source": {"id": "Flexible Recurrent Architecture", "type": "Architecture"}, "target": {"id": "Group-Wise Masking", "type": "Technique"}, "type": "HAS_FEATURE"}, {"source": {"id": "Flexible Recurrent Architecture", "type": "Architecture"}, "target": {"id": "Adaptive Remapping", "type": "Technique"}, "type": "HAS_FEATURE"}, {"source": {"id": "Flexible Recurrent Architecture", "type": "Architecture"}, "target": {"id": "Sparsity s", "type": "Parameter"}, "type": "HAS_FEATURE"}, {"source": {"id": "NN sensory", "type": "Component"}, "target": {"id": "q", "type": "Parameter"}, "type": "PROJECTS"}, {"source": {"id": "NN sensory", "type": "Component"}, "target": {"id": "k", "type": "Parameter"}, "type": "PROJECTS"}, {"source": {"id": "NN sensory", "type": "Component"}, "target": {"id": "v", "type": "Parameter"}, "type": "PROJECTS"}, {"source": {"id": "NN sensory", "type": "Component"}, "target": {"id": "Repurposed NCPCell", "type": "Algorithm"}, "type": "IS_AN_INSTANCE_OF"}, {"source": {"id": "Inter-to-Motor Pathways", "type": "Concept"}, "target": {"id": "Backbone Network", "type": "Component"}, "type": "FORMS"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "\u03d5", "type": "Parameter"}, "type": "COMPUTES"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "\u03c9\u03c4", "type": "Parameter"}, "type": "COMPUTES"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "Shared Representations", "type": "Concept"}, "type": "ALLOWS_LEARNING_OF"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "Accelerates Convergence During Training", "type": "Benefit"}, "type": "PROVIDES"}, {"source": {"id": "Head Layers", "type": "Component"}, "target": {"id": "Temporal Dependencies", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "Head Layers", "type": "Component"}, "target": {"id": "Structural Dependencies", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "Repurposed NCPCell", "type": "Algorithm"}, "type": "IS_AN_INSTANCE_OF"}, {"source": {"id": "\u03d5", "type": "Parameter"}, "target": {"id": "Content-Target Gate", "type": "Component"}, "type": "SERVES_AS"}, {"source": {"id": "Content-Target Gate", "type": "Component"}, "target": {"id": "Sigmoid Function", "type": "Function"}, "type": "USES"}, {"source": {"id": "Sigmoid Function", "type": "Function"}, "target": {"id": "Target Signal Strength", "type": "Concept"}, "type": "DETERMINES"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Learnable Time-Constant Gate Head", "type": "Component"}, "type": "IS_A"}, {"source": {"id": "Learnable Time-Constant Gate Head", "type": "Component"}, "target": {"id": "Rate of Convergence", "type": "Concept"}, "type": "CONTROLS"}, {"source": {"id": "Learnable Time-Constant Gate Head", "type": "Component"}, "target": {"id": "Steady-State Amplitude", "type": "Concept"}, "type": "CONTROLS"}, {"source": {"id": "\u03d5", "type": "Parameter"}, "target": {"id": "Content", "type": "Concept"}, "type": "REGULATES"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Expression Speed", "type": "Concept"}, "type": "GOVERNS"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Expression Extent", "type": "Concept"}, "type": "GOVERNS"}, {"source": {"id": "Input Curation", "type": "Process"}, "target": {"id": "Full Pairwise Concatenation", "type": "Technique"}, "type": "USES"}, {"source": {"id": "Full Pairwise Concatenation", "type": "Technique"}, "target": {"id": "Q", "type": "Parameter"}, "type": "COMBINES"}, {"source": {"id": "Full Pairwise Concatenation", "type": "Technique"}, "target": {"id": "K", "type": "Parameter"}, "type": "COMBINES"}, {"source": {"id": "Full Pairwise Concatenation", "type": "Technique"}, "target": {"id": "U", "type": "Parameter"}, "type": "FORMS"}, {"source": {"id": "Input Curation", "type": "Process"}, "target": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "type": "APPLIES"}, {"source": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "target": {"id": "S", "type": "Parameter"}, "type": "COMPUTES"}, {"source": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "target": {"id": "K", "type": "Parameter"}, "type": "SELECTS"}, {"source": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "target": {"id": "U topk", "type": "Parameter"}, "type": "CONSTRUCTS"}, {"source": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "target": {"id": "Memory Requirements", "type": "Concept"}, "type": "REDUCES"}, {"source": {"id": "Sparse Top-K Pairwise Concatenation", "type": "Technique"}, "target": {"id": "Sequence Length", "type": "Concept"}, "type": "SCALES_LINEARLY_WITH"}, {"source": {"id": "Algorithm 2", "type": "Algorithm"}, "target": {"id": "Input Curation", "type": "Process"}, "type": "OUTLINES_STEPS_FOR"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Continuous-depth Models", "type": "Model Type"}, "type": "BUILDS_ON"}, {"source": {"id": "Continuous-depth Models", "type": "Model Type"}, "target": {"id": "Hasani et al., 2022", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Pseudo-Time Vector", "type": "Parameter"}, "type": "CONSTRUCTS"}, {"source": {"id": "Pseudo-Time Vector", "type": "Parameter"}, "target": {"id": "Sigmoidal Transformation", "type": "Technique"}, "type": "USES"}, {"source": {"id": "Sigmoidal Transformation", "type": "Technique"}, "target": {"id": "ta", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Sigmoidal Transformation", "type": "Technique"}, "target": {"id": "tb", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Sigmoidal Transformation", "type": "Technique"}, "target": {"id": "Sigmoid Function", "type": "Function"}, "type": "USES"}, {"source": {"id": "t", "type": "Parameter"}, "target": {"id": "Timestamp", "type": "Concept"}, "type": "DERIVED_FROM_FOR"}, {"source": {"id": "Pseudo-Time Vector", "type": "Parameter"}, "target": {"id": "Bounded Representation of Time", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Parameter"}, "type": "CALCULATED_USING"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Parameter"}, "type": "CALCULATED_USING"}, {"source": {"id": "Attention Weights", "type": "Concept"}, "target": {"id": "Softmax Normalization", "type": "Technique"}, "type": "CALCULATED_USING"}, {"source": {"id": "Attention Weights", "type": "Concept"}, "target": {"id": "v", "type": "Parameter"}, "type": "USED_TO_INTEGRATE_WITH"}, {"source": {"id": "Attention Weights", "type": "Concept"}, "target": {"id": "Head-specific Attention Outputs", "type": "Concept"}, "type": "PRODUCES"}, {"source": {"id": "Head-specific Attention Outputs", "type": "Concept"}, "target": {"id": "Model Dimension", "type": "Concept"}, "type": "PROJECTED_INTO"}, {"source": {"id": "Multi-Head Attention (MHA)", "type": "Mechanism"}, "target": {"id": "Expressive Capacity", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Universal Approximator", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Universal Approximator", "type": "Concept"}, "target": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "type": "ESTABLISHED_BY_EXTENDING"}, {"source": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "target": {"id": "Nishijima, 2021", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "NAC Layer", "type": "Component"}, "type": "HAS"}, {"source": {"id": "Theorem 2", "type": "Theorem"}, "target": {"id": "Universal Approximation by NAC", "type": "Concept"}, "type": "STATES"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "NAC Layer", "type": "Component"}, "type": "DEPENDS_ON"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "Model Dimension", "type": "Concept"}, "type": "DEPENDS_ON"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "H", "type": "Parameter"}, "type": "DEPENDS_ON"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "Sparsity s", "type": "Parameter"}, "type": "DEPENDS_ON"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "Nonlinear Activations", "type": "Concept"}, "type": "DEPENDS_ON"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "COMPARES"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Discrete-time Recurrent Neural Networks (DT-RNNs)", "type": "Model"}, "type": "COMPARES"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Continuous-time RNNs (CT-RNNs)", "type": "Model"}, "type": "COMPARES"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "DT Attention", "type": "Mechanism"}, "type": "COMPARES"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Continuous-time Attention (CTA)", "type": "Mechanism"}, "type": "COMPARES"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "NAC Ablation Configurations", "type": "Concept"}, "type": "COMPARES"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Irregular Time-Series Classification", "type": "Task"}, "type": "CONDUCTED_ACROSS"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "type": "CONDUCTED_ACROSS"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Industrial Prognostics", "type": "Task"}, "type": "CONDUCTED_ACROSS"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "5-fold Cross-Validation", "type": "Technique"}, "type": "USES"}, {"source": {"id": "Models", "type": "Concept"}, "target": {"id": "BPTT", "type": "Algorithm"}, "type": "TRAINED_USING"}, {"source": {"id": "Table 1", "type": "Table"}, "target": {"id": "Results", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Event-based MNIST", "type": "Dataset"}, "type": "EVALUATED_ON"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Person Activity Recognition (PAR)", "type": "Task"}, "type": "EVALUATED_ON"}, {"source": {"id": "Event-based MNIST", "type": "Dataset"}, "target": {"id": "MNIST Dataset", "type": "Dataset"}, "type": "IS_TRANSFORMATION_OF"}, {"source": {"id": "Event-based MNIST", "type": "Dataset"}, "target": {"id": "Irregular Sampling", "type": "Technique"}, "type": "INCLUDES"}, {"source": {"id": "Event-based MNIST", "type": "Dataset"}, "target": {"id": "Lechner & Hasani, 2022", "type": "Publication"}, "type": "PROPOSED_BY"}, {"source": {"id": "Event-based MNIST", "type": "Dataset"}, "target": {"id": "Event-based Format", "type": "Format"}, "type": "ENCODED_INTO"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_96.64%"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "First Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_96.12%"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_96.04%"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_96.04%"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "Person Activity Recognition (PAR)", "type": "Task"}, "target": {"id": "Localized Person Activity Dataset", "type": "Dataset"}, "type": "EMPLOYED"}, {"source": {"id": "Localized Person Activity Dataset", "type": "Dataset"}, "target": {"id": "UC Irvine", "type": "Organization"}, "type": "FROM"}, {"source": {"id": "Localized Person Activity Dataset", "type": "Dataset"}, "target": {"id": "Vidulin et al., 2010", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Localized Person Activity Dataset", "type": "Dataset"}, "target": {"id": "Inertial Measurement Sensors", "type": "Device"}, "type": "CONTAINS_DATA_FROM"}, {"source": {"id": "Person Activity Recognition (PAR)", "type": "Task"}, "target": {"id": "Classification Task", "type": "Task"}, "type": "IS_A"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_89.15%"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "First Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_89.01%"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_89.01%"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "NAC-02s", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_88.84%"}, {"source": {"id": "NAC-02s", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "HAS_RANK"}, {"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "target": {"id": "Robotics", "type": "Field"}, "type": "PROBLEM_IN"}, {"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "target": {"id": "AI", "type": "Field"}, "type": "PROBLEM_IN"}, {"source": {"id": "Early Works", "type": "Research Area"}, "target": {"id": "Tiang et al., 2018", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Early Works", "type": "Research Area"}, "target": {"id": "Park et al., 2021", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Recent Research", "type": "Research Area"}, "target": {"id": "Lechner et al., 2020", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Recent Research", "type": "Research Area"}, "target": {"id": "Razzaq & Hongwei, 2023", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Recent Research", "type": "Research Area"}, "target": {"id": "Compact Architectures", "type": "Architecture Type"}, "type": "FOCUSES_ON"}, {"source": {"id": "Compact Architectures", "type": "Architecture Type"}, "target": {"id": "Resource-Constrained Devices", "type": "Device Type"}, "type": "SUITABLE_FOR"}, {"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "target": {"id": "Causal Structure", "type": "Concept"}, "type": "AIMS_TO_CREATE"}, {"source": {"id": "Causal Structure", "type": "Concept"}, "target": {"id": "Road's Horizon", "type": "Concept"}, "type": "BETWEEN"}, {"source": {"id": "Causal Structure", "type": "Concept"}, "target": {"id": "Steering Commands", "type": "Concept"}, "type": "BETWEEN"}, {"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "EVALUATED_USING"}, {"source": {"id": "OpenAI CarRacing", "type": "Environment"}, "target": {"id": "Brockman et al., 2016", "type": "Publication"}, "type": "CITED"}, {"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Task"}, "target": {"id": "Udacity Self-Driving Car Simulator", "type": "Environment"}, "type": "EVALUATED_USING"}, {"source": {"id": "OpenAI CarRacing", "type": "Environment"}, "target": {"id": "Classifying Steering Actions", "type": "Task"}, "type": "INVOLVES"}, {"source": {"id": "Udacity Self-Driving Car Simulator", "type": "Environment"}, "target": {"id": "Predicting Steering Values", "type": "Task"}, "type": "REQUIRES"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "Razzaq & Hongwei, 2023", "type": "Publication"}, "type": "PROPOSED_BY"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "Recurrent Layer", "type": "Component"}, "type": "REPLACED"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "REPLACED_WITH"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_80.72%_ON"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "First Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "NAC-Steady", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_80.62%_ON"}, {"source": {"id": "NAC-Steady", "type": "Model"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "NAC-Steady", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "Long-short term memory (LSTM)", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_80.60%_ON"}, {"source": {"id": "Long-short term memory (LSTM)", "type": "Model"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "Long-short term memory (LSTM)", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED_80.60%_ON"}, {"source": {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "Gated Recurrent Unit (GRU)", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "NAC-32k", "type": "Model"}, "target": {"id": "MSE", "type": "Metric"}, "type": "ACHIEVED_0.0170_ON"}, {"source": {"id": "NAC-32k", "type": "Model"}, "target": {"id": "Udacity Self-Driving Car Simulator", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "NAC-32k", "type": "Model"}, "target": {"id": "First Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "MSE", "type": "Metric"}, "type": "ACHIEVED_0.0173_ON"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "Udacity Self-Driving Car Simulator", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "MSE", "type": "Metric"}, "type": "ACHIEVED_0.0174_ON"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Udacity Self-Driving Car Simulator", "type": "Environment"}, "type": "PERFORMED_ON"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "HAS_RANK_ON"}, {"source": {"id": "Attention", "type": "Concept"}, "target": {"id": "Exponential Factor", "type": "Concept"}, "type": "REGULATED_BY"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Temporal Gating Role", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Softmax Normalization", "type": "Technique"}, "target": {"id": "Attention Weights", "type": "Concept"}, "type": "YIELDS"}, {"source": {"id": "Attention Weights", "type": "Concept"}, "target": {"id": "Probability Distribution", "type": "Concept"}, "type": "DEFINES"}, {"source": {"id": "\u03d5", "type": "Parameter"}, "target": {"id": "Content Alignments", "type": "Concept"}, "type": "AMPLIFIES_OR_SUPPRESSES"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Speed of Preferences", "type": "Concept"}, "type": "SHAPES"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "Saturation of Preferences", "type": "Concept"}, "type": "SHAPES"}, {"source": {"id": "Trajectory", "type": "Concept"}, "target": {"id": "Steady State", "type": "Concept"}, "type": "CONVERGES_TO"}, {"source": {"id": "Steady State", "type": "Concept"}, "target": {"id": "Scaled-Dot Attention", "type": "Mechanism"}, "type": "IS_ANALOGOUS_TO"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "Linear Projection", "type": "Technique"}, "type": "CONFIGURED_AS"}, {"source": {"id": "Nonlinear Backbone", "type": "Component"}, "target": {"id": "Expressive Similarities", "type": "Concept"}, "type": "ALLOWS_FOR"}, {"source": {"id": "Attention Output", "type": "Concept"}, "target": {"id": "Attention Weights", "type": "Concept"}, "type": "COMPUTED_BY_INTEGRATING"}, {"source": {"id": "Attention Output", "type": "Concept"}, "target": {"id": "Value Matrix", "type": "Concept"}, "type": "COMPUTED_BY_INTEGRATING"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "q", "type": "Parameter"}, "type": "USES_FOR_OUTPUT"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "k", "type": "Parameter"}, "type": "USES_FOR_OUTPUT"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "v", "type": "Parameter"}, "type": "USES_FOR_OUTPUT"}, {"source": {"id": "Integration", "type": "Concept"}, "target": {"id": "Riemann-Style Approach", "type": "Technique"}, "type": "APPROXIMATED_USING"}, {"source": {"id": "Riemann-Style Approach", "type": "Technique"}, "target": {"id": "Pseudo-Time Step", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Pseudo-Time Step", "type": "Parameter"}, "target": {"id": "Hyperparameter", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Attention Output", "type": "Concept"}, "target": {"id": "Continuous Analogue of Standard Weighted Sums", "type": "Concept"}, "type": "YIELDS"}, {"source": {"id": "Mechanism", "type": "Concept"}, "target": {"id": "Multi-Head Attention (MHA)", "type": "Mechanism"}, "type": "EXTENDED_TO"}, {"source": {"id": "Multi-Head Attention (MHA)", "type": "Mechanism"}, "target": {"id": "Input Sequence", "type": "Concept"}, "type": "PROJECTS"}, {"source": {"id": "Input Sequence", "type": "Concept"}, "target": {"id": "H", "type": "Parameter"}, "type": "INTO_SUBSPACES"}, {"source": {"id": "H", "type": "Parameter"}, "target": {"id": "Heads", "type": "Component"}, "type": "REPRESENTS"}, {"source": {"id": "Heads", "type": "Component"}, "target": {"id": "Query Tensors", "type": "Concept"}, "type": "YIELD"}, {"source": {"id": "Heads", "type": "Component"}, "target": {"id": "Key Tensors", "type": "Concept"}, "type": "YIELD"}, {"source": {"id": "Heads", "type": "Component"}, "target": {"id": "Value Tensors", "type": "Concept"}, "type": "YIELD"}, {"source": {"id": "Query Tensors", "type": "Concept"}, "target": {"id": "q(h)", "type": "Parameter"}, "type": "REPRESENTED_BY"}, {"source": {"id": "Key Tensors", "type": "Concept"}, "target": {"id": "k(h)", "type": "Parameter"}, "type": "REPRESENTED_BY"}, {"source": {"id": "Value Tensors", "type": "Concept"}, "target": {"id": "v(h)", "type": "Parameter"}, "type": "REPRESENTED_BY"}, {"source": {"id": "Heads", "type": "Component"}, "target": {"id": "Pairwise Logits", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "Pairwise Logits", "type": "Concept"}, "target": {"id": "Softmax Normalization", "type": "Technique"}, "type": "FOLLOWED_BY"}, {"source": {"id": "Softmax Normalization", "type": "Technique"}, "target": {"id": "Attention Weights", "type": "Concept"}, "type": "CALCULATES"}, {"source": {"id": "Attention Weights", "type": "Concept"}, "target": {"id": "v(h)", "type": "Parameter"}, "type": "USED_TO_INTEGRATE_WITH"}, {"source": {"id": "v(h)", "type": "Parameter"}, "target": {"id": "Head-specific Attention Outputs", "type": "Concept"}, "type": "PRODUCES"}, {"source": {"id": "Head-specific Attention Outputs", "type": "Concept"}, "target": {"id": "Model Dimension", "type": "Concept"}, "type": "PROJECTED_INTO"}, {"source": {"id": "Heads", "type": "Component"}, "target": {"id": "Dynamic Compatibilities", "type": "Concept"}, "type": "LEARN"}, {"source": {"id": "Dynamic Compatibilities", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Parameter"}, "type": "GOVERNED_BY"}, {"source": {"id": "Dynamic Compatibilities", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Parameter"}, "type": "GOVERNED_BY"}, {"source": {"id": "Multi-Head Attention (MHA)", "type": "Mechanism"}, "target": {"id": "Expressive Capacity", "type": "Concept"}, "type": "PRESERVES"}, {"source": {"id": "Figure 2", "type": "Figure"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "ILLUSTRATES"}, {"source": {"id": "Figure 2", "type": "Figure"}, "target": {"id": "Multi-Head Extension", "type": "Concept"}, "type": "ILLUSTRATES"}], "source": {"page_content": "Remark: This bound highlights that exponential convergence holds uniformly across all admissible initial conditions, with the constant M capturing the worst-case deviation. Corollary 3 (Sample complexity to \u03b4 -accuracy) . A natural operational question is the time required to achieve a target tolerance \u03b4 > 0 . Solving _ |a 0 \u2212 a [\u2217] |e [\u2212][\u03c9][\u03c4][ t] \u2264 \u03b4,_ (11) We obtain the threshold [1] ln _[|][a]_ [0] _[ \u2212]_ _[a][\u2217][|]_ _\u03c9\u03c4_ _\u03b4_ _t \u2265_ [1] _._ (12) _\u03b4_ Remark: The convergence rate is inversely proportional to _\u03c9\u03c4_, and the required time scales only logarithmically in the accuracy level 1 _/\u03b4_ . Intuitively, larger _\u03c9\u03c4_ accelerates contraction towards equilibrium, yielding faster attainment of any prescribed tolerance. Figure 1. Illustration of **(a)** NCPs with pre-determined wiring; **(b)** Sensory gate, where sensory neurons are active, and the remaining neurons are disabled for the _q_, _k_, and _v_ projections; **(c)** Backbone, showing inter-motor projections with sensory neurons disabled in extended heads for computing _\u03d5_ and _\u03c9\u03c4_ . 3 ![](E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/neuronal_attention_circuits.pdf-2-0.png) **Neuronal Attention Circuit (NAC) for Representation Learning** Algorithm 1 Repurposed NCPCell Require: Wiring _W_ with ( _A_ in _, A_ rec), groups ( _Ns, Ni, Nc, Nm_ ), activation _\u03b1_, input group _G_ input, output group _G_ output, disabled groups _D_ Ensure: Output _yt \u2208_ R _[B][\u00d7][d]_ [out], state **x** _t \u2208_ R _[B][\u00d7][d][h]_ Binary mask: _M_ rec _\u2190|A_ rec _|_, _M_ in _\u2190|A_ in _|_ Initialize parameters : _W_ in _, W_ rec _, b, w_ in _, b_ in _, w_ out _, b_ out Input neurons: _I_ in _\u2190_ _G_ input Output neurons: _I_ out _\u2190_ _G_ output Define activation mask: maskact _,i_ = 0 if _i \u2208D_ else 1 Input Projections: \u02dc _ut \u2190_ _ut \u2299_ _w_ in + _b_ in Recurrent computation:Sparse computation: _st \u2190 rt \u2190u_ \u02dc _t_ ( **x** _Wt\u2212_ in1 _\u2299_ ( _WM_ recin _\u2299_ ) _M_ rec) Neuron update: **x** _t \u2190_ _\u03b1_ ( _rt_ + _st_ + _b_ ) _\u2299_ maskact Output mapping: _yt \u2190_ ( **x** _t_ [ _I_ out] _\u2299_ _w_ out) + _b_ out **return** ( _yt,_ **x** _t_ ) Algorithm 2 Sparse Top- _K_ Pairwise Concatenation Require: Keys _K \u2208_ R _[B][\u00d7][H][\u00d7][T][k][\u00d7][D]_, Top- _K_ value _K_ Ensure: concatenated tensor _U \u2208_ R _[B][\u00d7][H][\u00d7][T][q]_ _[\u00d7][K]_ [eff] _[\u00d7]_ [2] _[D]_ Scores: _S \u2190_ _Q \u00b7 K_ _[\u22a4]_ Effective Top- _K_ : _K_ eff _\u2190_ min( _K, Tk_ ) Indices: _I_ topk _\u2190_ top ~~k~~ ( _S, K_ eff) Gather: _K_ selected _\u2190_ gather( _K, I_ topk) _\u2208_ R _[B][\u00d7][H][\u00d7][T][q]_ _[\u00d7][K]_ [eff] _[\u00d7][D]_ Tiled: _Q_ tiled _\u2190_ tile( _Q, K_ eff) _\u2208_ R _[B][\u00d7][H][\u00d7][T][q]_ _[\u00d7][K]_ [eff] _[\u00d7][D]_ Concatenate: _U_ topk _\u2190_ [ _Q_ tiled; _K_ selected ] _\u2208_ R _[B][\u00d7][H][\u00d7][T][q]_ _[\u00d7][K]_ [eff] _[\u00d7]_ [2] _[D]_ **return** _U_ topk 2.2. Designing the Neural Network We now outline the design of a neural network layer guided by the preceding analysis. The process involves five steps: (i) repurposing NCPs; (ii) input curation; (iii) construction of the time vector ( _t_ ); (iv) computing attention logits and weights; and (v) generating the attention output. Figure 2 provides a graphical overview of NAC. **Repurposing NCPs:** We repurpose the NCPs framework by converting its fixed, biologically derived wiring (see Figure 1(a)) into a flexible recurrent architecture that allows configurable input\u2013output mappings. Instead of enforcing a static connectome, our approach exposes adjacency matrices as modifiable structures defining sparse input and recurrent connections. This enables selective information routing across neuron groups while retaining the original circuit topology. Decoupling wiring specifications from model instantiation allows dynamic connectivity adjustments to accommodate different input modalities without full retraining. Algorithm 1 summarizes the steps for repurposing the NCPs wiring mechanism. Key features include group-wise masking for neuron isolation, adaptive remapping of inputs and outputs for task-specific adaptation, and tunable sparsity _s_ to balance expressiveness and efficiency. In our implementation, the sensory neuron gate ( _NN_ sensory) projects the _q_, _k_, and _v_ representations (see Figure 1(b)). This enables sensory neurons to maintain structured, contextaware representations rather than collapsing inputs into fully connected layers. As a result, the network preserves locality and modularity, which improves information routing. _NN_ sensory = NCPCell( _G_ input = [ _Ns_ ] _, G_ output = [ _Ns_ ] _,_ _D_ = [ _Ni, Nc, Nm_ ] _, s_ ) (13) The inter-to-motor pathways form a backbone network ( _NN_ backbone) with branches that compute _\u03d5_ and _\u03c9\u03c4_ (see Figure 1(c)). Instead of learning _\u03d5_ and _\u03c9\u03c4_ independently, this backbone allows the model to learn shared representations, enabling multiple benefits: (i) separate head layers enable the system to capture temporal and structural dependencies independently; (ii) accelerates convergence during training. _NN_ backbone = NCPCell( _G_ input = [ _Ni_ ] _, G_ output = [ _Nm_ ] _,_ _D_ = [ _Ns_ ] _, s_ ) (14) The output heads are defined as: _\u03d5_ = _\u03c3_ ( _NN_ backbone( **u** )) (15) _\u03c9\u03c4_ = softplus( _NN_ backbone( **u** )) + _\u03b5,_ _\u03b5 >_ 0 (16) Here, _\u03d5_ serves as a _content\u2013target gate_ head, where the sigmoid function _\u03c3_ ( _\u00b7_ ) determines the target signal strength. In contrast, _\u03c9\u03c4_ is a strictly positive _time\u2013constant gate_ head that controls the rate of convergence and the steady-state amplitude. Conceptually, this parallels recurrent gating: _\u03d5_ regulates _what_ content to emphasize, while _\u03c9\u03c4_ governs _how_ _quickly_ and _to what extent_ it is expressed. **Input Curation:** We experimented with different strategies for constructing query\u2013key inputs. Initially, we implemented full pairwise concatenation, where queries _Q \u2208_ R _[B][\u00d7][H][\u00d7][T][q][\u00d7][D]_ are combined with all keys _K_ _\u2208_ R _[B][\u00d7][H][\u00d7][T][k][\u00d7][D]_ to form a joint tensor _U \u2208_ R _[B][\u00d7][H][\u00d7][T][q][\u00d7][T][k][\u00d7]_ [2] _[D]_ . While this preserved complete feature information and enabled expressive, learnable similarity functions, it was memory-intensive, making it impractical for longer sequences. To mitigate this, we applied a sparse Top- _K_ optimization: for each query, we compute pairwise scores _S_ = _Q \u00b7 K_ _[\u22a4]_ _\u2208_ R _[B][\u00d7][H][\u00d7][T][q][\u00d7][T][k]_, select the Top- _K_ eff = min( _K, Tk_ ) keys, and construct concatenated pairs _U_ topk _\u2208_ R _[B][\u00d7][H][\u00d7][T][q][\u00d7][K]_ [eff] _[\u00d7]_ [2] _[D]_ . This approach preserves the most relevant interactions while substantially reducing memory requirements in the concatenation and subsequent backbone processing stages, allowing the method to scale linearly with the sequence length in those components. However, the initial computation of _S_ remains quadratic (see Appendix C.3). Algorithm 2 outlines the steps required for input curation. **Time Vector:** NAC builds on continuous-depth models as (Hasani et al., 2022) that adapt their temporal dynamics to the task. It constructs an internal, normalized pseudo-time vector _t_ pseudo using a sigmoidal transformation, _t_ pseudo = _\u03c3_ ( _ta \u00b7 t_ + _tb_ ), where _ta_ and _tb_ are learnable affine parameters and _\u03c3_ is the sigmoid function. For time-varying datasets (e.g., irregularly sampled series), each time point _t_ is derived from the sample\u2019s timestamp, while for tasks without meaningful timing, _t_ is set to 1. The resulting _t_ pseudo lies in [0 _,_ 1] and provides a smooth, bounded representation of time for modulating the network\u2019s dynamics. 4 **Neuronal Attention Circuit (NAC) for Representation Learning** **Attention logits and weights:** Starting from Eqn. 3, consider the trajectory of a query\u2013key pair with initial condition _a_ 0 = 0: _at_ = _[\u03d5]_ _\u03c9\u03c4_ \ufffd1 _\u2212_ _e_ _[\u2212][\u03c9][\u03c4][ t]_ [\ufffd] _,_ (17) followed by the _softmax_ normalization to calculate attention weights. The resulting attention weights _\u03b1t_ [(] _[h]_ [)] are then used to integrate with the value vector _v_ [(] _[h]_ [)], producing headspecific attention outputs. Finally, these outputs are concatenated and linearly projected back into the model dimension. This formulation ensures that each head learns distinct dynamic compatibilities governed by its own parameterization of _\u03d5_ and _\u03c9\u03c4_, while the aggregation across heads preserves the expressive capacity of the standard multi-head attention mechanism. **2.3. NAC as Universal Approximator** We now establish the universal approximation capability of NAC by extending the classical Universal Approximation Theorem (UAT) (Nishijima, 2021) to the proposed mechanism. For brevity, we consider a network with a single NAC layer processing fixed-dimensional inputs, though the argument generalizes to sequences. **Theorem 2** (Universal Approximation by NAC) **.** _Let K \u2282_ R _[n]_ _be a compact set and f_ : _K \u2192_ R _[m]_ _be a continuous_ _function. For any \u03f5 >_ 0 _, there exists a neural network_ _consisting of a single NAC layer, with sufficiently large_ _model dimension dmodel, number of heads H, sparsity s,_ _and nonlinear activations, such that the network\u2019s output_ _g_ : R _[n]_ _\u2192_ R _[m]_ _satisfies_ sup _\u2225f_ ( _x_ ) _\u2212_ _g_ ( _x_ ) _\u2225_ _< \u03f5._ (20) _x\u2208K_ _The proof is provided in Appendix B.3._ **3. Evaluation** We evaluate the proposed architecture against a range of baselines, including (DT & CT) RNN, (DT & CT) attention, and multiple NAC ablation configurations. Experiments are conducted across diverse domains, including irregular time-series modeling, lane keeping of autonomous vehicles, and Industry 4.0 prognostics. All results are obtained using 5-fold cross-validation, where models are trained using BPTT (see Appendix C.2) on each fold and evaluated across all folds. We report the mean ( _\u00b5_ ) and standard deviation ( _\u03c3_ ) to capture variability and quantify uncertainty in the predictions. Table 1 provides results for all experiments, and the details of the baselines, ablation, environment utilized, the data curation and preprocessing, and neural network architectures for all experiments are provided in the Appendix D.3. **3.1. Irregular Time-series** We evaluate the proposed architecture on two irregular time-series datasets: (i) Event-based MNIST; and (ii) Person Activity Recognition (PAR). For finite _t_, the exponential factor (1 _\u2212_ _e_ _[\u2212][\u03c9][\u03c4][ t]_ ) regulates the buildup of attention, giving _\u03c9\u03c4_ a temporal gating role. Normalizing across all keys via _softmax_ yields attention weights _\u03b1t_ = softmax( _at_ ), defining a valid probability distribution where _\u03d5_ amplifies or suppresses content alignments, and _\u03c9\u03c4_ shapes both the speed and saturation of these preferences. As _t \u2192\u221e_, the trajectory converges to the steady state _a_ _[\u2217]_ _t_ [=] _[\u03d5]_ _\u2248_ _[q][\u22a4][k]_ _,_ (18) _\u03c9\u03c4_ ~~_\u221a_~~ _dk_ which is analogous to scaled-dot attention under specific parameterization when the backbone _NN_ backbone is configured as a linear projection such that _\u03d5_ ( **u** ) = _q_ _[\u22a4]_ _k_ and _\u03c9\u03c4_ ( _u_ ) = _[\u221a]_ _dk_ (e.g., by setting NCP weights to emulate bilinear forms and disabling nonlinearities). In general, the nonlinear backbone allows for more expressive similarities, with the approximation holding when trained to mimic dot products. **Attention output:** Finally, the attention output is computed by integrating the attention weights with the value matrix: NAC( _q, k, v_ ) = _\u03b1tvtdt_ (19) _T_ In practice, the integration is approximated using a Riemannstyle approach, where the weighted elements are computed by multiplying each _vt_ with its corresponding _\u03b1t_ . These are then summed and multiplied by a fixed pseudo-time step _\u03b4t_, chosen as a scalar (typically between 0.5\u20131.0) hyperparameter during layer initialization. This yields a continuous analogue of standard weighted sums, giving finer resolution of the attention trajectory without altering the underlying values. Sensitivity to attention output w.r.t _\u03b4t_ is visualized in Appendix D.2. 2.2.1. EXTENSION TO MULTI-HEAD To scale this mechanism to multi-head attention, we project the input sequence into _H_ independent subspaces (heads) of dimension _d_ model _/H_, yielding query, key, and value tensors ( _q_ [(] _[h]_ [)] _, k_ [(] _[h]_ [)] _, v_ [(] _[h]_ [)] ) for _h \u2208{_ 1 _, . . ., H}_ . For each head, pairwise logits are computed according to Eqns. 2,3 or 18, followed by the _softmax_ normalization to calculate attention weights. The resulting attention weights _\u03b1t_ [(] _[h]_ [)] are then used to integrate with the value vector _v_ [(] _[h]_ [)], producing headspecific attention outputs. Finally, these outputs are concatenated and linearly projected back into the model dimension. This formulation ensures that each head learns distinct dynamic compatibilities governed by its own parameterization of _\u03d5_ and _\u03c9\u03c4_, while the aggregation across heads preserves the expressive capacity of the standard multi-head attention mechanism. 5 **Neuronal Attention Circuit (NAC) for Representation Learning** _Figure 2._ Illustration of the architecture of **(a)** Neuronal Attention Circuit mechanism ; **(b)** Multi-Head Extension ![](E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/neuronal_attention_circuits.pdf-5-0.png) **Event-based MNIST:** Event-based MNIST is the trans formation of the widely recognized MNIST dataset with irregular sampling added originally proposed in (Lechner & Hasani, 2022). The transformation was done in two steps: (i) flattening each 28\u00d728 image into a time series of length 784, and (ii) encoding the binary time series into an event-based format by collapsing consecutive identical values (e.g., 1,1,1,1 \u2192 (1, t=4)). This representation requires models to handle temporal dependencies effectively. NAC-PW achieved first place with an accuracy of 96.64%, followed by NAC-Exact/05s/8k at 96.12%. GRU-ODE and ContiFormer ranked third with 96.04%. **Person Activity Recognition (PAR):** We employed the Localized Person Activity dataset from UC Irvine (Vidulin et al., 2010). The dataset contains data from five participants, each equipped with inertial measurement sensors sampled every 211 ms. The goal of this experiment is to predict a person\u2019s activity from a set of predefined actions, making it a classification task. All models performed well on this task, with NAC-PW achieving 89.15% accuracy and taking first place. NAC-Exact/05s/8k and GRU-ODE ranked second with 89.01% accuracy, while NAC-02s ranked third with 88.84% mean accuracy. **3.2. Lane-Keeping of Autonomous Vehicles** Lane keeping in autonomous vehicles (AVs) is a fundamental problem in robotics and AI. Early works (Tiang et al., 2018; Park et al., 2021) primarily emphasized accuracy, often relying on large models. More recent research (Lechner et al., 2020; Razzaq & Hongwei, 2023) has shifted toward designing compact architectures suitable for resource-constrained devices. The goal of this experiment is to create a long causal structure between the road\u2019s horizon and the corresponding steering commands. To evaluate, we used two widely adopted simulation environments: (i) OpenAI CarRacing (Brockman et al., 2016); and (ii) the Udacity Self-Driving Car Simulator (uda). In OpenAI CarRacing, the task is to classify steering actions from a predefined action set. In contrast, the Udacity Simulator requires predicting a continuous trajectory of steering values. We implemented the AI models proposed by (Razzaq & Hongwei, 2023), replacing the recurrent layer with NAC and its counterparts. All models achieved around 80% accuracy on average in the CarRacing benchmark. Notably, NAC-PW performed the best, reaching the highest accuracy of 80.72%, followed by NAC-Steady, ranked second with 80.62%. LSTM and GRU took third position, achieving 80.60% on average. In the Udacity benchmark, NAC-32k performed the best, achieving the lowest MSE of 0.0170. NAC-Exact followed with 0.0173, and ContiFormer ranked third with 0.0174. To visualize saliency maps for these experiments, refer to Appendix D.3.3. Experimental videos are available for the [OpenAI CarRacing [click here] and for the Udacity Simula-](https://www.youtube.com/watch?v=kwTNU8aV8-I) [tor [click here].](https://www.youtube.com/watch?v=mMRVsNUQ8i0) **3.3. Industry 4.0**", "metadata": [{"key": "chunk_id", "value": "1"}]}}
{"nodes": [{"id": "Lane-Keeping for Autonomous Vehicles", "type": "Problem"}, {"id": "Robotics", "type": "Field"}, {"id": "AI", "type": "Field"}, {"id": "Tiang et al., 2018", "type": "Work"}, {"id": "Park et al., 2021", "type": "Work"}, {"id": "Accuracy", "type": "Metric"}, {"id": "Large Models", "type": "Model Type"}, {"id": "Recent Research", "type": "Concept"}, {"id": "Lechner et al., 2020", "type": "Work"}, {"id": "Razzaq & Hongwei, 2023", "type": "Work"}, {"id": "Compact Architectures", "type": "Concept"}, {"id": "Resource-Constrained Devices", "type": "Concept"}, {"id": "Experiment", "type": "Event"}, {"id": "Causal Structure", "type": "Concept"}, {"id": "Road's Horizon", "type": "Concept"}, {"id": "Steering Commands", "type": "Concept"}, {"id": "Evaluation", "type": "Process"}, {"id": "OpenAI CarRacing", "type": "Simulator"}, {"id": "Brockman et al., 2016", "type": "Work"}, {"id": "Udacity Self-Driving Car Simulator", "type": "Simulator"}, {"id": "Classification Task", "type": "Task"}, {"id": "Steering Actions", "type": "Concept"}, {"id": "Predicting Steering Values", "type": "Task"}, {"id": "Steering Values", "type": "Concept"}, {"id": "AI Models", "type": "Model Type"}, {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, {"id": "Recurrent Layer", "type": "Component"}, {"id": "CarRacing Benchmark", "type": "Benchmark"}, {"id": "NAC-PW", "type": "Model"}, {"id": "First Place", "type": "Rank"}, {"id": "NAC-Steady", "type": "Model"}, {"id": "Second Place", "type": "Rank"}, {"id": "LSTM", "type": "Model"}, {"id": "GRU", "type": "Model"}, {"id": "Third Place", "type": "Rank"}, {"id": "Udacity Benchmark", "type": "Benchmark"}, {"id": "NAC-32k", "type": "Model"}, {"id": "MSE", "type": "Metric"}, {"id": "NAC-Exact", "type": "Model"}, {"id": "ContiFormer", "type": "Model"}, {"id": "Saliency Maps", "type": "Concept"}, {"id": "Experiments", "type": "Concept"}, {"id": "Appendix D.3.3", "type": "Document Section"}, {"id": "Experimental Videos", "type": "Resource"}, {"id": "Industry 4.0", "type": "Concept"}, {"id": "Manufacturing", "type": "Industry"}, {"id": "Prognostic Health Management (PHM) Systems", "type": "System"}, {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, {"id": "Components", "type": "Concept"}, {"id": "Rolling Element Bearings (REB)", "type": "Component"}, {"id": "Machine Failures", "type": "Event"}, {"id": "Ding et al., 2021", "type": "Work"}, {"id": "Zhuang et al., 2021", "type": "Work"}, {"id": "Objective", "type": "Concept"}, {"id": "Degradation Features", "type": "Concept"}, {"id": "Operating Condition", "type": "Concept"}, {"id": "Dataset", "type": "Concept"}, {"id": "Unseen Conditions", "type": "Concept"}, {"id": "Model", "type": "Concept"}, {"id": "Accurate RUL Estimation", "type": "Task"}, {"id": "Different Datasets", "type": "Dataset Type"}, {"id": "Localized Safety", "type": "Concept"}, {"id": "Benchmark Datasets", "type": "Dataset Type"}, {"id": "PRONOSTIA", "type": "Dataset"}, {"id": "Nectoux et al., 2012", "type": "Work"}, {"id": "XJTU-SY", "type": "Dataset"}, {"id": "Wang et al., 2018", "type": "Work"}, {"id": "HUST", "type": "Dataset"}, {"id": "Thuan & Hong, 2023", "type": "Work"}, {"id": "Training", "type": "Process"}, {"id": "Cross-Validation", "type": "Process"}, {"id": "Score Metric", "type": "Metric"}, {"id": "Performance", "type": "Concept"}, {"id": "Generalization", "type": "Concept"}, {"id": "Bearing 1", "type": "Component"}, {"id": "Figure 3", "type": "Figure"}, {"id": "Expected Degradation", "type": "Concept"}, {"id": "NAC-Exact/05s/8k", "type": "Model"}, {"id": "NAC-FC", "type": "Model"}, {"id": "Results", "type": "Concept"}, {"id": "Cross-Validation Capability", "type": "Concept"}, {"id": "Computational Requirements", "type": "Concept"}, {"id": "Fixed-Length Sequences", "type": "Concept"}, {"id": "Google Colab T4-GPU", "type": "Hardware"}, {"id": "Runtime", "type": "Metric"}, {"id": "Throughput", "type": "Metric"}, {"id": "Peak Memory Usage", "type": "Metric"}, {"id": "CT-RNN Models", "type": "Model Type"}, {"id": "GRU-ODE", "type": "Model"}, {"id": "CfC", "type": "Model"}, {"id": "LTC", "type": "Model"}, {"id": "Memory Consumption", "type": "Metric"}, {"id": "mTAN", "type": "Model"}, {"id": "NAC-2k", "type": "Model"}, {"id": "CT-Attention Models", "type": "Model Type"}, {"id": "NAC Sparsity", "type": "Property"}, {"id": "Memory", "type": "Metric"}, {"id": "Top-K Selection", "type": "Property"}, {"id": "Flexibility of NAC", "type": "Concept"}, {"id": "Sparsity of NAC Layer", "type": "Property"}, {"id": "Robustness", "type": "Concept"}, {"id": "Top-K Interactions", "type": "Concept"}, {"id": "Benefits", "type": "Concept"}, {"id": "Exact Mode", "type": "Mode"}, {"id": "Efficiency", "type": "Metric"}, {"id": "Top-K=8", "type": "Setting"}, {"id": "50% Sparsity", "type": "Setting"}, {"id": "Steady Mode", "type": "Mode"}, {"id": "Euler Mode", "type": "Mode"}, {"id": "Adaptive Temporal Dynamics", "type": "Concept"}, {"id": "Research", "type": "Concept"}, {"id": "Biologically Plausible Attention Mechanisms", "type": "Concept"}, {"id": "Limitations", "type": "Concept"}, {"id": "Future Work", "type": "Concept"}], "relationships": [{"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Problem"}, "target": {"id": "Robotics", "type": "Field"}, "type": "IS_PROBLEM_IN"}, {"source": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Problem"}, "target": {"id": "AI", "type": "Field"}, "type": "IS_PROBLEM_IN"}, {"source": {"id": "Tiang et al., 2018", "type": "Work"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "EMPHASIZED"}, {"source": {"id": "Park et al., 2021", "type": "Work"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "EMPHASIZED"}, {"source": {"id": "Tiang et al., 2018", "type": "Work"}, "target": {"id": "Large Models", "type": "Model Type"}, "type": "RELIED_ON"}, {"source": {"id": "Park et al., 2021", "type": "Work"}, "target": {"id": "Large Models", "type": "Model Type"}, "type": "RELIED_ON"}, {"source": {"id": "Recent Research", "type": "Concept"}, "target": {"id": "Lechner et al., 2020", "type": "Work"}, "type": "INCLUDES"}, {"source": {"id": "Recent Research", "type": "Concept"}, "target": {"id": "Razzaq & Hongwei, 2023", "type": "Work"}, "type": "INCLUDES"}, {"source": {"id": "Recent Research", "type": "Concept"}, "target": {"id": "Compact Architectures", "type": "Concept"}, "type": "SHIFTED_TOWARD_DESIGNING"}, {"source": {"id": "Compact Architectures", "type": "Concept"}, "target": {"id": "Resource-Constrained Devices", "type": "Concept"}, "type": "SUITABLE_FOR"}, {"source": {"id": "Experiment", "type": "Event"}, "target": {"id": "Causal Structure", "type": "Concept"}, "type": "SEEKS_TO_CREATE"}, {"source": {"id": "Road's Horizon", "type": "Concept"}, "target": {"id": "Steering Commands", "type": "Concept"}, "type": "HAS_CAUSAL_STRUCTURE_TO"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "OpenAI CarRacing", "type": "Simulator"}, "type": "USED"}, {"source": {"id": "OpenAI CarRacing", "type": "Simulator"}, "target": {"id": "Brockman et al., 2016", "type": "Work"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Evaluation", "type": "Process"}, "target": {"id": "Udacity Self-Driving Car Simulator", "type": "Simulator"}, "type": "USED"}, {"source": {"id": "OpenAI CarRacing", "type": "Simulator"}, "target": {"id": "Classification Task", "type": "Task"}, "type": "INVOLVES_TASK"}, {"source": {"id": "Classification Task", "type": "Task"}, "target": {"id": "Steering Actions", "type": "Concept"}, "type": "CLASSIFIES"}, {"source": {"id": "Udacity Self-Driving Car Simulator", "type": "Simulator"}, "target": {"id": "Predicting Steering Values", "type": "Task"}, "type": "REQUIRES"}, {"source": {"id": "Predicting Steering Values", "type": "Task"}, "target": {"id": "Steering Values", "type": "Concept"}, "type": "PREDICTS"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "Razzaq & Hongwei, 2023", "type": "Work"}, "type": "PROPOSED_BY"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "USES_REPLACEMENT"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "Recurrent Layer", "type": "Component"}, "type": "REPLACES"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "AI Models", "type": "Model Type"}, "target": {"id": "CarRacing Benchmark", "type": "Benchmark"}, "type": "EVALUATED_ON"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "CarRacing Benchmark", "type": "Benchmark"}, "type": "PERFORMED_BEST_IN"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "First Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "NAC-Steady", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-Steady", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "NAC-32k", "type": "Model"}, "target": {"id": "Udacity Benchmark", "type": "Benchmark"}, "type": "PERFORMED_BEST_ON"}, {"source": {"id": "NAC-32k", "type": "Model"}, "target": {"id": "MSE", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "NAC-32k", "type": "Model"}, "type": "FOLLOWED"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "MSE", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "MSE", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "Saliency Maps", "type": "Concept"}, "target": {"id": "Experiments", "type": "Concept"}, "type": "VISUALIZE"}, {"source": {"id": "Saliency Maps", "type": "Concept"}, "target": {"id": "Appendix D.3.3", "type": "Document Section"}, "type": "REFERENCED_IN"}, {"source": {"id": "Experimental Videos", "type": "Resource"}, "target": {"id": "OpenAI CarRacing", "type": "Simulator"}, "type": "AVAILABLE_FOR"}, {"source": {"id": "Experimental Videos", "type": "Resource"}, "target": {"id": "Udacity Self-Driving Car Simulator", "type": "Simulator"}, "type": "AVAILABLE_FOR"}, {"source": {"id": "Industry 4.0", "type": "Concept"}, "target": {"id": "Manufacturing", "type": "Industry"}, "type": "TRANSFORMED"}, {"source": {"id": "Industry 4.0", "type": "Concept"}, "target": {"id": "Prognostic Health Management (PHM) Systems", "type": "System"}, "type": "MAKES_ESSENTIAL"}, {"source": {"id": "Prognostic Health Management (PHM) Systems", "type": "System"}, "target": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "type": "INCLUDES_TASK"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "Components", "type": "Concept"}, "type": "APPLIES_TO"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "Rolling Element Bearings (REB)", "type": "Component"}, "type": "APPLIES_TO"}, {"source": {"id": "Rolling Element Bearings (REB)", "type": "Component"}, "target": {"id": "Machine Failures", "type": "Event"}, "type": "ACCOUNT_FOR"}, {"source": {"id": "Ding et al., 2021", "type": "Work"}, "target": {"id": "Machine Failures", "type": "Event"}, "type": "CITES"}, {"source": {"id": "Zhuang et al., 2021", "type": "Work"}, "target": {"id": "Machine Failures", "type": "Event"}, "type": "CITES"}, {"source": {"id": "Objective", "type": "Concept"}, "target": {"id": "Degradation Features", "type": "Concept"}, "type": "LEARNS"}, {"source": {"id": "Objective", "type": "Concept"}, "target": {"id": "Unseen Conditions", "type": "Concept"}, "type": "GENERALIZES_TO"}, {"source": {"id": "Degradation Features", "type": "Concept"}, "target": {"id": "Operating Condition", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "Operating Condition", "type": "Concept"}, "target": {"id": "Dataset", "type": "Concept"}, "type": "OF"}, {"source": {"id": "Unseen Conditions", "type": "Concept"}, "target": {"id": "Dataset", "type": "Concept"}, "type": "WITHIN"}, {"source": {"id": "Model", "type": "Concept"}, "target": {"id": "Accurate RUL Estimation", "type": "Task"}, "type": "PROVIDES"}, {"source": {"id": "Accurate RUL Estimation", "type": "Task"}, "target": {"id": "Different Datasets", "type": "Dataset Type"}, "type": "ON"}, {"source": {"id": "Model", "type": "Concept"}, "target": {"id": "Compact Architectures", "type": "Concept"}, "type": "MAINTAINS"}, {"source": {"id": "Compact Architectures", "type": "Concept"}, "target": {"id": "Resource-Constrained Devices", "type": "Concept"}, "type": "SUITABLE_FOR"}, {"source": {"id": "Compact Architectures", "type": "Concept"}, "target": {"id": "Localized Safety", "type": "Concept"}, "type": "SUPPORTS"}, {"source": {"id": "Benchmark Datasets", "type": "Dataset Type"}, "target": {"id": "PRONOSTIA", "type": "Dataset"}, "type": "INCLUDES"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "Nectoux et al., 2012", "type": "Work"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Benchmark Datasets", "type": "Dataset Type"}, "target": {"id": "XJTU-SY", "type": "Dataset"}, "type": "INCLUDES"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Wang et al., 2018", "type": "Work"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Benchmark Datasets", "type": "Dataset Type"}, "target": {"id": "HUST", "type": "Dataset"}, "type": "INCLUDES"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Thuan & Hong, 2023", "type": "Work"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Training", "type": "Process"}, "target": {"id": "PRONOSTIA", "type": "Dataset"}, "type": "PERFORMED_ON"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Cross-Validation", "type": "Process"}, "type": "USED_FOR"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Cross-Validation", "type": "Process"}, "type": "USED_FOR"}, {"source": {"id": "Score Metric", "type": "Metric"}, "target": {"id": "Nectoux et al., 2012", "type": "Work"}, "type": "INTRODUCED_BY"}, {"source": {"id": "Score Metric", "type": "Metric"}, "target": {"id": "Performance", "type": "Concept"}, "type": "ASSESSES"}, {"source": {"id": "Generalization", "type": "Concept"}, "target": {"id": "Bearing 1", "type": "Component"}, "type": "EVALUATED_USING"}, {"source": {"id": "Bearing 1", "type": "Component"}, "target": {"id": "Operating Condition", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "Figure 3", "type": "Figure"}, "target": {"id": "Expected Degradation", "type": "Concept"}, "type": "VISUALIZES"}, {"source": {"id": "Figure 3", "type": "Figure"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "VISUALIZES_OUTPUTS_OF"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "PRONOSTIA", "type": "Dataset"}, "type": "PERFORMED_BEST_ON"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "XJTU-SY", "type": "Dataset"}, "type": "PERFORMED_BEST_ON"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-FC", "type": "Model"}, "target": {"id": "Second Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "NAC-FC", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Third Place", "type": "Rank"}, "type": "RANKED"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "HUST", "type": "Dataset"}, "type": "ACHIEVED_FIRST_PLACE_ON"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "HUST", "type": "Dataset"}, "type": "RANKED_SECOND_ON"}, {"source": {"id": "NAC-PW", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "NAC-FC", "type": "Model"}, "target": {"id": "HUST", "type": "Dataset"}, "type": "RANKED_THIRD_ON"}, {"source": {"id": "NAC-FC", "type": "Model"}, "target": {"id": "Score Metric", "type": "Metric"}, "type": "ACHIEVED"}, {"source": {"id": "Results", "type": "Concept"}, "target": {"id": "Cross-Validation Capability", "type": "Concept"}, "type": "DEMONSTRATED"}, {"source": {"id": "Cross-Validation Capability", "type": "Concept"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "type": "OF"}, {"source": {"id": "Computational Requirements", "type": "Concept"}, "target": {"id": "Fixed-Length Sequences", "type": "Concept"}, "type": "EVALUATED_ON"}, {"source": {"id": "Model", "type": "Concept"}, "target": {"id": "Google Colab T4-GPU", "type": "Hardware"}, "type": "RUN_ON"}, {"source": {"id": "Experiment", "type": "Event"}, "target": {"id": "Runtime", "type": "Metric"}, "type": "REPORTS"}, {"source": {"id": "Experiment", "type": "Event"}, "target": {"id": "Throughput", "type": "Metric"}, "type": "REPORTS"}, {"source": {"id": "Experiment", "type": "Event"}, "target": {"id": "Peak Memory Usage", "type": "Metric"}, "type": "REPORTS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "CT-RNN Models", "type": "Model Type"}, "type": "HAS_INTERMEDIATE_RUNTIME_RELATIVE_TO"}, {"source": {"id": "CT-RNN Models", "type": "Model Type"}, "target": {"id": "GRU-ODE", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "CT-RNN Models", "type": "Model Type"}, "target": {"id": "CfC", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "CT-RNN Models", "type": "Model Type"}, "target": {"id": "LTC", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Model"}, "target": {"id": "mTAN", "type": "Model"}, "type": "USES_LESS_MEMORY_THAN"}, {"source": {"id": "NAC-2k", "type": "Model"}, "target": {"id": "CT-Attention Models", "type": "Model Type"}, "type": "HAS_LEAST_MEMORY_CONSUMPTION_AMONG"}, {"source": {"id": "Reducing NAC Sparsity", "type": "Concept"}, "target": {"id": "Memory", "type": "Metric"}, "type": "HAS_MINIMAL_EFFECT_ON"}, {"source": {"id": "Decreasing Top-K Selection", "type": "Concept"}, "target": {"id": "Memory Consumption", "type": "Metric"}, "type": "REDUCES"}, {"source": {"id": "Reduction", "type": "Concept"}, "target": {"id": "Flexibility of NAC", "type": "Concept"}, "type": "DEMONSTRATES"}, {"source": {"id": "Increasing Sparsity of NAC Layer", "type": "Property"}, "target": {"id": "Robustness", "type": "Concept"}, "type": "IMPROVES"}, {"source": {"id": "Increasing Sparsity of NAC Layer", "type": "Property"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "LEADS_TO"}, {"source": {"id": "Increasing Top-K Interactions", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ENHANCES"}, {"source": {"id": "Benefits", "type": "Concept"}, "target": {"id": "Memory Consumption", "type": "Metric"}, "type": "DIMINISH_WITH"}, {"source": {"id": "Exact Mode", "type": "Mode"}, "target": {"id": "Accuracy", "type": "Metric"}, "type": "ACHIEVES_BALANCE_BETWEEN"}, {"source": {"id": "Exact Mode", "type": "Mode"}, "target": {"id": "Efficiency", "type": "Metric"}, "type": "ACHIEVES_BALANCE_BETWEEN"}, {"source": {"id": "Exact Mode", "type": "Mode"}, "target": {"id": "Top-K=8", "type": "Setting"}, "type": "USES"}, {"source": {"id": "Exact Mode", "type": "Mode"}, "target": {"id": "50% Sparsity", "type": "Setting"}, "type": "USES"}, {"source": {"id": "Steady Mode", "type": "Mode"}, "target": {"id": "Fastest", "type": "Concept"}, "type": "IS"}, {"source": {"id": "Euler Mode", "type": "Mode"}, "target": {"id": "Adaptive Temporal Dynamics", "type": "Concept"}, "type": "HANDLES"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "Biologically Plausible Attention Mechanisms", "type": "Concept"}, "type": "PART_OF"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "Limitations", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Limitations", "type": "Concept"}, "target": {"id": "Future Work", "type": "Concept"}, "type": "ADDRESSED_IN"}], "source": {"page_content": "3.2. Lane-Keeping of Autonomous Vehicles\n\n\nLane keeping in autonomous vehicles (AVs) is a fundamental problem in robotics and AI. Early works (Tiang et al.,\n2018; Park et al., 2021) primarily emphasized accuracy,\noften relying on large models. More recent research (Lechner et al., 2020; Razzaq & Hongwei, 2023) has shifted toward designing compact architectures suitable for resourceconstrained devices. The goal of this experiment is to create\na long causal structure between the road\u2019s horizon and the\n\n\n\ncorresponding steering commands. To evaluate, we used\ntwo widely adopted simulation environments: (i) OpenAI\nCarRacing (Brockman et al., 2016); and (ii) the Udacity SelfDriving Car Simulator (uda). In OpenAI CarRacing, the\ntask is to classify steering actions from a predefined action\nset. In contrast, the Udacity Simulator requires predicting a\ncontinuous trajectory of steering values. We implemented\nthe AI models proposed by (Razzaq & Hongwei, 2023),\nreplacing the recurrent layer with NAC and its counterparts.\nAll models achieved around 80% accuracy on average in\nthe CarRacing benchmark. Notably, NAC-PW performed\nthe best, reaching the highest accuracy of 80.72%, followed\nby NAC-Steady, ranked second with 80.62%. LSTM and\nGRU took third position, achieving 80.60% on average.\nIn the Udacity benchmark, NAC-32k performed the best,\nachieving the lowest MSE of 0.0170. NAC-Exact followed\nwith 0.0173, and ContiFormer ranked third with 0.0174.\nTo visualize saliency maps for these experiments, refer to\nAppendix D.3.3. Experimental videos are available for the\n[OpenAI CarRacing [click here] and for the Udacity Simula-](https://www.youtube.com/watch?v=kwTNU8aV8-I)\n[tor [click here].](https://www.youtube.com/watch?v=mMRVsNUQ8i0)\n\n\n3.3. Industry 4.0\n\n\nIndustry 4.0 has transformed manufacturing, making prognostic health management (PHM) systems essential. A key\nPHM task is estimating the remaining useful life (RUL) of\ncomponents, particularly rolling element bearings (REB),\nwhich account for 40\u201350% of machine failures (Ding et al.,\n2021; Zhuang et al., 2021). The objective is to learn degradation features from one operating condition of a dataset\nand generalize to unseen conditions within the same dataset.\nFurthermore, the model should provide accurate RUL estimation on entirely different datasets, while maintaining a\n\n\n\n6\n\n\nNeuronal Attention Circuit (NAC) for Representation Learning\n\n\n_Table 1._ Model Performance Across All Categories and Datasets\n\n\nIrregular Time-Series Lane-Keeeping of AVs Industry 4.0\nModel\n\nE-MNIST (\u2191) PAR (\u2191) CarRacing (\u2191) Udacity (\u2193) PRONOSTIA (\u2193) XJTU-SY (\u2193) HUST (\u2193)\n\n\nRNN 95.59 [\u00b1] [0.37] 88.77 [\u00b1] [0.58] 78.90 [\u00b1] [3.35] 0.0210 [\u00b1] [0.0014] 42.05 [\u00b1] [7.49] 31.07 [\u00b1] [6.63] 42.22 [\u00b1] [8.16]\n\nLSTM 95.88 [\u00b1] [0.23] 88.36 [\u00b1] [0.79] 80.60 [\u00b1] [0.12] 0.0181 [\u00b1] [0.0014] 41.87 [\u00b1] [2.88] 31.99 [\u00b1] [8.32] 44.09 [\u00b1] [2.14]\n\nGRU 95.85 [\u00b1] [0.22] 88.68 [\u00b1] [1.35] 80.60 [\u00b1] [0.22] 0.0206 [\u00b1] [0.0014] 44.22 [\u00b1] [4.60] 26.65 [\u00b1] [4.49] 41.86 [\u00b1] [7.96]\n\nCT-RNN 95.18 [\u00b1] [0.20] 88.71 [\u00b1] [0.87] 80.21 [\u00b1] [0.27] 0.0206 [\u00b1] [0.0013] 44.32 [\u00b1] [8.69] 26.01 [\u00b1] [8.74] 39.99 [\u00b1] [6.33]\n\nGRU-ODE **96.04** [\u00b1] **[0.13]** **89.01** [\u00b1] **[1.55]** 80.29 [\u00b1] [0.72] 0.0188 [\u00b1] [0.0016] 45.11 [\u00b1] [3.19] 31.20 [\u00b1] [8.69] 43.91 [\u00b1] [7.10]\n\nPhasedLSTM 95.79 [\u00b1] [0.14] 88.93 [\u00b1] [1.08] 80.35 [\u00b1] [0.38] 0.0186 [\u00b1] [0.0015] 44.15 [\u00b1] [4.80] 35.49 [\u00b1] [5.54] 38.66 [\u00b1] [5.55]\n\nmmRNN 95.74 [\u00b1] [0.27] 88.48 [\u00b1] [0.46] 80.13 [\u00b1] [0.54] 0.0205 [\u00b1] [0.0027] 48.50 [\u00b1] [4.60] 27.84 [\u00b1] [4.05] 40.11 [\u00b1] [9.56]\n\nLTC 95.25 [\u00b1] [0.00] 88.12 [\u00b1] [0.68] 76.37 [\u00b1] [3.01] 0.0245 [\u00b1] [0.0024] 48.14 [\u00b1] [5.01] 36.83 [\u00b1] [8.57] 61.82 [\u00b1] [15.64]\n\nCfC 94.16 [\u00b1] [0.49] 88.60 [\u00b1] [0.34] 80.59 [\u00b1] [0.33] 0.0198 [\u00b1] [0.0022] 47.78 [\u00b1] [3.54] 35.51 [\u00b1] [3.94] 54.09 [\u00b1] [10.13]\n\nAttention 95.68 [\u00b1] [0.23] 88.29 [\u00b1] [0.98] 80.40 [\u00b1] [0.26] 0.0193 [\u00b1] [0.0009] 41.89 [\u00b1] [6.98] 26.29 [\u00b1] [4.06] 40.28 [\u00b1] [4.23]\n\nMHA 95.94 [\u00b1] [0.15] 88.36 [\u00b1] [1.06] 79.99 [\u00b1] [0.49] 0.0185 [\u00b1] [0.0017] 45.36 [\u00b1] [5.16] 37.31 [\u00b1] [12.20] 41.40 [\u00b1] [7.72]\n\nmTAN 95.97 [\u00b1] [0.25] 88.08 [\u00b1] [0.94] 80.86 [\u00b1] [0.22] 0.0178 [\u00b1] [0.0005] 44.41 [\u00b1] [7.15] 41.34 [\u00b1] [3.72] 66.29 [\u00b1] [4.25]\n\nCTA 95.86 [\u00b1] [0.14] 88.10 [\u00b1] [1.10] 80.54 [\u00b1] [0.40] 0.0197 [\u00b1] [0.0016] 39.16 [\u00b1] [3.54] **25.86** [\u00b1] [1.47] 38.41 [\u00b1] [4.51]\n\nODEFormer 95.62 [\u00b1] [0.20] 88.25 [\u00b1] [0.66] 80.54 [\u00b1] [0.40] 0.0190 [\u00b1] [0.0012] 42.42 [\u00b1] [6.98] 35.63 [\u00b1] [9.24] 40.60 [\u00b1] [6.83]\n\nContiFormer **96.04** [\u00b1] **[0.23]** 81.28 [\u00b1] [0.85] 80.47 [\u00b1] [0.50] **0.0174** [\u00b1] **[0.01]** **27.82** [\u00b1] **[7.09]** 34.71 [\u00b1] [4.98] 43.81 [\u00b1] [10.18]\n\n\nNAC-2k 95.73 [\u00b1] [0.07] 88.84% [\u00b1] [0.81] 80.59 [\u00b1] [0.46] 0.0208 [\u00b1] [0.0015] 43.78 [\u00b1] [2.71] 37.43 [\u00b1] [9.28] 40.51 [\u00b1] [6.61]\n\nNAC-32k 95.15 [\u00b1] [0.11] 88.80 [\u00b1] [0.76] 80.38 [\u00b1] [0.16] **0.0170** [\u00b1] **[0.0007]** 49.53 [\u00b1] [4.89] 32.45 [\u00b1] [10.84] 39.17 [\u00b1] [12.23]\n\nNAC-PW **96.64** [\u00b1] [0.12] **89.15** [\u00b1] **[1.01]** **80.72** [\u00b1] **[0.41]** 0.0177 [\u00b1] [0.0008] **37.50** [\u00b1] **[2.56]** 28.01 [\u00b1] [4.93] **30.14** [\u00b1] **[6.87]**\n\n\nNAC-FC 95.31 [\u00b1] [0.07] 88.45 [\u00b1] [0.91] 80.49 [\u00b1] [0.46] 0.0192 [\u00b1] [0.0012] 40.36 [\u00b1] [6.09] **24.89** [\u00b1] **[5.30]** **35.35** [\u00b1] **[6.64]**\n\nNAC-02s 95.31 [\u00b1] [0.07] 88.84 [\u00b1] [1.33] 80.47 [\u00b1] [0.27] 0.0188 [\u00b1] [0.0013] 39.43 [\u00b1] [5.94] 35.59 [\u00b1] [3.86] 38.90 [\u00b1] [6.43]\n\nNAC-09s 95.86 [\u00b1] [0.11] 88.61% [\u00b1] [1.25] 80.43% [\u00b1] [0.17] 0.0188 [\u00b1] [0.0013] 47.29 [\u00b1] [5.52] 40.40 [\u00b1] [8.85] 44.39 [\u00b1] [6.82]\n\n\nNAC-Exact/05s/8k **96.12** [\u00b1] [0.11] **89.01** [\u00b1] **[1.01]** 80.59 [\u00b1] [1.82] **0.0173** [\u00b1] **[0.0006]** **37.75** [\u00b1] **[4.72]** **19.87** [\u00b1] **[1.75]** **27.82** [\u00b1] **[7.09]**\n\nNAC-Euler 95.67 [\u00b1] [0.26] 88.52 [\u00b1] [0.68] **80.61** [\u00b1] [0.28] 0.0181 [\u00b1] [0.0017] 42.08 [\u00b1] [6.14] 28.46 [\u00b1] [8.18] 39.32 [\u00b1] [9.15]\n\nNAC-Steady 95.75 [\u00b1] [0.28] 88.36 [\u00b1] [1.05] **80.62** [\u00b1] **[0.26]** 0.0181 [\u00b1] [0.0012] 40.95 [\u00b1] [5.77] 26.76 [\u00b1] [7.36] 37.12 [\u00b1] [12.43]\n\n\nNote: (\u2191) higher is better; (\u2193) lower is better.\n\n\nthe lowest score of 27.82. NAC-Exact/05s/8k and NAC-PW\n\nachieved nearly identical scores, obtaining 37.75 and 37.50\non average, respectively. On the XJTU-SY dataset, NACExact/05s/8k has the lowest score of 19.87. NAC-FC ranked\n\nsecond with a score of 24.89, followed by NAC-PW in third\nplace with an average score of 28.01. A similar trend was\nobserved on the HUST dataset, where NAC-Exact/05s/8k\nachieved first place with a score of 27.82, NAC-PW ranked\nsecond with 30.14, and NAC-FC ranked third with 35.35.\nThese results demonstrated the strong cross-validation capability of NAC.\n\n\n\n![](E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/neuronal_attention_circuits.pdf-6-0.png)\n\n_Figure 3._ Degradation Estimation Results.\n\n\ncompact architecture suitable for resource-constrained devices, thereby supporting localized safety.\nWe utilized three benchmark datasets: (i) PRONOSTIA\n(Nectoux et al., 2012), (ii) XJTU-SY (Wang et al., 2018),\nand (iii) HUST (Thuan & Hong, 2023). Training is performed on PRONOSTIA, while XJTU-SY and HUST are\n\nused to assess cross-validation. We used the Score met\nric (Nectoux et al., 2012) to assess the performance. We\nevaluate generalization using _Bearing 1_ from the first operating condition of each dataset. Figure 3 visualizes the\nexpected degradation alongside the outputs of NAC. On the\nPRONOSTIA dataset, ContiFormer performed the best with\n\n\n\n**3.4. Run Time and Memory Experiments**\n\n\nWe evaluate computational requirements on fixed-length\nsequences of 1024 steps, 64-dimensional features, 4 heads,\nand a Batch size of 1. Each model is run for ten for\nward passes on Google Colab T4-GPU, and we report the\nmean runtime with standard deviation, throughput, and peak\nmemory usage. NAC occupies an intermediate position\nin runtime relative to several CT-RNN models, including\nGRU-ODE, CfC, and LTC. In terms of memory consumption, NAC uses significantly less memory than mTAN, with\nNAC-2k being the least memory-consuming among the CTAttention models. Reducing NAC sparsity from 90% to 20%\nhas minimal effect on memory, decreasing usage slightly\n\n\n\n7\n\n\nNeuronal Attention Circuit (NAC) for Representation Learning\n\n\n_Table 2._ Run-Time and Memory Benchmark Results\n\n\n**Run-Time** **Throughput** **Peak Memory**\n**Model**\n(s) (seq/s) (MB)\n\n\nRNN 1 . 8392 [\u00b1] [0] [.] [1933] 0.544 0.29\nCT-RNN 7 . 1097 [\u00b1] [0] [.] [3048] 0.141 0.67\nLSTM 2 . 6241 [\u00b1] [0] [.] [2906] 0.381 0.42\nPhasedLSTM 4 . 9812 [\u00b1] [0] [.] [272] 0.201 0.80\nGRU 3 . 216 [\u00b1] [0] [.] [2566] 0.311 0.54\nGRU-ODE 12 . 2498 [\u00b1] [0] [.] [0525] 0.082 0.64\nmmRNN 7 . 5852 [\u00b1] [0] [.] [2785] 0.132 0.96\nLTC 14 . 643 [\u00b1] [0] [.] [2445] 0.068 0.99\nCfC 6 . 0988 [\u00b1] [0] [.] [2135] 0.164 0.76\n\n\nAttention 0 . 0016 [\u00b1] [0] [.] [0001] 625.00 16.86\nMHA 0 . 0041 [\u00b1] [0] [.] [0001] 243.90 69.05\nmTAN 0 . 0272 [\u00b1] [0] [.] [0054] 36.76 790.16\nODEFormer 0 . 0317 [\u00b1] [0] [.] [0016] 31.55 67.71\nCTA 8 . 5275 [\u00b1] [0] [.] [2355] 0.117 1.43\nContiFormer 0 . 066 [\u00b1] [0] [.] [0075] 15.15 67.71\n\n\nNAC-2k 7 . 3071 [\u00b1] [0] [.] [1547] 0.137 44.75\nNAC-32k 7 . 2313 [\u00b1] [0] [.] [219] 0.138 549.86\nNAC-PW 8 . 5649 [\u00b1] [0] [.] [0203] 0.117 5042.09\nNAC-FC 0 . 0195 [\u00b1] [0] [.] [0002] 51.28 29.92\nNAC-02s 7 . 252 [\u00b1] [0] [.] [2018] 0.138 151.54\nNAC-09s 7 . 222 [\u00b1] [0] [.] [176] 0.139 150.85\nNAC-Exact/05s/8k 7 . 4101 [\u00b1] [0] [.] [1586] 0.135 151.50\nNAC-Euler 7 . 3367 [\u00b1] [0] [.] [1719] 0.136 152.22\nNAC-Steady 7 . 2942 [\u00b1] [0] [.] [1451] 0.137 150.86\n\n\nfrom 151.54 MB to 150.85 MB. In constrast, decreasing\nthe Top- K selection from PW to k = 2 drastically reduces\nmemory consumption from 5042 MB to 44.75 MB, demonstrating the flexibility of NAC.\n**Interpreting the Results:** From the experiments, we observe that increasing the sparsity of the NAC layer improves\nthe robustness of the system and leads to higher overall accuracy. Similarly, increasing the Top- K interactions enhances\naccuracy too; however, the benefits diminish as memory\nconsumption grows. Using Exact mode, Top- K =8 with 50%\nsparsity achieves the best balance between accuracy and\nefficiency. Steady mode is the fastest, while Euler mode\nhandles adaptive temporal dynamics.\n\n\n**4. Discussions**\n\n\n\nThis research is part of ongoing work on biologically plausible attention mechanisms and represents a pioneering step,\nwith limitations to be addressed in future work.\n", "metadata": []}}
{"nodes": [{"id": "Top-K Selection", "type": "Concept"}, {"id": "NAC-PW", "type": "Concept"}, {"id": "k", "type": "Parameter"}, {"id": "Memory Consumption", "type": "Concept"}, {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, {"id": "Flexibility", "type": "Concept"}, {"id": "Experiments", "type": "Event"}, {"id": "NAC Sparsity", "type": "Concept"}, {"id": "NAC Layer", "type": "Concept"}, {"id": "Robustness", "type": "Concept"}, {"id": "Accuracy", "type": "Concept"}, {"id": "Top-K Interactions", "type": "Concept"}, {"id": "Exact Mode", "type": "Concept"}, {"id": "Top-K=8", "type": "Concept"}, {"id": "50% Sparsity", "type": "Concept"}, {"id": "Efficiency", "type": "Concept"}, {"id": "Steady Mode", "type": "Concept"}, {"id": "Fastest", "type": "Concept"}, {"id": "Euler Mode", "type": "Concept"}, {"id": "Adaptive Temporal Dynamics", "type": "Concept"}, {"id": "Research", "type": "Concept"}, {"id": "Biologically Plausible Attention Mechanisms", "type": "Concept"}, {"id": "Limitations", "type": "Concept"}, {"id": "Future Work", "type": "Concept"}, {"id": "Architectural improvement", "type": "Concept"}, {"id": "predetermined wiring", "type": "Concept"}, {"id": "AutoNCP", "type": "Concept"}, {"id": "number of units", "type": "Concept"}, {"id": "Sensory Neurons", "type": "Concept"}, {"id": "Interneuron", "type": "Concept"}, {"id": "Motor Neurons", "type": "Concept"}, {"id": "Sparsity", "type": "Concept"}, {"id": "Attention Mechanisms", "type": "Concept"}, {"id": "wiring", "type": "Concept"}, {"id": "NN sensory", "type": "Concept"}, {"id": "backbone units", "type": "Concept"}, {"id": "output motor neurons", "type": "Concept"}, {"id": "architectural size", "type": "Concept"}, {"id": "Runtime", "type": "Concept"}, {"id": "user-defined NCPs configurations", "type": "Concept"}, {"id": "randomized wiring", "type": "Concept"}, {"id": "efficient architectures", "type": "Concept"}, {"id": "Sparse Top-K Selection", "type": "Concept"}, {"id": "Context", "type": "Concept"}, {"id": "QK[\u22a4] matrix", "type": "Concept"}, {"id": "Cost", "type": "Concept"}, {"id": "Long Sequences", "type": "Concept"}, {"id": "Adaptive Top-K Selection", "type": "Concept"}, {"id": "improved key scoring", "type": "Concept"}, {"id": "hardware-aware optimization", "type": "Concept"}, {"id": "Paper", "type": "Concept"}, {"id": "Biologically Inspired Attention Mechanism", "type": "Concept"}, {"id": "Attention Logits", "type": "Concept"}, {"id": "Linear First-Order ODE", "type": "Concept"}, {"id": "nonlinear, interlinked gates", "type": "Concept"}, {"id": "C. elegans", "type": "Concept"}, {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, {"id": "discrete attention", "type": "Concept"}, {"id": "continuous-time dynamics", "type": "Concept"}, {"id": "adaptive temporal processing", "type": "Concept"}, {"id": "traditional scaled dot-product attention", "type": "Concept"}, {"id": "Ordinary Differential Equations (ODEs)", "type": "Concept"}, {"id": "computational modes", "type": "Concept"}, {"id": "Explicit Euler Integration", "type": "Concept"}, {"id": "Exact Closed-Form Solution", "type": "Concept"}, {"id": "equilibrium states", "type": "Concept"}, {"id": "Sparse Top-K Pairwise Concatenation Scheme", "type": "Concept"}, {"id": "memory intensity", "type": "Concept"}, {"id": "State Stability", "type": "Concept"}, {"id": "exponential error bounds", "type": "Concept"}, {"id": "Universal Approximation by NAC", "type": "Concept"}, {"id": "Convergence", "type": "Concept"}, {"id": "Expressiveness", "type": "Concept"}, {"id": "Empirical evaluations", "type": "Concept"}, {"id": "state-of-the-art performance", "type": "Concept"}, {"id": "diverse tasks", "type": "Concept"}, {"id": "irregularly sampled time-series benchmarks", "type": "Concept"}, {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Concept"}, {"id": "Industrial Prognostics", "type": "Concept"}, {"id": "CT-RNN Models", "type": "Concept"}, {"id": "CT-Attention Models", "type": "Concept"}, {"id": "robust temporal modeling", "type": "Concept"}, {"id": "Memory", "type": "Concept"}, {"id": "Code for reproducibility", "type": "Concept"}, {"id": "https://github.com/itxwaleedrazzaq/neuronal_attention_circuit", "type": "Software Repository"}, {"id": "Continuous-time Attention (CTA)", "type": "Concept"}, {"id": "sparse, adaptive networks", "type": "Concept"}, {"id": "natural wiring", "type": "Concept"}, {"id": "robust AI", "type": "Concept"}, {"id": "resource-limited settings", "type": "Concept"}, {"id": "ethical concerns", "type": "Concept"}, {"id": "Surveillance", "type": "Concept"}, {"id": "Autonomous Systems", "type": "Concept"}, {"id": "Representation Learning", "type": "Concept"}, {"id": "Introduction to self-driving cars", "type": "Document"}, {"id": "https://www.udacity.com/course/intro-to-self-driving-cars--nd113", "type": "Online Resource"}, {"id": "Aguiar-Conraria, L.", "type": "Person"}, {"id": "Soares, M. J.", "type": "Person"}, {"id": "The continuous wavelet transform", "type": "Concept"}, {"id": "Journal of economic surveys", "type": "Publication"}, {"id": "Beltagy, I.", "type": "Person"}, {"id": "Peters, M. E.", "type": "Person"}, {"id": "Cohan, A.", "type": "Person"}, {"id": "Longformer", "type": "Concept"}, {"id": "arXiv preprint arXiv:2004.05150", "type": "Publication"}, {"id": "The long-document transformer", "type": "Concept"}, {"id": "Bojarski, M.", "type": "Person"}, {"id": "End to end learning for self-driving cars", "type": "Concept"}, {"id": "arXiv preprint arXiv:1604.07316", "type": "Publication"}, {"id": "Brockman, G.", "type": "Person"}, {"id": "OpenAI Gym", "type": "Software"}, {"id": "arXiv preprint arXiv:1606.01540", "type": "Publication"}, {"id": "Cao, Y.", "type": "Person"}, {"id": "Adjoint sensitivity analysis for differential-algebraic equations", "type": "Concept"}, {"id": "SIAM journal on scientific computing", "type": "Publication"}, {"id": "Chen, R. T.", "type": "Person"}, {"id": "NeuralODE", "type": "Concept"}, {"id": "Advances in neural information processing systems", "type": "Publication"}, {"id": "Chen, Y.", "type": "Person"}, {"id": "ContiFormer", "type": "Concept"}, {"id": "Continuous-time transformer for irregular time series modeling", "type": "Concept"}, {"id": "Advances in Neural Information Processing Systems", "type": "Publication"}, {"id": "Chien, J.-T.", "type": "Person"}, {"id": "Chen, Y.-H.", "type": "Person"}, {"id": "Continuous-time attention for sequential learning", "type": "Concept"}, {"id": "Proceedings of the AAAI conference on artificial intelligence", "type": "Publication"}, {"id": "Cho, K.", "type": "Person"}, {"id": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "type": "Concept"}, {"id": "arXiv preprint arXiv:1406.1078", "type": "Publication"}, {"id": "d\u2019Ascoli, S.", "type": "Person"}, {"id": "ODEFormer", "type": "Concept"}, {"id": "Symbolic regression of dynamical systems with transformers", "type": "Concept"}, {"id": "arXiv preprint arXiv:2310.05573", "type": "Publication"}, {"id": "De Brouwer, E.", "type": "Person"}, {"id": "Gru-ode-bayes", "type": "Concept"}, {"id": "Continuous modeling of sporadicallyobserved time series", "type": "Concept"}, {"id": "Deng, L.", "type": "Person"}, {"id": "MNIST Dataset", "type": "Dataset"}, {"id": "IEEE signal processing magazine", "type": "Publication"}, {"id": "Ding, Y.", "type": "Person"}, {"id": "Remaining useful life estimation using deep metric transfer learning for kernel regression", "type": "Concept"}, {"id": "Reliability Engineering & System Safety", "type": "Publication"}, {"id": "Hasani, R.", "type": "Person"}, {"id": "Liquid Neural Networks (LNNs)", "type": "Concept"}, {"id": "Proceedings of the AAAI Conference on Artificial Intelligence", "type": "Publication"}, {"id": "Closed form continuous-time neural networks", "type": "Concept"}, {"id": "Nature Machine Intelligence", "type": "Publication"}, {"id": "Hochreiter, S.", "type": "Person"}, {"id": "Vanishing Gradients", "type": "Concept"}, {"id": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems", "type": "Publication"}, {"id": "Schmidhuber, J.", "type": "Person"}, {"id": "Long-short term memory (LSTM)", "type": "Concept"}, {"id": "Neural computation", "type": "Publication"}, {"id": "Hong, H. S.", "type": "Person"}, {"id": "Thuan, N.", "type": "Person"}, {"id": "HUST Bearing", "type": "Dataset"}, {"id": "ball bearing fault diagnosis", "type": "Concept"}, {"id": "Mendeley Data", "type": "Publication"}, {"id": "John, F.", "type": "Person"}, {"id": "integration of parabolic equations by difference methods", "type": "Concept"}, {"id": "Communications on Pure and Applied Mathematics", "type": "Publication"}, {"id": "Jordan, M. I.", "type": "Person"}, {"id": "Serial order: A parallel distributed processing approach", "type": "Concept"}, {"id": "Advances in psychology", "type": "Publication"}, {"id": "Elsevier", "type": "Publisher"}, {"id": "Lechner, M.", "type": "Person"}, {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Concept"}, {"id": "long-term dependencies", "type": "Concept"}, {"id": "irregularly sampled time series", "type": "Concept"}, {"id": "Hasani, R. M.", "type": "Person"}, {"id": "Grosu, R.", "type": "Person"}, {"id": "Neuronal Circuit Policies", "type": "Concept"}, {"id": "arXiv preprint arXiv:1803.08554", "type": "Publication"}, {"id": "Neural circuit policies enabling auditable autonomy", "type": "Concept"}, {"id": "Auditable Autonomy", "type": "Concept"}, {"id": "LeCun, Y.", "type": "Person"}, {"id": "back-propagation", "type": "Concept"}, {"id": "A theoretical framework for back-propagation", "type": "Concept"}, {"id": "Proceedings of the 1988 connectionist models summer school", "type": "Publication"}, {"id": "Lin, J.", "type": "Person"}, {"id": "Qu, L.", "type": "Person"}, {"id": "Feature extraction based on morlet wavelet", "type": "Concept"}, {"id": "mechanical fault diagnosis", "type": "Concept"}, {"id": "Journal of sound and vibration", "type": "Publication"}, {"id": "Nectoux, P.", "type": "Person"}, {"id": "PRONOSTIA", "type": "Dataset"}, {"id": "experimental platform", "type": "Concept"}, {"id": "bearings accelerated degradation tests", "type": "Concept"}, {"id": "IEEE International Conference on Prognostics and Health Management, PHM\u201912", "type": "Publication"}, {"id": "Neil, D.", "type": "Person"}, {"id": "Phased LSTM", "type": "Concept"}, {"id": "recurrent network training", "type": "Concept"}, {"id": "long or event-based sequences", "type": "Concept"}, {"id": "Nishijima, T.", "type": "Person"}, {"id": "Universal Approximation Theorem (UAT)", "type": "Concept"}, {"id": "neural networks", "type": "Concept"}, {"id": "arXiv preprint arXiv:2102.10993", "type": "Publication"}, {"id": "Park, M.", "type": "Person"}, {"id": "convolutional neural network-based end-to-end self-driving", "type": "Concept"}, {"id": "Lidar", "type": "Concept"}, {"id": "Camera Fusion", "type": "Concept"}, {"id": "Electronics", "type": "Publication"}, {"id": "Waleed Razzaq", "type": "Person"}, {"id": "Hongwei, M.", "type": "Person"}, {"id": "Neural circuit policies imposing visual perceptual autonomy", "type": "Concept"}, {"id": "visual perceptual autonomy", "type": "Concept"}, {"id": "Neural Processing Letters", "type": "Publication"}, {"id": "Yun-Bo Zhao", "type": "Person"}, {"id": "Carle", "type": "Framework"}, {"id": "hybrid deep-shallow learning framework", "type": "Concept"}, {"id": "robust and explainable RUL estimation", "type": "Concept"}, {"id": "Remaining Useful Life (RUL) Estimation", "type": "Concept"}, {"id": "Rolling Element Bearings (REB)", "type": "Concept"}, {"id": "Soft Computing", "type": "Publication"}, {"id": "distance-aware uncertainty quantification methods", "type": "Concept"}, {"id": "physics-guided neural networks", "type": "Concept"}, {"id": "reliable bearing health prediction", "type": "Concept"}, {"id": "https://arxiv.org/abs/2512.08499", "type": "Online Resource"}, {"id": "Roy, A.", "type": "Person"}, {"id": "Efficient content-based sparse attention with routing transformers", "type": "Concept"}, {"id": "content-based sparse attention", "type": "Concept"}, {"id": "routing transformers", "type": "Concept"}, {"id": "Transactions of the Association for Computational Linguistics", "type": "Publication"}, {"id": "Rubanova, Y.", "type": "Person"}, {"id": "Latent ordinary differential equations for irregularly-sampled time series", "type": "Concept"}, {"id": "irregularly-sampled time series", "type": "Concept"}, {"id": "Rumelhart, D. E.", "type": "Person"}, {"id": "Learning internal representations by error propagation", "type": "Concept"}, {"id": "Technical report", "type": "Publication Type"}, {"id": "Shibuya, N.", "type": "Person"}, {"id": "Car behavioral cloning", "type": "Concept"}, {"id": "https://github.com/naokishibuya/car-behavioral-cloning", "type": "Online Resource"}, {"id": "Shukla, S. N.", "type": "Person"}, {"id": "Marlin, B. M.", "type": "Person"}, {"id": "Multi-time attention networks for irregularly sampled time series", "type": "Concept"}, {"id": "arXiv preprint arXiv:2101.10318", "type": "Publication"}, {"id": "Stinchcomb, M.", "type": "Person"}, {"id": "Multilayered feedforward networks", "type": "Concept"}, {"id": "Universal Approximator", "type": "Concept"}, {"id": "Neural Networks", "type": "Publication"}, {"id": "Tay, Y.", "type": "Person"}, {"id": "Sparse sinkhorn attention", "type": "Concept"}, {"id": "International conference on machine learning", "type": "Publication"}, {"id": "PMLR", "type": "Publisher"}, {"id": "Thuan, N. D.", "type": "Person"}, {"id": "BMC research notes", "type": "Publication"}, {"id": "Tiang, Y.", "type": "Person"}, {"id": "Lane marking detection", "type": "Concept"}, {"id": "patch proposal network (ppn)", "type": "Concept"}, {"id": "Vaswani, A.", "type": "Person"}, {"id": "Attention is all you need", "type": "Concept"}, {"id": "Vidulin, V.", "type": "Person"}, {"id": "Localized Person Activity Dataset", "type": "Dataset"}, {"id": "UCI Machine Learning Repository", "type": "Organization"}, {"id": "Wang, B.", "type": "Person"}, {"id": "XJTU-SY", "type": "Dataset"}, {"id": "GitHub Repository", "type": "Platform"}, {"id": "Zaheer, M.", "type": "Person"}, {"id": "BigBird", "type": "Concept"}, {"id": "Transformers for longer sequences", "type": "Concept"}, {"id": "Zhuang, J.", "type": "Person"}, {"id": "Adaptive checkpoint adjoint method", "type": "Concept"}, {"id": "gradient estimation in neural ode", "type": "Concept"}, {"id": "Temporal convolution-based transferable cross-domain adaptation approach", "type": "Concept"}, {"id": "Appendix A. Preliminaries", "type": "Document Section"}, {"id": "Decoder", "type": "Concept"}, {"id": "Encoder Outputs", "type": "Concept"}, {"id": "Target Token", "type": "Concept"}, {"id": "V", "type": "Parameter"}, {"id": "n", "type": "Parameter"}, {"id": "Scaled-Dot Attention", "type": "Concept"}, {"id": "Softmax Normalization", "type": "Concept"}, {"id": "Query Tensors", "type": "Concept"}, {"id": "Key Tensors", "type": "Concept"}, {"id": "scaling factor", "type": "Concept"}, {"id": "destabilizing the softmax", "type": "Concept"}, {"id": "Vaswani et al., 2017", "type": "Reference"}, {"id": "Neuronal Circuit Policies (NCPs)", "type": "Concept"}, {"id": "resting potential", "type": "Concept"}, {"id": "activation potential", "type": "Concept"}, {"id": "Nm", "type": "Concept"}, {"id": "Mp", "type": "Concept"}, {"id": "Mn", "type": "Concept"}, {"id": "controllable variable y", "type": "Concept"}, {"id": "biologically plausible range", "type": "Concept"}, {"id": "NCP architecture", "type": "Concept"}, {"id": "biological sparsity", "type": "Concept"}, {"id": "abstraction of neural circuits", "type": "Concept"}, {"id": "Ns", "type": "Concept"}, {"id": "Ni", "type": "Concept"}, {"id": "feedforward connections", "type": "Concept"}, {"id": "Nc", "type": "Concept"}, {"id": "recurrent connections", "type": "Concept"}, {"id": "Lechner et al., 2018", "type": "Reference"}, {"id": "Figure 1(a)", "type": "Figure"}, {"id": "connectome of NCPs", "type": "Concept"}, {"id": "Proofs", "type": "Concept"}, {"id": "Deriving Closed-form (Exact) Solution", "type": "Concept"}, {"id": "\u03d5", "type": "Parameter"}, {"id": "\u03c9\u03c4", "type": "Parameter"}, {"id": "nonlinear functions", "type": "Concept"}, {"id": "input u", "type": "Concept"}, {"id": "pseudo-time integration interval", "type": "Concept"}, {"id": "Query-Key Pair", "type": "Concept"}, {"id": "frozen-coefficient approximation", "type": "Concept"}, {"id": "integrating factor", "type": "Concept"}], "relationships": [{"source": {"id": "NAC-PW", "type": "Concept"}, "target": {"id": "Top-K Selection", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "k", "type": "Parameter"}, "target": {"id": "Top-K Selection", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Top-K Selection", "type": "Concept"}, "target": {"id": "Memory Consumption", "type": "Concept"}, "type": "AFFECTS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Flexibility", "type": "Concept"}, "type": "EXHIBITS"}, {"source": {"id": "NAC Sparsity", "type": "Concept"}, "target": {"id": "Robustness", "type": "Concept"}, "type": "IMPROVES"}, {"source": {"id": "NAC Sparsity", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Concept"}, "type": "INCREASES"}, {"source": {"id": "NAC Layer", "type": "Concept"}, "target": {"id": "NAC Sparsity", "type": "Concept"}, "type": "HAS_PROPERTY"}, {"source": {"id": "Top-K Interactions", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Concept"}, "type": "ENHANCES"}, {"source": {"id": "Top-K Interactions", "type": "Concept"}, "target": {"id": "Memory Consumption", "type": "Concept"}, "type": "INFLUENCES"}, {"source": {"id": "Exact Mode", "type": "Concept"}, "target": {"id": "Top-K=8", "type": "Concept"}, "type": "USED_WITH"}, {"source": {"id": "Exact Mode", "type": "Concept"}, "target": {"id": "50% Sparsity", "type": "Concept"}, "type": "USED_WITH"}, {"source": {"id": "Exact Mode", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Concept"}, "type": "BALANCES"}, {"source": {"id": "Exact Mode", "type": "Concept"}, "target": {"id": "Efficiency", "type": "Concept"}, "type": "BALANCES"}, {"source": {"id": "Steady Mode", "type": "Concept"}, "target": {"id": "Fastest", "type": "Concept"}, "type": "HAS_CHARACTERISTIC"}, {"source": {"id": "Euler Mode", "type": "Concept"}, "target": {"id": "Adaptive Temporal Dynamics", "type": "Concept"}, "type": "HANDLES"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "Biologically Plausible Attention Mechanisms", "type": "Concept"}, "type": "IS_PART_OF"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "Limitations", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Limitations", "type": "Concept"}, "target": {"id": "Future Work", "type": "Concept"}, "type": "TO_BE_ADDRESSED_IN"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "predetermined wiring", "type": "Concept"}, "type": "USES"}, {"source": {"id": "predetermined wiring", "type": "Concept"}, "target": {"id": "AutoNCP", "type": "Concept"}, "type": "IS_CALLED"}, {"source": {"id": "AutoNCP", "type": "Concept"}, "target": {"id": "number of units", "type": "Concept"}, "type": "REQUIRES"}, {"source": {"id": "number of units", "type": "Concept"}, "target": {"id": "Sensory Neurons", "type": "Concept"}, "type": "COMPRISES"}, {"source": {"id": "number of units", "type": "Concept"}, "target": {"id": "Interneuron", "type": "Concept"}, "type": "COMPRISES"}, {"source": {"id": "number of units", "type": "Concept"}, "target": {"id": "Motor Neurons", "type": "Concept"}, "type": "COMPRISES"}, {"source": {"id": "AutoNCP", "type": "Concept"}, "target": {"id": "output motor neurons", "type": "Concept"}, "type": "REQUIRES"}, {"source": {"id": "AutoNCP", "type": "Concept"}, "target": {"id": "Sparsity", "type": "Concept"}, "type": "REQUIRES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Attention Mechanisms", "type": "Concept"}, "type": "INTEGRATES_WITH"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "wiring", "type": "Concept"}, "type": "PRESERVES"}, {"source": {"id": "NN sensory", "type": "Concept"}, "target": {"id": "Sensory Neurons", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "backbone units", "type": "Concept"}, "type": "UTILIZES"}, {"source": {"id": "backbone units", "type": "Concept"}, "target": {"id": "architectural size", "type": "Concept"}, "type": "LEADS_TO"}, {"source": {"id": "backbone units", "type": "Concept"}, "target": {"id": "Runtime", "type": "Concept"}, "type": "INCREASES"}, {"source": {"id": "Future Work", "type": "Concept"}, "target": {"id": "user-defined NCPs configurations", "type": "Concept"}, "type": "WILL_SUPPORT"}, {"source": {"id": "Future Work", "type": "Concept"}, "target": {"id": "randomized wiring", "type": "Concept"}, "type": "WILL_SUPPORT"}, {"source": {"id": "user-defined NCPs configurations", "type": "Concept"}, "target": {"id": "efficient architectures", "type": "Concept"}, "type": "ENABLES"}, {"source": {"id": "randomized wiring", "type": "Concept"}, "target": {"id": "efficient architectures", "type": "Concept"}, "type": "ENABLES"}, {"source": {"id": "Sparse Top-K Selection", "type": "Concept"}, "target": {"id": "Context", "type": "Concept"}, "type": "MISSES"}, {"source": {"id": "Sparse Top-K Selection", "type": "Concept"}, "target": {"id": "k", "type": "Parameter"}, "type": "IS_SENSITIVE_TO"}, {"source": {"id": "Sparse Top-K Selection", "type": "Concept"}, "target": {"id": "QK[\u22a4] matrix", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "QK[\u22a4] matrix", "type": "Concept"}, "target": {"id": "Cost", "type": "Concept"}, "type": "DOMINATES"}, {"source": {"id": "Cost", "type": "Concept"}, "target": {"id": "Long Sequences", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Future Work", "type": "Concept"}, "target": {"id": "Adaptive Top-K Selection", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Future Work", "type": "Concept"}, "target": {"id": "improved key scoring", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Future Work", "type": "Concept"}, "target": {"id": "hardware-aware optimization", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Adaptive Top-K Selection", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Concept"}, "type": "STRENGTHENS"}, {"source": {"id": "Adaptive Top-K Selection", "type": "Concept"}, "target": {"id": "Robustness", "type": "Concept"}, "type": "STRENGTHENS"}, {"source": {"id": "improved key scoring", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Concept"}, "type": "STRENGTHENS"}, {"source": {"id": "improved key scoring", "type": "Concept"}, "target": {"id": "Robustness", "type": "Concept"}, "type": "STRENGTHENS"}, {"source": {"id": "hardware-aware optimization", "type": "Concept"}, "target": {"id": "Accuracy", "type": "Concept"}, "type": "STRENGTHENS"}, {"source": {"id": "hardware-aware optimization", "type": "Concept"}, "target": {"id": "Robustness", "type": "Concept"}, "type": "STRENGTHENS"}, {"source": {"id": "Paper", "type": "Concept"}, "target": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "type": "INTRODUCES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Biologically Inspired Attention Mechanism", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Biologically Inspired Attention Mechanism", "type": "Concept"}, "target": {"id": "Attention Logits", "type": "Concept"}, "type": "REFORMULATES"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "Linear First-Order ODE", "type": "Concept"}, "type": "AS_SOLUTION_TO"}, {"source": {"id": "Linear First-Order ODE", "type": "Concept"}, "target": {"id": "nonlinear, interlinked gates", "type": "Concept"}, "type": "MODULATED_BY"}, {"source": {"id": "nonlinear, interlinked gates", "type": "Concept"}, "target": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "type": "DERIVED_FROM"}, {"source": {"id": "C. elegans Neuronal Circuit Policies (NCPs)", "type": "Concept"}, "target": {"id": "C. elegans", "type": "Concept"}, "type": "DERIVED_FROM"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "discrete attention", "type": "Concept"}, "type": "BRIDGES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "continuous-time dynamics", "type": "Concept"}, "type": "BRIDGES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "adaptive temporal processing", "type": "Concept"}, "type": "ENABLES"}, {"source": {"id": "adaptive temporal processing", "type": "Concept"}, "target": {"id": "Limitations", "type": "Concept"}, "type": "WITHOUT"}, {"source": {"id": "Limitations", "type": "Concept"}, "target": {"id": "traditional scaled dot-product attention", "type": "Concept"}, "type": "INHERENT_TO"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "computational modes", "type": "Concept"}, "type": "INTRODUCES"}, {"source": {"id": "computational modes", "type": "Concept"}, "target": {"id": "Euler Mode", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Euler Mode", "type": "Concept"}, "target": {"id": "Explicit Euler Integration", "type": "Concept"}, "type": "BASED_ON"}, {"source": {"id": "computational modes", "type": "Concept"}, "target": {"id": "Exact Mode", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Exact Mode", "type": "Concept"}, "target": {"id": "Exact Closed-Form Solution", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "computational modes", "type": "Concept"}, "target": {"id": "Steady Mode", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Steady Mode", "type": "Concept"}, "target": {"id": "equilibrium states", "type": "Concept"}, "type": "APPROXIMATES"}, {"source": {"id": "Sparse Top-K Pairwise Concatenation Scheme", "type": "Concept"}, "target": {"id": "memory intensity", "type": "Concept"}, "type": "MITIGATES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "State Stability", "type": "Concept"}, "type": "ESTABLISHES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "exponential error bounds", "type": "Concept"}, "type": "ESTABLISHES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Universal Approximation by NAC", "type": "Concept"}, "type": "ESTABLISHES"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "Convergence", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "Universal Approximation by NAC", "type": "Concept"}, "target": {"id": "Expressiveness", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "Empirical evaluations", "type": "Concept"}, "target": {"id": "state-of-the-art performance", "type": "Concept"}, "type": "DEMONSTRATE"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "state-of-the-art performance", "type": "Concept"}, "type": "ACHIEVES"}, {"source": {"id": "state-of-the-art performance", "type": "Concept"}, "target": {"id": "diverse tasks", "type": "Concept"}, "type": "ACROSS"}, {"source": {"id": "diverse tasks", "type": "Concept"}, "target": {"id": "irregularly sampled time-series benchmarks", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "diverse tasks", "type": "Concept"}, "target": {"id": "Lane-Keeping for Autonomous Vehicles", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "diverse tasks", "type": "Concept"}, "target": {"id": "Industrial Prognostics", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "CT-RNN Models", "type": "Concept"}, "type": "OCCUPIES_POSITION_BETWEEN"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "CT-Attention Models", "type": "Concept"}, "type": "OCCUPIES_POSITION_BETWEEN"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "robust temporal modeling", "type": "Concept"}, "type": "OFFERS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Runtime", "type": "Concept"}, "type": "REQUIRES_LESS"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Memory", "type": "Concept"}, "type": "REQUIRES_LESS"}, {"source": {"id": "CT-RNN Models", "type": "Concept"}, "target": {"id": "Runtime", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "CT-Attention Models", "type": "Concept"}, "target": {"id": "Memory", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "Code for reproducibility", "type": "Concept"}, "target": {"id": "https://github.com/itxwaleedrazzaq/neuronal_attention_circuit", "type": "Software Repository"}, "type": "IS_AVAILABLE_AT"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "Continuous-time Attention (CTA)", "type": "Concept"}, "type": "ADDRESSES"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "Biologically Plausible Attention Mechanisms", "type": "Concept"}, "type": "PIONEERS"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "sparse, adaptive networks", "type": "Concept"}, "type": "PROMOTES"}, {"source": {"id": "sparse, adaptive networks", "type": "Concept"}, "target": {"id": "natural wiring", "type": "Concept"}, "type": "RESEMBLE"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "robust AI", "type": "Concept"}, "type": "SUPPORTS"}, {"source": {"id": "robust AI", "type": "Concept"}, "target": {"id": "resource-limited settings", "type": "Concept"}, "type": "APPLIES_TO"}, {"source": {"id": "Research", "type": "Concept"}, "target": {"id": "ethical concerns", "type": "Concept"}, "type": "RAISES"}, {"source": {"id": "ethical concerns", "type": "Concept"}, "target": {"id": "Surveillance", "type": "Concept"}, "type": "APPLIES_TO"}, {"source": {"id": "ethical concerns", "type": "Concept"}, "target": {"id": "Autonomous Systems", "type": "Concept"}, "type": "APPLIES_TO"}, {"source": {"id": "Neuronal Attention Circuit (NAC)", "type": "Concept"}, "target": {"id": "Representation Learning", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Introduction to self-driving cars", "type": "Document"}, "target": {"id": "https://www.udacity.com/course/intro-to-self-driving-cars--nd113", "type": "Online Resource"}, "type": "HAS_URL"}, {"source": {"id": "Aguiar-Conraria, L.", "type": "Person"}, "target": {"id": "The continuous wavelet transform", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Soares, M. J.", "type": "Person"}, "target": {"id": "The continuous wavelet transform", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "The continuous wavelet transform", "type": "Concept"}, "target": {"id": "Journal of economic surveys", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Beltagy, I.", "type": "Person"}, "target": {"id": "Longformer", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Peters, M. E.", "type": "Person"}, "target": {"id": "Longformer", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Cohan, A.", "type": "Person"}, "target": {"id": "Longformer", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Longformer", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:2004.05150", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Longformer", "type": "Concept"}, "target": {"id": "The long-document transformer", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Bojarski, M.", "type": "Person"}, "target": {"id": "End to end learning for self-driving cars", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "End to end learning for self-driving cars", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:1604.07316", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Brockman, G.", "type": "Person"}, "target": {"id": "OpenAI Gym", "type": "Software"}, "type": "AUTHORED"}, {"source": {"id": "OpenAI Gym", "type": "Software"}, "target": {"id": "arXiv preprint arXiv:1606.01540", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Cao, Y.", "type": "Person"}, "target": {"id": "Adjoint sensitivity analysis for differential-algebraic equations", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Adjoint sensitivity analysis for differential-algebraic equations", "type": "Concept"}, "target": {"id": "SIAM journal on scientific computing", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Chen, R. T.", "type": "Person"}, "target": {"id": "NeuralODE", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "NeuralODE", "type": "Concept"}, "target": {"id": "Advances in neural information processing systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Chen, Y.", "type": "Person"}, "target": {"id": "ContiFormer", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "ContiFormer", "type": "Concept"}, "target": {"id": "Continuous-time transformer for irregular time series modeling", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "ContiFormer", "type": "Concept"}, "target": {"id": "Advances in Neural Information Processing Systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Chien, J.-T.", "type": "Person"}, "target": {"id": "Continuous-time attention for sequential learning", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Chen, Y.-H.", "type": "Person"}, "target": {"id": "Continuous-time attention for sequential learning", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Continuous-time attention for sequential learning", "type": "Concept"}, "target": {"id": "Proceedings of the AAAI conference on artificial intelligence", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Cho, K.", "type": "Person"}, "target": {"id": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:1406.1078", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "d\u2019Ascoli, S.", "type": "Person"}, "target": {"id": "ODEFormer", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "ODEFormer", "type": "Concept"}, "target": {"id": "Symbolic regression of dynamical systems with transformers", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "ODEFormer", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:2310.05573", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "De Brouwer, E.", "type": "Person"}, "target": {"id": "Gru-ode-bayes", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Gru-ode-bayes", "type": "Concept"}, "target": {"id": "Continuous modeling of sporadicallyobserved time series", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Gru-ode-bayes", "type": "Concept"}, "target": {"id": "Advances in neural information processing systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Deng, L.", "type": "Person"}, "target": {"id": "MNIST Dataset", "type": "Dataset"}, "type": "AUTHORED"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "IEEE signal processing magazine", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Ding, Y.", "type": "Person"}, "target": {"id": "Remaining useful life estimation using deep metric transfer learning for kernel regression", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Remaining useful life estimation using deep metric transfer learning for kernel regression", "type": "Concept"}, "target": {"id": "Reliability Engineering & System Safety", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Hasani, R.", "type": "Person"}, "target": {"id": "Liquid Neural Networks (LNNs)", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Liquid Neural Networks (LNNs)", "type": "Concept"}, "target": {"id": "Proceedings of the AAAI Conference on Artificial Intelligence", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Hasani, R.", "type": "Person"}, "target": {"id": "Closed form continuous-time neural networks", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Closed form continuous-time neural networks", "type": "Concept"}, "target": {"id": "Nature Machine Intelligence", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Hochreiter, S.", "type": "Person"}, "target": {"id": "Vanishing Gradients", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Vanishing Gradients", "type": "Concept"}, "target": {"id": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems", "type": "Publication"}, "type": "DESCRIBED_IN"}, {"source": {"id": "Hochreiter, S.", "type": "Person"}, "target": {"id": "Long-short term memory (LSTM)", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Schmidhuber, J.", "type": "Person"}, "target": {"id": "Long-short term memory (LSTM)", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Long-short term memory (LSTM)", "type": "Concept"}, "target": {"id": "Neural computation", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Hong, H. S.", "type": "Person"}, "target": {"id": "HUST Bearing", "type": "Dataset"}, "type": "AUTHORED"}, {"source": {"id": "Thuan, N.", "type": "Person"}, "target": {"id": "HUST Bearing", "type": "Dataset"}, "type": "CO_AUTHORED"}, {"source": {"id": "HUST Bearing", "type": "Dataset"}, "target": {"id": "ball bearing fault diagnosis", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "HUST Bearing", "type": "Dataset"}, "target": {"id": "Mendeley Data", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "John, F.", "type": "Person"}, "target": {"id": "integration of parabolic equations by difference methods", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "integration of parabolic equations by difference methods", "type": "Concept"}, "target": {"id": "Communications on Pure and Applied Mathematics", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Jordan, M. I.", "type": "Person"}, "target": {"id": "Serial order: A parallel distributed processing approach", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Serial order: A parallel distributed processing approach", "type": "Concept"}, "target": {"id": "Advances in psychology", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Advances in psychology", "type": "Publication"}, "target": {"id": "Elsevier", "type": "Publisher"}, "type": "PUBLISHED_BY"}, {"source": {"id": "Lechner, M.", "type": "Person"}, "target": {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Hasani, R.", "type": "Person"}, "target": {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Mixed-memory RNNs (mmRNNs)", "type": "Concept"}, "target": {"id": "long-term dependencies", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "long-term dependencies", "type": "Concept"}, "target": {"id": "irregularly sampled time series", "type": "Concept"}, "type": "IN"}, {"source": {"id": "Lechner, M.", "type": "Person"}, "target": {"id": "Neuronal Circuit Policies", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Hasani, R. M.", "type": "Person"}, "target": {"id": "Neuronal Circuit Policies", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Grosu, R.", "type": "Person"}, "target": {"id": "Neuronal Circuit Policies", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Neuronal Circuit Policies", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:1803.08554", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Lechner, M.", "type": "Person"}, "target": {"id": "Neural circuit policies enabling auditable autonomy", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Neural circuit policies enabling auditable autonomy", "type": "Concept"}, "target": {"id": "Auditable Autonomy", "type": "Concept"}, "type": "ENABLES"}, {"source": {"id": "Neural circuit policies enabling auditable autonomy", "type": "Concept"}, "target": {"id": "Nature Machine Intelligence", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "LeCun, Y.", "type": "Person"}, "target": {"id": "back-propagation", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "back-propagation", "type": "Concept"}, "target": {"id": "A theoretical framework for back-propagation", "type": "Concept"}, "type": "DESCRIBED_IN"}, {"source": {"id": "A theoretical framework for back-propagation", "type": "Concept"}, "target": {"id": "Proceedings of the 1988 connectionist models summer school", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Lin, J.", "type": "Person"}, "target": {"id": "Feature extraction based on morlet wavelet", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Qu, L.", "type": "Person"}, "target": {"id": "Feature extraction based on morlet wavelet", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Feature extraction based on morlet wavelet", "type": "Concept"}, "target": {"id": "mechanical fault diagnosis", "type": "Concept"}, "type": "APPLIES_TO"}, {"source": {"id": "Feature extraction based on morlet wavelet", "type": "Concept"}, "target": {"id": "Journal of sound and vibration", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Nectoux, P.", "type": "Person"}, "target": {"id": "PRONOSTIA", "type": "Dataset"}, "type": "AUTHORED"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "experimental platform", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "bearings accelerated degradation tests", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "IEEE International Conference on Prognostics and Health Management, PHM\u201912", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Neil, D.", "type": "Person"}, "target": {"id": "Phased LSTM", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Phased LSTM", "type": "Concept"}, "target": {"id": "recurrent network training", "type": "Concept"}, "type": "ACCELERATES"}, {"source": {"id": "recurrent network training", "type": "Concept"}, "target": {"id": "long or event-based sequences", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Phased LSTM", "type": "Concept"}, "target": {"id": "Advances in neural information processing systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Nishijima, T.", "type": "Person"}, "target": {"id": "Universal Approximation Theorem (UAT)", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Universal Approximation Theorem (UAT)", "type": "Concept"}, "target": {"id": "neural networks", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Universal Approximation Theorem (UAT)", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:2102.10993", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Park, M.", "type": "Person"}, "target": {"id": "convolutional neural network-based end-to-end self-driving", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "convolutional neural network-based end-to-end self-driving", "type": "Concept"}, "target": {"id": "Lidar", "type": "Concept"}, "type": "USES"}, {"source": {"id": "convolutional neural network-based end-to-end self-driving", "type": "Concept"}, "target": {"id": "Camera Fusion", "type": "Concept"}, "type": "USES"}, {"source": {"id": "convolutional neural network-based end-to-end self-driving", "type": "Concept"}, "target": {"id": "Electronics", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Waleed Razzaq", "type": "Person"}, "target": {"id": "Neural circuit policies imposing visual perceptual autonomy", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Hongwei, M.", "type": "Person"}, "target": {"id": "Neural circuit policies imposing visual perceptual autonomy", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Neural circuit policies imposing visual perceptual autonomy", "type": "Concept"}, "target": {"id": "visual perceptual autonomy", "type": "Concept"}, "type": "IMPOSES"}, {"source": {"id": "Neural circuit policies imposing visual perceptual autonomy", "type": "Concept"}, "target": {"id": "Neural Processing Letters", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Waleed Razzaq", "type": "Person"}, "target": {"id": "Carle", "type": "Framework"}, "type": "AUTHORED"}, {"source": {"id": "Yun-Bo Zhao", "type": "Person"}, "target": {"id": "Carle", "type": "Framework"}, "type": "CO_AUTHORED"}, {"source": {"id": "Carle", "type": "Framework"}, "target": {"id": "hybrid deep-shallow learning framework", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Carle", "type": "Framework"}, "target": {"id": "robust and explainable RUL estimation", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "robust and explainable RUL estimation", "type": "Concept"}, "target": {"id": "Rolling Element Bearings (REB)", "type": "Concept"}, "type": "OF"}, {"source": {"id": "Carle", "type": "Framework"}, "target": {"id": "Soft Computing", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Waleed Razzaq", "type": "Person"}, "target": {"id": "distance-aware uncertainty quantification methods", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Yun-Bo Zhao", "type": "Person"}, "target": {"id": "distance-aware uncertainty quantification methods", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "distance-aware uncertainty quantification methods", "type": "Concept"}, "target": {"id": "physics-guided neural networks", "type": "Concept"}, "type": "USES"}, {"source": {"id": "distance-aware uncertainty quantification methods", "type": "Concept"}, "target": {"id": "reliable bearing health prediction", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "distance-aware uncertainty quantification methods", "type": "Concept"}, "target": {"id": "https://arxiv.org/abs/2512.08499", "type": "Online Resource"}, "type": "PUBLISHED_AT"}, {"source": {"id": "Roy, A.", "type": "Person"}, "target": {"id": "Efficient content-based sparse attention with routing transformers", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Efficient content-based sparse attention with routing transformers", "type": "Concept"}, "target": {"id": "content-based sparse attention", "type": "Concept"}, "type": "USES"}, {"source": {"id": "Efficient content-based sparse attention with routing transformers", "type": "Concept"}, "target": {"id": "routing transformers", "type": "Concept"}, "type": "USES"}, {"source": {"id": "Efficient content-based sparse attention with routing transformers", "type": "Concept"}, "target": {"id": "Transactions of the Association for Computational Linguistics", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Rubanova, Y.", "type": "Person"}, "target": {"id": "Latent ordinary differential equations for irregularly-sampled time series", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Latent ordinary differential equations for irregularly-sampled time series", "type": "Concept"}, "target": {"id": "irregularly-sampled time series", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Latent ordinary differential equations for irregularly-sampled time series", "type": "Concept"}, "target": {"id": "Advances in neural information processing systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Rumelhart, D. E.", "type": "Person"}, "target": {"id": "Learning internal representations by error propagation", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Learning internal representations by error propagation", "type": "Concept"}, "target": {"id": "Technical report", "type": "Publication Type"}, "type": "IS_A"}, {"source": {"id": "Shibuya, N.", "type": "Person"}, "target": {"id": "Car behavioral cloning", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Car behavioral cloning", "type": "Concept"}, "target": {"id": "https://github.com/naokishibuya/car-behavioral-cloning", "type": "Online Resource"}, "type": "IS_AVAILABLE_AT"}, {"source": {"id": "Shukla, S. N.", "type": "Person"}, "target": {"id": "Multi-time attention networks for irregularly sampled time series", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Marlin, B. M.", "type": "Person"}, "target": {"id": "Multi-time attention networks for irregularly sampled time series", "type": "Concept"}, "type": "CO_AUTHORED"}, {"source": {"id": "Multi-time attention networks for irregularly sampled time series", "type": "Concept"}, "target": {"id": "irregularly sampled time series", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Multi-time attention networks for irregularly sampled time series", "type": "Concept"}, "target": {"id": "arXiv preprint arXiv:2101.10318", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Stinchcomb, M.", "type": "Person"}, "target": {"id": "Multilayered feedforward networks are universal approximators", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Multilayered feedforward networks", "type": "Concept"}, "target": {"id": "Universal Approximator", "type": "Concept"}, "type": "ARE"}, {"source": {"id": "Multilayered feedforward networks are universal approximators", "type": "Concept"}, "target": {"id": "Neural Networks", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Tay, Y.", "type": "Person"}, "target": {"id": "Sparse sinkhorn attention", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Sparse sinkhorn attention", "type": "Concept"}, "target": {"id": "International conference on machine learning", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "International conference on machine learning", "type": "Publication"}, "target": {"id": "PMLR", "type": "Publisher"}, "type": "PUBLISHED_BY"}, {"source": {"id": "Thuan, N. D.", "type": "Person"}, "target": {"id": "HUST Bearing", "type": "Dataset"}, "type": "AUTHORED"}, {"source": {"id": "Hong, H. S.", "type": "Person"}, "target": {"id": "HUST Bearing", "type": "Dataset"}, "type": "CO_AUTHORED"}, {"source": {"id": "HUST Bearing", "type": "Dataset"}, "target": {"id": "ball bearing fault diagnosis", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "HUST Bearing", "type": "Dataset"}, "target": {"id": "BMC research notes", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Tiang, Y.", "type": "Person"}, "target": {"id": "Lane marking detection", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Lane marking detection", "type": "Concept"}, "target": {"id": "patch proposal network (ppn)", "type": "Concept"}, "type": "USES"}, {"source": {"id": "Vaswani, A.", "type": "Person"}, "target": {"id": "Attention is all you need", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Attention is all you need", "type": "Concept"}, "target": {"id": "Advances in neural information processing systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Vidulin, V.", "type": "Person"}, "target": {"id": "Localized Person Activity Dataset", "type": "Dataset"}, "type": "AUTHORED"}, {"source": {"id": "Localized Person Activity Dataset", "type": "Dataset"}, "target": {"id": "UCI Machine Learning Repository", "type": "Organization"}, "type": "HOSTED_BY"}, {"source": {"id": "Wang, B.", "type": "Person"}, "target": {"id": "XJTU-SY", "type": "Dataset"}, "type": "AUTHORED"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "GitHub Repository", "type": "Platform"}, "type": "PUBLISHED_ON"}, {"source": {"id": "Zaheer, M.", "type": "Person"}, "target": {"id": "BigBird", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "BigBird", "type": "Concept"}, "target": {"id": "Transformers for longer sequences", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "BigBird", "type": "Concept"}, "target": {"id": "Advances in neural information processing systems", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Zhuang, J.", "type": "Person"}, "target": {"id": "Adaptive checkpoint adjoint method", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Adaptive checkpoint adjoint method", "type": "Concept"}, "target": {"id": "gradient estimation in neural ode", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Adaptive checkpoint adjoint method", "type": "Concept"}, "target": {"id": "International conference on machine learning", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "International conference on machine learning", "type": "Publication"}, "target": {"id": "PMLR", "type": "Publisher"}, "type": "PUBLISHED_BY"}, {"source": {"id": "Zhuang, J.", "type": "Person"}, "target": {"id": "Temporal convolution-based transferable cross-domain adaptation approach", "type": "Concept"}, "type": "AUTHORED"}, {"source": {"id": "Temporal convolution-based transferable cross-domain adaptation approach", "type": "Concept"}, "target": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Temporal convolution-based transferable cross-domain adaptation approach", "type": "Concept"}, "target": {"id": "Reliability Engineering & System Safety", "type": "Publication"}, "type": "PUBLISHED_IN"}, {"source": {"id": "Appendix A. Preliminaries", "type": "Document Section"}, "target": {"id": "Attention Mechanisms", "type": "Concept"}, "type": "DESCRIBES"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "modern neural architectures", "type": "Concept"}, "type": "INTEGRAL_TO"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "neural machine translation", "type": "Concept"}, "type": "INTRODUCED_IN"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "Decoder", "type": "Concept"}, "type": "ALLOWS"}, {"source": {"id": "Decoder", "type": "Concept"}, "target": {"id": "Encoder Outputs", "type": "Concept"}, "type": "WEIGHTS"}, {"source": {"id": "Encoder Outputs", "type": "Concept"}, "target": {"id": "Target Token", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "q", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "K", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Attention Mechanisms", "type": "Concept"}, "target": {"id": "V", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "Scaled-Dot Attention", "type": "Concept"}, "target": {"id": "Attention Logits", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "q", "type": "Parameter"}, "type": "DERIVED_FROM"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "k", "type": "Parameter"}, "type": "DERIVED_FROM"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "d", "type": "Parameter"}, "type": "SCALED_BY"}, {"source": {"id": "Attention Logits", "type": "Concept"}, "target": {"id": "Attention Weights", "type": "Concept"}, "type": "NORMALIZED_TO"}, {"source": {"id": "Attention Weights", "type": "Concept"}, "target": {"id": "Attention Output", "type": "Concept"}, "type": "USED_TO_COMPUTE"}, {"source": {"id": "Softmax Normalization", "type": "Concept"}, "target": {"id": "Attention Logits", "type": "Concept"}, "type": "APPLIED_TO"}, {"source": {"id": "Attention Output", "type": "Concept"}, "target": {"id": "q", "type": "Parameter"}, "type": "DEPENDS_ON"}, {"source": {"id": "Attention Output", "type": "Concept"}, "target": {"id": "k", "type": "Parameter"}, "type": "DEPENDS_ON"}, {"source": {"id": "Attention Output", "type": "Concept"}, "target": {"id": "v", "type": "Parameter"}, "type": "DEPENDS_ON"}, {"source": {"id": "q", "type": "Parameter"}, "target": {"id": "Query Tensors", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "k", "type": "Parameter"}, "target": {"id": "Key Tensors", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "d", "type": "Parameter"}, "target": {"id": "scaling factor", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "d", "type": "Parameter"}, "target": {"id": "destabilizing the softmax", "type": "Concept"}, "type": "PREVENTS"}, {"source": {"id": "Vaswani et al., 2017", "type": "Reference"}, "target": {"id": "scaling factor", "type": "Concept"}, "type": "DESCRIBED"}, {"source": {"id": "Nm", "type": "Concept"}, "target": {"id": "Mp", "type": "Concept"}, "type": "COMPOSED_OF"}, {"source": {"id": "Nm", "type": "Concept"}, "target": {"id": "Mn", "type": "Concept"}, "type": "COMPOSED_OF"}, {"source": {"id": "Nm", "type": "Concept"}, "target": {"id": "controllable variable y", "type": "Concept"}, "type": "DRIVEN_BY"}, {"source": {"id": "controllable variable y", "type": "Concept"}, "target": {"id": "biologically plausible range", "type": "Concept"}, "type": "MAPS_TO"}, {"source": {"id": "NCP architecture", "type": "Concept"}, "target": {"id": "biological sparsity", "type": "Concept"}, "type": "REFLECTS"}, {"source": {"id": "NCP architecture", "type": "Concept"}, "target": {"id": "abstraction of neural circuits", "type": "Concept"}, "type": "REFLECTS"}, {"source": {"id": "Ns", "type": "Concept"}, "target": {"id": "Ni", "type": "Concept"}, "type": "CONNECTS_TO"}, {"source": {"id": "Nc", "type": "Concept"}, "target": {"id": "Nm", "type": "Concept"}, "type": "CONNECTS_TO"}, {"source": {"id": "Lechner et al., 2018", "type": "Reference"}, "target": {"id": "recurrent connections", "type": "Concept"}, "type": "DESCRIBES"}, {"source": {"id": "Figure 1(a)", "type": "Figure"}, "target": {"id": "connectome of NCPs", "type": "Concept"}, "type": "ILLUSTRATES"}, {"source": {"id": "Proofs", "type": "Concept"}, "target": {"id": "Deriving Closed-form (Exact) Solution", "type": "Concept"}, "type": "CONTAINS"}, {"source": {"id": "\u03d5", "type": "Parameter"}, "target": {"id": "nonlinear functions", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "nonlinear functions", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "\u03d5", "type": "Parameter"}, "target": {"id": "input u", "type": "Concept"}, "type": "OF"}, {"source": {"id": "\u03c9\u03c4", "type": "Parameter"}, "target": {"id": "input u", "type": "Concept"}, "type": "OF"}, {"source": {"id": "input u", "type": "Concept"}, "target": {"id": "q", "type": "Parameter"}, "type": "COMPRISES"}, {"source": {"id": "input u", "type": "Concept"}, "target": {"id": "k", "type": "Parameter"}, "type": "COMPRISES"}, {"source": {"id": "Exact Closed-Form Solution", "type": "Concept"}, "target": {"id": "frozen-coefficient approximation", "type": "Concept"}, "type": "DERIVED_BY"}, {"source": {"id": "frozen-coefficient approximation", "type": "Concept"}, "target": {"id": "John, F.", "type": "Person"}, "type": "BASED_ON"}, {"source": {"id": "Linear First-Order ODE", "type": "Concept"}, "target": {"id": "integrating factor", "type": "Concept"}, "type": "HAS"}], "source": {"page_content": "from 151.54 MB to 150.85 MB. In constrast, decreasing the Top- _K_ selection from _PW_ to _k_ = 2 drastically reduces memory consumption from 5042 MB to 44.75 MB, demonstrating the flexibility of NAC.\n**Interpreting the Results:** From the experiments, we observe that increasing the sparsity of the NAC layer improves the robustness of the system and leads to higher overall accuracy. Similarly, increasing the Top- _K_ interactions enhances accuracy too; however, the benefits diminish as memory consumption grows. Using Exact mode, Top- _K_ =8 with 50% sparsity achieves the best balance between accuracy and efficiency. Steady mode is the fastest, while Euler mode handles adaptive temporal dynamics.\n\n\n**4. Discussions**\n\n\n\nThis research is part of ongoing work on biologically plausible attention mechanisms and represents a pioneering step, with limitations to be addressed in future work.\n\n**Architectural improvement:** Currently, NAC uses predetermined wiring (AutoNCP) requiring three inputs: number of units (sensory + interneuron + motor), output motor neurons, and sparsity, with typically 60% of units assigned to sensory neurons. To integrate with the attention mechanism while preserving wiring, sensory units for _NN_ sensory are set as unitssensory = \ufffd _d_ model0 _.\u2212_ 6 0 _._ 5 \ufffd and backbone units as\n\n\n\nare set as unitssensory = \ufffd _d_ model0 _.\u2212_ 6 0 _._ 5 \ufffd and backbone units as\n\nunits _backbone_ = _d_ model + \ufffd _d_ 0model _._ 6 \ufffd, where _\u2308\u00b7\u2309_ and _\u230a\u00b7\u230b_ denote\n\n\n\nunits _backbone_ = _d_ model + \ufffd _d_ 0model _._ 6 \ufffd, where _\u2308\u00b7\u2309_ and _\u230a\u00b7\u230b_ denote\n\nthe ceiling and floor functions, respectively. This results in a larger overall architectural size and increased runtime.\n\n\n\nFuture work will support user-defined NCPs configurations or randomized wiring to enable more efficient architectures.\n**Learnable sparse Top-** _**K**_ **selection:** Sparse Top- _K_ attention can miss important context, is sensitive to _k_, and may be harder to optimize. A further limitation is that it still computes the full _QK_ _[\u22a4]_ matrix, which can dominate the cost for very long sequences. Future work includes adaptive or learnable Top- _K_ selection, improved key scoring, and hardware-aware optimization to strengthen accuracy and robustness.\n\n\n**5. Conclusion**\n\n\nIn this paper, we introduce the Neuronal Attention Circuit (NAC), a biologically inspired attention mechanism that reformulates attention logits as the solution to a first-order ODE modulated by nonlinear, interlinked gates derived from repurposing _C.elegans_ nematode NCPs. NAC bridges discrete attention with continuous-time dynamics, enabling adaptive temporal processing without the limitations inherent to traditional scaled dot-product attention. Based on the solution to ODE, we introduce three computational modes: (i) Euler, based on _explicit Euler_ integration; (ii) Exact, providing closed-form solutions; and (iii) Steady, approximating equilibrium states. In addition, a sparse Top- _K_ pairwise concatenation scheme is introduced to mitigate the memory intensity. Theoretically, we establish NAC\u2019s log-state stability, exponential error bounds, and universal approximation, thereby providing rigorous guarantees of convergence and expressiveness. Empirical evaluations demonstrate that NAC achieves state-of-the-art performance across diverse tasks, including irregularly sampled time-series benchmarks, autonomous vehicle lane-keeping, and industrial prognostics. Moreover, NAC occupies an intermediate position between CT-RNNs and CT-Attention, offering robust temporal modeling while requiring less runtime than CT-RNNs and less memory than CT-Attention models.\n\n\n**Reproducibility Statement**\n\n\nThe code for reproducibility is available at [https://github.com/itxwaleedrazzaq/neuronal_attention_circuit]\n\n[neuronal_attention_circuit]\n\n\n**Impact Statement**\n\n\nThe work addresses the growing field of continuous-time attention and pioneers a biologically plausible mechanism. It encourages research into sparse, adaptive networks that resemble natural wiring. From a societal perspective, it supports more robust AI in resource-limited settings, but it also raises ethical concerns when applied to areas such as surveillance or autonomous systems.\n\n\n\n8\n\n\n**Neuronal Attention Circuit (NAC) for Representation Learning**\n\n\n\n**References**\n\n\nIntroduction to self-driving cars. URL [https://www.udacity.com/course/intro-to-self-driving-cars--nd113]\n\n[intro-to-self-driving-cars--nd113.]\n\n\nAguiar-Conraria, L. and Soares, M. J. The continuous wavelet transform: Moving beyond uni-and bivariate analysis. _Journal of economic surveys_, 28(2):344\u2013375, 2014.\n\n\nBeltagy, I., Peters, M. E., and Cohan, A. Longformer: The long-document transformer. _arXiv preprint_ _arXiv:2004.05150_, 2020.\n\n\nBojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L. D., Monfort, M., Muller, U., Zhang, J., et al. End to end learning for self-driving cars. _arXiv preprint arXiv:1604.07316_, 2016.\n\n\nBrockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., and Zaremba, W. Openai gym. _arXiv preprint arXiv:1606.01540_, 2016.\n\n\nCao, Y., Li, S., Petzold, L., and Serban, R. Adjoint sensitivity analysis for differential-algebraic equations: The adjoint dae system and its numerical solution. _SIAM_ _journal on scientific computing_, 24(3):1076\u20131089, 2003.\n\n\nChen, R. T., Rubanova, Y., Bettencourt, J., and Duvenaud, D. K. Neural ordinary differential equations. _Advances_ _in neural information processing systems_, 31, 2018.\n\n\nChen, Y., Ren, K., Wang, Y., Fang, Y., Sun, W., and Li, D. Contiformer: Continuous-time transformer for irregular time series modeling. _Advances in Neural Information_ _Processing Systems_, 36:47143\u201347175, 2023.\n\n\nChien, J.-T. and Chen, Y.-H. Continuous-time attention for sequential learning. In _Proceedings of the AAAI confer-_ _ence on artificial intelligence_, volume 35, pp. 7116\u20137124, 2021.\n\n\nCho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau,\u00a8 D., Bougares, F., Schwenk, H., and Bengio, Y. Learning phrase representations using rnn encoder-decoder for statistical machine translation. _arXiv preprint_ _arXiv:1406.1078_, 2014.\n\n\nd\u2019Ascoli, S., Becker, S., Mathis, A., Schwaller, P., and Kilbertus, N. Odeformer: Symbolic regression of dynamical systems with transformers. _arXiv preprint_ _arXiv:2310.05573_, 2023.\n\n\nDe Brouwer, E., Simm, J., Arany, A., and Moreau, Y. Gru-ode-bayes: Continuous modeling of sporadicallyobserved time series. _Advances in neural information_ _processing systems_, 32, 2019.\n\n\nDeng, L. The mnist database of handwritten digit images for machine learning research [best of the web]. _IEEE_ _signal processing magazine_, 29(6):141\u2013142, 2012.\n\n\nDing, Y., Jia, M., Miao, Q., and Huang, P. Remaining useful life estimation using deep metric transfer learning for kernel regression. _Reliability Engineering & System_ _Safety_, 212:107583, 2021.\n\n\nHasani, R., Lechner, M., Amini, A., Rus, D., and Grosu, R. Liquid time-constant networks. In _Proceedings of the_ _AAAI Conference on Artificial Intelligence_, volume 35, pp. 7657\u20137666, 2021.\n\n\nHasani, R., Lechner, M., Amini, A., Liebenwein, L., Ray, A., Tschaikowski, M., Teschl, G., and Rus, D. Closed form continuous-time neural networks. _Nature Machine_\n\n_Intelligence_, 4(11):992\u20131003, 2022.\n\n\nHochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. _Interna-_ _tional Journal of Uncertainty, Fuzziness and Knowledge-_ _Based Systems_, 6(02):107\u2013116, 1998.\n\n\nHochreiter, S. and Schmidhuber, J. Long short-term memory. _Neural computation_, 9(8):1735\u20131780, 1997.\n\n\nHong, H. S. and Thuan, N. Hust bearing: a practical dataset for ball bearing fault diagnosis. _Mendeley Data_, 3, 2023.\n\n\nJohn, F. On integration of parabolic equations by difference methods: I. linear and quasi-linear equations for the infinite interval. _Communications on Pure and Applied_ _Mathematics_, 5(2):155\u2013211, 1952.\n\n\nJordan, M. I. Serial order: A parallel distributed processing approach. In _Advances in psychology_, volume 121, pp. 471\u2013495. Elsevier, 1997.\n\n\nLechner, M. and Hasani, R. Mixed-memory rnns for learning long-term dependencies in irregularly sampled time series. 2022.\n\n\nLechner, M., Hasani, R. M., and Grosu, R. Neuronal circuit policies. _arXiv preprint arXiv:1803.08554_, 2018.\n\n\nLechner, M., Hasani, R., Amini, A., Henzinger, T. A., Rus, D., and Grosu, R. Neural circuit policies enabling auditable autonomy. _Nature Machine Intelligence_, 2(10):\n642\u2013652, 2020.\n\n\nLeCun, Y., Touresky, D., Hinton, G., and Sejnowski, T. A theoretical framework for back-propagation. In _Proceed-_ _ings of the 1988 connectionist models summer school_, volume 1, pp. 21\u201328, 1988.\n\n\nLin, J. and Qu, L. Feature extraction based on morlet wavelet and its application for mechanical fault diagnosis. _Journal of sound and vibration_, 234(1):135\u2013148, 2000.\n\n\n\n9\n\n\n**Neuronal Attention Circuit (NAC) for Representation Learning**\n\n\n\nNectoux, P., Gouriveau, R., Medjaher, K., Ramasso, E., Chebel-Morello, B., Zerhouni, N., and Varnier, C. Pronostia: An experimental platform for bearings accelerated degradation tests. In _IEEE International Conference on_ _Prognostics and Health Management, PHM\u201912._, pp. 1\u20138. IEEE Catalog Number: CPF12PHM-CDR, 2012.\n\n\nNeil, D., Pfeiffer, M., and Liu, S.-C. Phased lstm: Accelerating recurrent network training for long or event-based sequences. _Advances in neural information processing_ _systems_, 29, 2016.\n\n\nNishijima, T. Universal approximation theorem for neural networks. _arXiv preprint arXiv:2102.10993_, 2021.\n\n\nPark, M., Kim, H., and Park, S. A convolutional neural network-based end-to-end self-driving using lidar and camera fusion: Analysis perspectives in a real-world environment. _Electronics_, 10(21):2608, 2021.\n\n\nRazzaq, W. and Hongwei, M. Neural circuit policies imposing visual perceptual autonomy. _Neural Processing_ _Letters_, 55(7):9101\u20139116, 2023.\n\n\nRazzaq, W. and Zhao, Y.-B. Carle: a hybrid deep-shallow learning framework for robust and explainable rul estimation of rolling element bearings. _Soft Computing_, 29(23):\n6269\u20136292, 2025a.\n\n\nRazzaq, W. and Zhao, Y.-B. Developing distance-aware uncertainty quantification methods in physics-guided neural networks for reliable bearing health prediction, 2025b.\n[URL https://arxiv.org/abs/2512.08499.]\n\n\nRoy, A., Saffar, M., Vaswani, A., and Grangier, D. Efficient content-based sparse attention with routing transformers. _Transactions of the Association for Computational_ _Linguistics_, 9:53\u201368, 2021.\n\n\nRubanova, Y., Chen, R. T., and Duvenaud, D. K. Latent ordinary differential equations for irregularly-sampled time series. _Advances in neural information processing_ _systems_, 32, 2019.\n\n\nRumelhart, D. E., Hinton, G. E., and Williams, R. J. Learning internal representations by error propagation. Technical report, 1985.\n\n\nShibuya, N. Car behavioral cloning, 2017. URL [https://github.com/naokishibuya/car-behavioral-cloning]\n\n[car-behavioral-cloning.] Accessed: 202510-05.\n\n\nShukla, S. N. and Marlin, B. M. Multi-time attention networks for irregularly sampled time series. _arXiv preprint_ _arXiv:2101.10318_, 2021.\n\n\n\nStinchcomb, M. Multilayered feedforward networks are universal approximators. _Neural Networks_, 2:356\u2013359,\n1989.\n\n\nTay, Y., Bahri, D., Yang, L., Metzler, D., and Juan, D.-C. Sparse sinkhorn attention. In _International conference on_ _machine learning_, pp. 9438\u20139447. PMLR, 2020.\n\n\nThuan, N. D. and Hong, H. S. Hust bearing: a practical dataset for ball bearing fault diagnosis. _BMC research_ _notes_, 16(1):138, 2023.\n\n\nTiang, Y., Gelernter, J. R., Wang, X., Chen, W., Gao, J., Zhang, Y., and Li, X. Lane marking detection via fast end-to-end deep convolutional neural network that is our patch proposal network (ppn). 2018.\n\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., and Polosukhin, I. Attention is all you need. _Advances in neural information_ _processing systems_, 30, 2017.\n\n\nVidulin, V., Lustrek, M., Kaluza, B., Piltaver, R., and Krivec, J. Localization Data for Person Activity. UCI Machine Learning Repository, 2010. DOI:\nhttps://doi.org/10.24432/C57G8X.\n\n\nWang, B., Lei, Y., Li, N., et al. Xjtu-sy bearing datasets. _GitHub, GitHub Repository_, 2018.\n\n\nZaheer, M., Guruganesh, G., Dubey, K. A., Ainslie, J., Alberti, C., Ontanon, S., Pham, P., Ravula, A., Wang, Q., Yang, L., et al. Big bird: Transformers for longer sequences. _Advances in neural information processing_ _systems_, 33:17283\u201317297, 2020.\n\n\nZhuang, J., Dvornek, N., Li, X., Tatikonda, S., Papademetris, X., and Duncan, J. Adaptive checkpoint adjoint method for gradient estimation in neural ode. In _International_ _Conference on Machine Learning_, pp. 11639\u201311649. PMLR, 2020.\n\n\nZhuang, J., Jia, M., Ding, Y., and Ding, P. Temporal convolution-based transferable cross-domain adaptation approach for remaining useful life estimation under variable failure behaviors. _Reliability Engineering & System_ _Safety_, 216:107946, 2021.\n\n\n\n10\n\n\n**Neuronal Attention Circuit (NAC) for Representation Learning**\n\n\n\n**Appendix**\n\n\n**A. Preliminaries**\n\n\n**A.1. Attention Mechanism**\n\n\nAttention mechanisms have become a cornerstone in\n\nmodern neural architectures, enabling models to dynamically focus on relevant parts of the input. The concept\nwas first introduced in the context of neural machine\ntranslation, where it allowed the decoder to weight encoder\noutputs according to their importance for generating each\ntarget token. Formally, given a query vector _q \u2208_ R _[d]_, key\nvectors _K_ = [ _k_ 1 _, k_ 2 _, . . ., kn_ ] _\u2208_ R _[n][\u00d7][d]_, and value vectors\n_V_ = [ _v_ 1 _, v_ 2 _, . . ., vn_ ] _\u2208_ R _[n][\u00d7][d]_, the attention mechanism can\nbe expressed in two steps:\n\n\n1. Compute the scaled dot attention logits:\n\n\n_ai_ = _[q][T][ k][i]_ (21)\n~_\u221a_~\n_d_\n\n\n2. Normalize the logits to get attention weights and compute the output:\n\n\n_e_ _[a][i]_\n_\u03b1i_ = softmax( _ai_ ) = ~_n_~ (22)\n~\ufffd~ _j_ =1 _[e][a][j]_\n\n\n\nAttention( _q, k, v_ ) =\n\n\n\n_n_\n\ufffd _\u03b1ivi_ (23)\n\n\n_i_ =1\n\n\n\nHere, _ai_ is the raw attention logit between the query and\neach key, and the scaling factor _\u221ad_ prevents large dot prod\nucts from destabilizing the softmax (Vaswani et al., 2017).\n\n\n**A.2. Neuronal Circuit Policies (NCPs)**\n\n\nexhibit a resting potential at _\u2212_ 70 mV and an activation potential near _\u2212_ 20 mV. Similarly, each _Nm_ is composed of\ntwo subneurons, _Mp_ and _Mn_, and is driven by a controllable variable _y_, which also maps to a biologically plausible\nrange [ _\u2212_ 70 mV _, \u2212_ 20 mV]. The connections in the NCP\narchitecture are designed to reflect the biological sparsity\nand abstraction of neural circuits. Specifically, connections\nfrom _Ns_ to _Ni_ are feedforward, while those between _Nc_\nand _Nm_ are highly recurrent (Lechner et al., 2018). Figure\n1(a) illustrates the connectome of NCPs.\n\n\n**B. Proofs**\n\n\nIn this section, we provide all the proofs.\n\n\n**B.1. Deriving Closed-form (Exact) Solution**\n\n\nAlthough _\u03d5_ and _\u03c9\u03c4_ are nonlinear functions of the input\n**u** = [ **q** ; **k** ], we derive closed-form solution by treating them\nas locally constant over the pseudo-time integration interval\nfor each query\u2013key pair based on frozen-coefficient approximation (John, 1952). This is accurate whenever the interval\nis short or when input variations are slow compared with\nthe relaxation rate _\u03c9\u03c4_ . Under approximation assumption,\nrewrite Eqn. 1 as\n\n\n_dadtt_ [+] _[ \u03c9][\u03c4]_ _[a][t]_ [ =] _[ \u03d5.]_ (24)\n\n\nThis is now a linear first-order ODE. The integrating factor\nis", "metadata": null}}
{"nodes": [{"id": "Nm", "type": "Component"}, {"id": "Mp", "type": "Component"}, {"id": "Mn", "type": "Component"}, {"id": "y", "type": "Variable"}, {"id": "NCP architecture", "type": "Architecture"}, {"id": "biological sparsity", "type": "Concept"}, {"id": "abstraction of neural circuits", "type": "Concept"}, {"id": "Ns", "type": "Component"}, {"id": "Ni", "type": "Component"}, {"id": "Nc", "type": "Component"}, {"id": "Lechner et al., 2018", "type": "Publication"}, {"id": "Figure 1(a)", "type": "Figure"}, {"id": "connectome of NCPs", "type": "Concept"}, {"id": "Proofs", "type": "Section"}, {"id": "Deriving Closed-form (Exact) Solution", "type": "Section"}, {"id": "\u03d5", "type": "Variable"}, {"id": "\u03c9\u03c4", "type": "Variable"}, {"id": "nonlinear functions", "type": "Concept"}, {"id": "input u", "type": "Input"}, {"id": "q", "type": "Variable"}, {"id": "k", "type": "Variable"}, {"id": "closed-form solution", "type": "Concept"}, {"id": "pseudo-time integration interval", "type": "Concept"}, {"id": "query\u2013key pair", "type": "Concept"}, {"id": "frozen-coefficient approximation", "type": "Method"}, {"id": "John, F.", "type": "Person"}, {"id": "John, F. (1952)", "type": "Publication"}, {"id": "accuracy", "type": "Concept"}, {"id": "interval length", "type": "Concept"}, {"id": "input variations", "type": "Concept"}, {"id": "relaxation rate \u03c9\u03c4", "type": "Variable"}, {"id": "Equation 1", "type": "Equation"}, {"id": "Equation 24", "type": "Equation"}, {"id": "approximation assumption", "type": "Concept"}, {"id": "linear first-order ODE", "type": "Concept"}, {"id": "Ordinary Differential Equations (ODEs)", "type": "Concept"}, {"id": "integrating factor \u00b5", "type": "Variable"}, {"id": "Equation 25", "type": "Equation"}, {"id": "Equation 26", "type": "Equation"}, {"id": "derivative", "type": "Concept"}, {"id": "Equation 27", "type": "Equation"}, {"id": "integration", "type": "Concept"}, {"id": "Equation 28", "type": "Equation"}, {"id": "Equation 29", "type": "Equation"}, {"id": "Equation 30", "type": "Equation"}, {"id": "Equation 31", "type": "Equation"}, {"id": "Equation 32", "type": "Equation"}, {"id": "a*", "type": "Variable"}, {"id": "a0", "type": "Variable"}, {"id": "at", "type": "Variable"}, {"id": "Proof of Theorem 1", "type": "Section"}, {"id": "Theorem 1", "type": "Theorem"}, {"id": "single-connection case M=1", "type": "Case"}, {"id": "multi-connection case M>1", "type": "Case"}, {"id": "CASE 1: Single Connection (M=1)", "type": "Case"}, {"id": "Equation 33", "type": "Equation"}, {"id": "A", "type": "Variable"}, {"id": "equilibrium", "type": "Concept"}, {"id": "Upper bound", "type": "Concept"}, {"id": "Equation 34", "type": "Equation"}, {"id": "Lower bound", "type": "Concept"}, {"id": "Equation 35", "type": "Equation"}, {"id": "interval [m, M]", "type": "Concept"}, {"id": "forward-invariant", "type": "Concept"}, {"id": "Remark 1", "type": "Remark"}, {"id": "continuous-time attention state", "type": "Concept"}, {"id": "well-defined interval", "type": "Concept"}, {"id": "per-connection equilibria", "type": "Concept"}, {"id": "state trajectory", "type": "Concept"}, {"id": "closed-form equilibrium solution", "type": "Concept"}, {"id": "Equation 18", "type": "Equation"}, {"id": "CASE 2: Multiple Connections (M>1)", "type": "Case"}, {"id": "Equation 37", "type": "Equation"}, {"id": "Aj", "type": "Variable"}, {"id": "\u03d5j", "type": "Variable"}, {"id": "fj", "type": "Variable"}, {"id": "effective equilibrium", "type": "Concept"}, {"id": "Equation 38", "type": "Equation"}, {"id": "weights fj", "type": "Variable"}, {"id": "convex combination", "type": "Concept"}, {"id": "A_min", "type": "Variable"}, {"id": "A_max", "type": "Variable"}, {"id": "Equation 39", "type": "Equation"}, {"id": "Equation 40", "type": "Equation"}, {"id": "Equation 41", "type": "Equation"}, {"id": "Proof for Theorem 2", "type": "Section"}, {"id": "Theorem 2", "type": "Theorem"}, {"id": "NAC layer", "type": "Component"}, {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, {"id": "nonlinear activations", "type": "Concept"}, {"id": "universal approximator", "type": "Concept"}, {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, {"id": "self-attention", "type": "Mechanism"}, {"id": "single-token input x", "type": "Input"}, {"id": "R^n", "type": "Space"}, {"id": "sequence length T", "type": "Variable"}, {"id": "steady mode", "type": "Concept"}, {"id": "NCP sparsity s", "type": "Variable"}, {"id": "full connectivity", "type": "Concept"}, {"id": "Backbone Network", "type": "Component"}, {"id": "function \u03d5", "type": "Function"}, {"id": "R^(2d)", "type": "Space"}, {"id": "error \u03b4", "type": "Concept"}, {"id": "stacked layers", "type": "Concept"}, {"id": "multi-head", "type": "Concept"}, {"id": "H", "type": "Variable"}, {"id": "target complexity", "type": "Concept"}, {"id": "output projection Wo", "type": "Component"}, {"id": "UAT proofs", "type": "Concept"}, {"id": "Stinchcomb, M.", "type": "Person"}, {"id": "Stinchcomb, M. (1989)", "type": "Publication"}, {"id": "Input Projections", "type": "Section"}, {"id": "input x", "type": "Input"}, {"id": "NCP-based sensory projections", "type": "Mechanism"}, {"id": "v", "type": "Variable"}, {"id": "q proj", "type": "Function"}, {"id": "k proj", "type": "Function"}, {"id": "v proj", "type": "Function"}, {"id": "R^(d_model)", "type": "Space"}, {"id": "emulation", "type": "Concept"}, {"id": "In", "type": "Function"}, {"id": "identity function", "type": "Function"}, {"id": "Head Splitting and Sparse Top-K Pairwise Computation", "type": "Section"}, {"id": "H heads", "type": "Concept"}, {"id": "q(h)", "type": "Variable"}, {"id": "k(h)", "type": "Variable"}, {"id": "R^d", "type": "Space"}, {"id": "head h", "type": "Concept"}, {"id": "sparse top-k pairs", "type": "Concept"}, {"id": "K_eff", "type": "Variable"}, {"id": "concatenated pair u(h)", "type": "Variable"}, {"id": "R^(2d)", "type": "Space"}, {"id": "Computation of phi(h) and omega_tau(h)", "type": "Section"}, {"id": "scalar phi(h)", "type": "Variable"}, {"id": "NCP-based inter-to-motor projection", "type": "Mechanism"}, {"id": "Equation 42", "type": "Equation"}, {"id": "sigma(z)", "type": "Function"}, {"id": "sigmoid", "type": "Function"}, {"id": "continuous scalar function phi~", "type": "Function"}, {"id": "multi-layer networks", "type": "Model"}, {"id": "omega_tau(h)", "type": "Variable"}, {"id": "softplus", "type": "Function"}, {"id": "epsilon", "type": "Variable"}, {"id": "Equation 43", "type": "Equation"}, {"id": "weights", "type": "Concept"}, {"id": "constant", "type": "Concept"}, {"id": "steady-mode logit", "type": "Concept"}, {"id": "a(h)", "type": "Variable"}, {"id": "w(h)", "type": "Variable"}, {"id": "b(h)", "type": "Variable"}, {"id": "sigmoid hidden unit", "type": "Component"}, {"id": "Attention Weights and output", "type": "Section"}, {"id": "alpha(h)", "type": "Variable"}, {"id": "head output y(h)", "type": "Variable"}, {"id": "Output Projection", "type": "Section"}, {"id": "Y", "type": "Variable"}, {"id": "R^H", "type": "Space"}, {"id": "final dense layer", "type": "Component"}, {"id": "g(x)", "type": "Function"}, {"id": "bo", "type": "Variable"}, {"id": "R^m", "type": "Space"}, {"id": "Equation 44", "type": "Equation"}, {"id": "H units", "type": "Concept"}, {"id": "continuous function f", "type": "Function"}, {"id": "compact K", "type": "Concept"}, {"id": "accuracy epsilon", "type": "Concept"}, {"id": "Training, Gradients and Complexity", "type": "Section"}, {"id": "Gradient Characterization", "type": "Section"}, {"id": "sensitivity analysis", "type": "Concept"}, {"id": "dynamics", "type": "Concept"}, {"id": "learnable parameters", "type": "Concept"}, {"id": "closed-form derivatives", "type": "Concept"}, {"id": "gradients", "type": "Concept"}, {"id": "system", "type": "Concept"}, {"id": "parameterizations", "type": "Concept"}, {"id": "vanishing or exploding gradients", "type": "Concept"}, {"id": "TRAJECTORY SENSITIVITIES FOR CLOSED-FORM FORMULATION", "type": "Section"}, {"id": "Equation 45", "type": "Equation"}], "relationships": [{"source": {"id": "Nm", "type": "Component"}, "target": {"id": "Mp", "type": "Component"}, "type": "COMPOSED_OF"}, {"source": {"id": "Nm", "type": "Component"}, "target": {"id": "Mn", "type": "Component"}, "type": "COMPOSED_OF"}, {"source": {"id": "y", "type": "Variable"}, "target": {"id": "Nm", "type": "Component"}, "type": "DRIVES"}, {"source": {"id": "NCP architecture", "type": "Architecture"}, "target": {"id": "biological sparsity", "type": "Concept"}, "type": "REFLECTS"}, {"source": {"id": "NCP architecture", "type": "Architecture"}, "target": {"id": "abstraction of neural circuits", "type": "Concept"}, "type": "REFLECTS"}, {"source": {"id": "Ns", "type": "Component"}, "target": {"id": "Ni", "type": "Component"}, "type": "FEEDFORWARD"}, {"source": {"id": "Nc", "type": "Component"}, "target": {"id": "Nm", "type": "Component"}, "type": "RECURRENT"}, {"source": {"id": "Lechner et al., 2018", "type": "Publication"}, "target": {"id": "Nc", "type": "Component"}, "type": "IDENTIFIES_CONNECTION_BETWEEN"}, {"source": {"id": "Lechner et al., 2018", "type": "Publication"}, "target": {"id": "Nm", "type": "Component"}, "type": "IDENTIFIES_CONNECTION_BETWEEN"}, {"source": {"id": "Figure 1(a)", "type": "Figure"}, "target": {"id": "connectome of NCPs", "type": "Concept"}, "type": "ILLUSTRATES"}, {"source": {"id": "Proofs", "type": "Section"}, "target": {"id": "Deriving Closed-form (Exact) Solution", "type": "Section"}, "type": "HAS_SUBSECTION"}, {"source": {"id": "\u03d5", "type": "Variable"}, "target": {"id": "nonlinear functions", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "\u03c9\u03c4", "type": "Variable"}, "target": {"id": "nonlinear functions", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "\u03d5", "type": "Variable"}, "target": {"id": "input u", "type": "Input"}, "type": "IS_FUNCTION_OF"}, {"source": {"id": "\u03c9\u03c4", "type": "Variable"}, "target": {"id": "input u", "type": "Input"}, "type": "IS_FUNCTION_OF"}, {"source": {"id": "input u", "type": "Input"}, "target": {"id": "q", "type": "Variable"}, "type": "COMPRISED_OF"}, {"source": {"id": "input u", "type": "Input"}, "target": {"id": "k", "type": "Variable"}, "type": "COMPRISED_OF"}, {"source": {"id": "closed-form solution", "type": "Concept"}, "target": {"id": "frozen-coefficient approximation", "type": "Method"}, "type": "DERIVED_USING"}, {"source": {"id": "frozen-coefficient approximation", "type": "Method"}, "target": {"id": "pseudo-time integration interval", "type": "Concept"}, "type": "APPLIED_OVER"}, {"source": {"id": "frozen-coefficient approximation", "type": "Method"}, "target": {"id": "query\u2013key pair", "type": "Concept"}, "type": "APPLIED_FOR"}, {"source": {"id": "John, F. (1952)", "type": "Publication"}, "target": {"id": "John, F.", "type": "Person"}, "type": "HAS_AUTHOR"}, {"source": {"id": "frozen-coefficient approximation", "type": "Method"}, "target": {"id": "John, F. (1952)", "type": "Publication"}, "type": "DESCRIBED_IN"}, {"source": {"id": "accuracy", "type": "Concept"}, "target": {"id": "interval length", "type": "Concept"}, "type": "DEPENDS_ON"}, {"source": {"id": "accuracy", "type": "Concept"}, "target": {"id": "input variations", "type": "Concept"}, "type": "RELATED_TO"}, {"source": {"id": "accuracy", "type": "Concept"}, "target": {"id": "relaxation rate \u03c9\u03c4", "type": "Variable"}, "type": "RELATED_TO"}, {"source": {"id": "Equation 1", "type": "Equation"}, "target": {"id": "Equation 24", "type": "Equation"}, "type": "REWRITTEN_AS"}, {"source": {"id": "Equation 1", "type": "Equation"}, "target": {"id": "approximation assumption", "type": "Concept"}, "type": "REWRITTEN_UNDER"}, {"source": {"id": "Equation 24", "type": "Equation"}, "target": {"id": "linear first-order ODE", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "linear first-order ODE", "type": "Concept"}, "target": {"id": "Ordinary Differential Equations (ODEs)", "type": "Concept"}, "type": "IS_A_TYPE_OF"}, {"source": {"id": "integrating factor \u00b5", "type": "Variable"}, "target": {"id": "Equation 25", "type": "Equation"}, "type": "DEFINED_BY"}, {"source": {"id": "Equation 24", "type": "Equation"}, "target": {"id": "Equation 26", "type": "Equation"}, "type": "TRANSFORMED_INTO"}, {"source": {"id": "integrating factor \u00b5", "type": "Variable"}, "target": {"id": "Equation 26", "type": "Equation"}, "type": "USED_FOR_TRANSFORMATION"}, {"source": {"id": "Equation 26", "type": "Equation"}, "target": {"id": "Equation 27", "type": "Equation"}, "type": "LHS_EQUIVALENT_TO"}, {"source": {"id": "Equation 27", "type": "Equation"}, "target": {"id": "integration", "type": "Concept"}, "type": "UNDERGOES"}, {"source": {"id": "Equation 27", "type": "Equation"}, "target": {"id": "Equation 28", "type": "Equation"}, "type": "INTEGRATED_TO"}, {"source": {"id": "Equation 28", "type": "Equation"}, "target": {"id": "Equation 29", "type": "Equation"}, "type": "COMPUTES_INTEGRAL"}, {"source": {"id": "Equation 28", "type": "Equation"}, "target": {"id": "Equation 30", "type": "Equation"}, "type": "SUBSTITUTED_TO_YIELD"}, {"source": {"id": "Equation 30", "type": "Equation"}, "target": {"id": "Equation 31", "type": "Equation"}, "type": "REARRANGED_TO"}, {"source": {"id": "Equation 31", "type": "Equation"}, "target": {"id": "Equation 32", "type": "Equation"}, "type": "REARRANGED_TO"}, {"source": {"id": "a*", "type": "Variable"}, "target": {"id": "\u03d5", "type": "Variable"}, "type": "DEFINED_BY"}, {"source": {"id": "a*", "type": "Variable"}, "target": {"id": "\u03c9\u03c4", "type": "Variable"}, "type": "DEFINED_BY"}, {"source": {"id": "at", "type": "Variable"}, "target": {"id": "a*", "type": "Variable"}, "type": "EXPRESSED_IN_TERMS_OF"}, {"source": {"id": "at", "type": "Variable"}, "target": {"id": "a0", "type": "Variable"}, "type": "EXPRESSED_IN_TERMS_OF"}, {"source": {"id": "Proof of Theorem 1", "type": "Section"}, "target": {"id": "Theorem 1", "type": "Theorem"}, "type": "PROVES"}, {"source": {"id": "Proof of Theorem 1", "type": "Section"}, "target": {"id": "single-connection case M=1", "type": "Case"}, "type": "HAS_PART"}, {"source": {"id": "Proof of Theorem 1", "type": "Section"}, "target": {"id": "multi-connection case M>1", "type": "Case"}, "type": "HAS_PART"}, {"source": {"id": "Proof of Theorem 1", "type": "Section"}, "target": {"id": "CASE 1: Single Connection (M=1)", "type": "Case"}, "type": "INCLUDES"}, {"source": {"id": "Equation 33", "type": "Equation"}, "target": {"id": "CASE 1: Single Connection (M=1)", "type": "Case"}, "type": "REDUCES_TO_FOR"}, {"source": {"id": "A", "type": "Variable"}, "target": {"id": "equilibrium", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "Upper bound", "type": "Concept"}, "target": {"id": "Equation 34", "type": "Equation"}, "type": "EVALUATED_AT"}, {"source": {"id": "Lower bound", "type": "Concept"}, "target": {"id": "Equation 35", "type": "Equation"}, "type": "EVALUATED_AT"}, {"source": {"id": "interval [m, M]", "type": "Concept"}, "target": {"id": "forward-invariant", "type": "Concept"}, "type": "IS"}, {"source": {"id": "Remark 1", "type": "Remark"}, "target": {"id": "continuous-time attention state", "type": "Concept"}, "type": "STATES"}, {"source": {"id": "continuous-time attention state", "type": "Concept"}, "target": {"id": "well-defined interval", "type": "Concept"}, "type": "CONVERGES_WITHIN"}, {"source": {"id": "well-defined interval", "type": "Concept"}, "target": {"id": "per-connection equilibria", "type": "Concept"}, "type": "DICTATED_BY"}, {"source": {"id": "state trajectory", "type": "Concept"}, "target": {"id": "closed-form equilibrium solution", "type": "Concept"}, "type": "CONVERGES_TO"}, {"source": {"id": "state trajectory", "type": "Concept"}, "target": {"id": "single-connection case M=1", "type": "Case"}, "type": "CONVERGES_IN"}, {"source": {"id": "closed-form equilibrium solution", "type": "Concept"}, "target": {"id": "Equation 18", "type": "Equation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "Proof of Theorem 1", "type": "Section"}, "target": {"id": "CASE 2: Multiple Connections (M>1)", "type": "Case"}, "type": "INCLUDES"}, {"source": {"id": "Equation 37", "type": "Equation"}, "target": {"id": "CASE 2: Multiple Connections (M>1)", "type": "Case"}, "type": "DESCRIBES_ODE_FOR"}, {"source": {"id": "Aj", "type": "Variable"}, "target": {"id": "\u03d5j", "type": "Variable"}, "type": "DEFINED_BY"}, {"source": {"id": "Aj", "type": "Variable"}, "target": {"id": "fj", "type": "Variable"}, "type": "DEFINED_BY"}, {"source": {"id": "effective equilibrium", "type": "Concept"}, "target": {"id": "Equation 38", "type": "Equation"}, "type": "DEFINED_BY"}, {"source": {"id": "A", "type": "Variable"}, "target": {"id": "convex combination", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "A", "type": "Variable"}, "target": {"id": "Aj", "type": "Variable"}, "type": "IS_CONVEX_COMBINATION_OF"}, {"source": {"id": "weights fj", "type": "Variable"}, "target": {"id": "A", "type": "Variable"}, "type": "INFLUENCES"}, {"source": {"id": "A", "type": "Variable"}, "target": {"id": "A_min", "type": "Variable"}, "type": "IS_IN_RANGE"}, {"source": {"id": "A", "type": "Variable"}, "target": {"id": "A_max", "type": "Variable"}, "type": "IS_IN_RANGE"}, {"source": {"id": "A", "type": "Variable"}, "target": {"id": "Equation 39", "type": "Equation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "Upper bound", "type": "Concept"}, "target": {"id": "Equation 40", "type": "Equation"}, "type": "CALCULATED_BY"}, {"source": {"id": "Lower bound", "type": "Concept"}, "target": {"id": "Equation 41", "type": "Equation"}, "type": "CALCULATED_BY"}, {"source": {"id": "Proof for Theorem 2", "type": "Section"}, "target": {"id": "Theorem 2", "type": "Theorem"}, "type": "PROVES"}, {"source": {"id": "Proof for Theorem 2", "type": "Section"}, "target": {"id": "NAC layer", "type": "Component"}, "type": "SHOWS_EMULATION_BY"}, {"source": {"id": "NAC layer", "type": "Component"}, "target": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "type": "EMULATES"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "nonlinear activations", "type": "Concept"}, "type": "USES"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "universal approximator", "type": "Concept"}, "type": "IS_A"}, {"source": {"id": "universal approximator", "type": "Concept"}, "target": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "type": "SUPPORTED_BY"}, {"source": {"id": "Proof for Theorem 2", "type": "Section"}, "target": {"id": "self-attention", "type": "Mechanism"}, "type": "ASSUMES"}, {"source": {"id": "self-attention", "type": "Mechanism"}, "target": {"id": "single-token input x", "type": "Input"}, "type": "ON"}, {"source": {"id": "single-token input x", "type": "Input"}, "target": {"id": "R^n", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "sequence length T", "type": "Variable"}, "target": {"id": "1", "type": "Concept"}, "type": "IS_SET_TO"}, {"source": {"id": "Proof for Theorem 2", "type": "Section"}, "target": {"id": "steady mode", "type": "Concept"}, "type": "FOCUSES_ON"}, {"source": {"id": "NCP sparsity s", "type": "Variable"}, "target": {"id": "0", "type": "Concept"}, "type": "SET_TO"}, {"source": {"id": "NCP sparsity s", "type": "Variable"}, "target": {"id": "full connectivity", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "full connectivity", "type": "Concept"}, "target": {"id": "Backbone Network", "type": "Component"}, "type": "ENSURES"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "function \u03d5", "type": "Function"}, "type": "APPROXIMATES"}, {"source": {"id": "function \u03d5", "type": "Function"}, "target": {"id": "R^(2d)", "type": "Space"}, "type": "MAPS_FROM"}, {"source": {"id": "function \u03d5", "type": "Function"}, "target": {"id": "[0,1]", "type": "Concept"}, "type": "MAPS_TO"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "error \u03b4", "type": "Concept"}, "type": "APPROXIMATES_WITH"}, {"source": {"id": "Backbone Network", "type": "Component"}, "target": {"id": "stacked layers", "type": "Concept"}, "type": "APPROXIMATES_VIA"}, {"source": {"id": "H", "type": "Variable"}, "target": {"id": "target complexity", "type": "Concept"}, "type": "SCALED_PROPORTIONALLY_TO"}, {"source": {"id": "output projection Wo", "type": "Component"}, "target": {"id": "aggregation", "type": "Concept"}, "type": "PERFORMS"}, {"source": {"id": "aggregation", "type": "Concept"}, "target": {"id": "UAT proofs", "type": "Concept"}, "type": "AS_IN"}, {"source": {"id": "UAT proofs", "type": "Concept"}, "target": {"id": "Stinchcomb, M. (1989)", "type": "Publication"}, "type": "CITED_FROM"}, {"source": {"id": "Stinchcomb, M. (1989)", "type": "Publication"}, "target": {"id": "Stinchcomb, M.", "type": "Person"}, "type": "HAS_AUTHOR"}, {"source": {"id": "Input Projections", "type": "Section"}, "target": {"id": "input x", "type": "Input"}, "type": "PROJECTS"}, {"source": {"id": "input x", "type": "Input"}, "target": {"id": "NCP-based sensory projections", "type": "Mechanism"}, "type": "PROJECTED_VIA"}, {"source": {"id": "NCP-based sensory projections", "type": "Mechanism"}, "target": {"id": "query q", "type": "Variable"}, "type": "YIELDS"}, {"source": {"id": "NCP-based sensory projections", "type": "Mechanism"}, "target": {"id": "key k", "type": "Variable"}, "type": "YIELDS"}, {"source": {"id": "NCP-based sensory projections", "type": "Mechanism"}, "target": {"id": "v", "type": "Variable"}, "type": "YIELDS"}, {"source": {"id": "query q", "type": "Variable"}, "target": {"id": "q proj", "type": "Function"}, "type": "DEFINED_BY"}, {"source": {"id": "key k", "type": "Variable"}, "target": {"id": "k proj", "type": "Function"}, "type": "DEFINED_BY"}, {"source": {"id": "v", "type": "Variable"}, "target": {"id": "v proj", "type": "Function"}, "type": "DEFINED_BY"}, {"source": {"id": "query q", "type": "Variable"}, "target": {"id": "R^(d_model)", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "key k", "type": "Variable"}, "target": {"id": "R^(d_model)", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "v", "type": "Variable"}, "target": {"id": "R^(d_model)", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "q proj", "type": "Function"}, "target": {"id": "In", "type": "Function"}, "type": "SET_TO"}, {"source": {"id": "k proj", "type": "Function"}, "target": {"id": "In", "type": "Function"}, "type": "SET_TO"}, {"source": {"id": "q proj", "type": "Function"}, "target": {"id": "emulation", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "k proj", "type": "Function"}, "target": {"id": "emulation", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "In", "type": "Function"}, "target": {"id": "identity function", "type": "Function"}, "type": "IS_AN"}, {"source": {"id": "identity function", "type": "Function"}, "target": {"id": "R^n", "type": "Space"}, "type": "ON"}, {"source": {"id": "input", "type": "Concept"}, "target": {"id": "H heads", "type": "Concept"}, "type": "SPLIT_INTO"}, {"source": {"id": "H heads", "type": "Concept"}, "target": {"id": "q(h)", "type": "Variable"}, "type": "YIELDS_PER"}, {"source": {"id": "H heads", "type": "Concept"}, "target": {"id": "k(h)", "type": "Variable"}, "type": "YIELDS_PER"}, {"source": {"id": "q(h)", "type": "Variable"}, "target": {"id": "R^d", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "k(h)", "type": "Variable"}, "target": {"id": "R^d", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "head h", "type": "Concept"}, "target": {"id": "q(h)", "type": "Variable"}, "type": "ASSOCIATED_WITH"}, {"source": {"id": "head h", "type": "Concept"}, "target": {"id": "k(h)", "type": "Variable"}, "type": "ASSOCIATED_WITH"}, {"source": {"id": "sparse top-k pairs", "type": "Concept"}, "target": {"id": "sequence length T", "type": "Variable"}, "type": "COMPUTED_FOR"}, {"source": {"id": "sequence length T", "type": "Variable"}, "target": {"id": "K_eff", "type": "Variable"}, "type": "RESULTS_IN"}, {"source": {"id": "K_eff", "type": "Variable"}, "target": {"id": "concatenated pair u(h)", "type": "Variable"}, "type": "YIELDS"}, {"source": {"id": "concatenated pair u(h)", "type": "Variable"}, "target": {"id": "q(h)", "type": "Variable"}, "type": "COMPOSED_OF"}, {"source": {"id": "concatenated pair u(h)", "type": "Variable"}, "target": {"id": "k(h)", "type": "Variable"}, "type": "COMPOSED_OF"}, {"source": {"id": "concatenated pair u(h)", "type": "Variable"}, "target": {"id": "R^(2d)", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "scalar phi(h)", "type": "Variable"}, "target": {"id": "NCP-based inter-to-motor projection", "type": "Mechanism"}, "type": "COMPUTED_VIA"}, {"source": {"id": "NCP-based inter-to-motor projection", "type": "Mechanism"}, "target": {"id": "concatenated pair u(h)", "type": "Variable"}, "type": "APPLIED_ON"}, {"source": {"id": "scalar phi(h)", "type": "Variable"}, "target": {"id": "Equation 42", "type": "Equation"}, "type": "DEFINED_BY"}, {"source": {"id": "Equation 42", "type": "Equation"}, "target": {"id": "sigma(z)", "type": "Function"}, "type": "USES"}, {"source": {"id": "sigma(z)", "type": "Function"}, "target": {"id": "sigmoid", "type": "Function"}, "type": "IS_A"}, {"source": {"id": "NCP architecture", "type": "Architecture"}, "target": {"id": "continuous scalar function phi~", "type": "Function"}, "type": "APPROXIMATES"}, {"source": {"id": "approximation", "type": "Concept"}, "target": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "type": "SUPPORTED_BY"}, {"source": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "target": {"id": "multi-layer networks", "type": "Model"}, "type": "FOR"}, {"source": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "target": {"id": "Stinchcomb, M. (1989)", "type": "Publication"}, "type": "CITED_FROM"}, {"source": {"id": "omega_tau(h)", "type": "Variable"}, "target": {"id": "softplus", "type": "Function"}, "type": "COMPUTED_VIA"}, {"source": {"id": "omega_tau(h)", "type": "Variable"}, "target": {"id": "Equation 43", "type": "Equation"}, "type": "DEFINED_BY"}, {"source": {"id": "Equation 43", "type": "Equation"}, "target": {"id": "epsilon", "type": "Variable"}, "type": "USES"}, {"source": {"id": "weights", "type": "Concept"}, "target": {"id": "omega_tau(h)", "type": "Variable"}, "type": "SET_TO_MAKE"}, {"source": {"id": "omega_tau(h)", "type": "Variable"}, "target": {"id": "constant", "type": "Concept"}, "type": "IS"}, {"source": {"id": "steady-mode logit", "type": "Concept"}, "target": {"id": "a(h)", "type": "Variable"}, "type": "SIMPLIFIES_TO"}, {"source": {"id": "a(h)", "type": "Variable"}, "target": {"id": "scalar phi(h)", "type": "Variable"}, "type": "EQUALS"}, {"source": {"id": "a(h)", "type": "Variable"}, "target": {"id": "omega_tau(h)", "type": "Variable"}, "type": "EQUALS"}, {"source": {"id": "a(h)", "type": "Variable"}, "target": {"id": "sigmoid hidden unit", "type": "Component"}, "type": "EMULATES"}, {"source": {"id": "sigmoid hidden unit", "type": "Component"}, "target": {"id": "w(h)", "type": "Variable"}, "type": "USES"}, {"source": {"id": "sigmoid hidden unit", "type": "Component"}, "target": {"id": "b(h)", "type": "Variable"}, "type": "USES"}, {"source": {"id": "Attention Weights and output", "type": "Section"}, "target": {"id": "softmax", "type": "Function"}, "type": "USES"}, {"source": {"id": "softmax", "type": "Function"}, "target": {"id": "alpha(h)", "type": "Variable"}, "type": "YIELDS"}, {"source": {"id": "sequence length T", "type": "Variable"}, "target": {"id": "alpha(h)", "type": "Variable"}, "type": "INFLUENCES"}, {"source": {"id": "head output y(h)", "type": "Variable"}, "target": {"id": "alpha(h)", "type": "Variable"}, "type": "COMPUTED_FROM"}, {"source": {"id": "head output y(h)", "type": "Variable"}, "target": {"id": "v(h)", "type": "Variable"}, "type": "COMPUTED_FROM"}, {"source": {"id": "v proj", "type": "Function"}, "target": {"id": "v(h)", "type": "Variable"}, "type": "SET_TO_YIELD"}, {"source": {"id": "head output y(h)", "type": "Variable"}, "target": {"id": "sigma(z)", "type": "Function"}, "type": "APPROXIMATES_AS"}, {"source": {"id": "Y", "type": "Variable"}, "target": {"id": "head output y(h)", "type": "Variable"}, "type": "IS_CONCATENATION_OF"}, {"source": {"id": "Y", "type": "Variable"}, "target": {"id": "R^H", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "final dense layer", "type": "Component"}, "target": {"id": "Y", "type": "Variable"}, "type": "APPLIED_TO"}, {"source": {"id": "final dense layer", "type": "Component"}, "target": {"id": "g(x)", "type": "Function"}, "type": "YIELDS"}, {"source": {"id": "g(x)", "type": "Function"}, "target": {"id": "Equation 44", "type": "Equation"}, "type": "DEFINED_BY"}, {"source": {"id": "Equation 44", "type": "Equation"}, "target": {"id": "Y", "type": "Variable"}, "type": "USES"}, {"source": {"id": "Equation 44", "type": "Equation"}, "target": {"id": "output projection Wo", "type": "Component"}, "type": "USES"}, {"source": {"id": "Equation 44", "type": "Equation"}, "target": {"id": "bo", "type": "Variable"}, "type": "USES"}, {"source": {"id": "g(x)", "type": "Function"}, "target": {"id": "R^m", "type": "Space"}, "type": "IS_IN"}, {"source": {"id": "g(x)", "type": "Function"}, "target": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "type": "MATCHES"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "H units", "type": "Concept"}, "type": "HAS"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "continuous function f", "type": "Function"}, "type": "APPROXIMATES"}, {"source": {"id": "continuous function f", "type": "Function"}, "target": {"id": "compact K", "type": "Concept"}, "type": "ON"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "accuracy epsilon", "type": "Concept"}, "type": "APPROXIMATES_TO"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "Universal Approximation Theorem (UAT)", "type": "Theorem"}, "type": "BY_THEORY"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "w(h)", "type": "Variable"}, "type": "CONFIGURED_BY"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "b(h)", "type": "Variable"}, "type": "CONFIGURED_BY"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "output projection Wo", "type": "Component"}, "type": "CONFIGURED_BY"}, {"source": {"id": "single-hidden-layer feedforward neural network", "type": "Model"}, "target": {"id": "bo", "type": "Variable"}, "type": "CONFIGURED_BY"}, {"source": {"id": "Training, Gradients and Complexity", "type": "Section"}, "target": {"id": "Gradient Characterization", "type": "Section"}, "type": "HAS_SUBSECTION"}, {"source": {"id": "Gradient Characterization", "type": "Section"}, "target": {"id": "sensitivity analysis", "type": "Concept"}, "type": "ANALYZES"}, {"source": {"id": "sensitivity analysis", "type": "Concept"}, "target": {"id": "dynamics", "type": "Concept"}, "type": "PERTAINS_TO"}, {"source": {"id": "sensitivity analysis", "type": "Concept"}, "target": {"id": "learnable parameters", "type": "Concept"}, "type": "WITH_RESPECT_TO"}, {"source": {"id": "Gradient Characterization", "type": "Section"}, "target": {"id": "closed-form derivatives", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "steady state", "type": "Concept"}, "type": "OF"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "trajectory at", "type": "Concept"}, "type": "OF"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Variable"}, "type": "WITH_RESPECT_TO"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Variable"}, "type": "WITH_RESPECT_TO"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "gradients", "type": "Concept"}, "type": "EXPLAIN_FLOW_OF"}, {"source": {"id": "gradients", "type": "Concept"}, "target": {"id": "system", "type": "Concept"}, "type": "FLOW_THROUGH"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "parameterizations", "type": "Concept"}, "type": "GUIDE_SELECTION_OF"}, {"source": {"id": "parameterizations", "type": "Concept"}, "target": {"id": "vanishing or exploding gradients", "type": "Concept"}, "type": "AVOIDS"}, {"source": {"id": "Gradient Characterization", "type": "Section"}, "target": {"id": "TRAJECTORY SENSITIVITIES FOR CLOSED-FORM FORMULATION", "type": "Section"}, "type": "HAS_SUBSECTION"}, {"source": {"id": "trajectory at", "type": "Concept"}, "target": {"id": "Equation 45", "type": "Equation"}, "type": "DEFINED_BY"}], "source": {"page_content": "exhibit a resting potential at _\u2212_ 70 mV and an activation potential near _\u2212_ 20 mV. Similarly, each _Nm_ is composed of two subneurons, _Mp_ and _Mn_, and is driven by a controllable variable _y_, which also maps to a biologically plausible range [ _\u2212_ 70 mV _, \u2212_ 20 mV]. The connections in the NCP architecture are designed to reflect the biological sparsity and abstraction of neural circuits. Specifically, connections from _Ns_ to _Ni_ are feedforward, while those between _Nc_ and _Nm_ are highly recurrent (Lechner et al., 2018). Figure 1(a) illustrates the connectome of NCPs.B. ProofsIn this section, we provide all the proofs.B.1. Deriving Closed-form (Exact) SolutionAlthough _\u03d5_ and _\u03c9\u03c4_ are nonlinear functions of the input **u** = [ **q** ; **k** ], we derive closed-form solution by treating them as locally constant over the pseudo-time integration interval for each query\u2013key pair based on frozen-coefficient approximation (John, 1952). This is accurate whenever the interval is short or when input variations are slow compared with the relaxation rate _\u03c9\u03c4_ . Under approximation assumption, rewrite Eqn. 1 asEqn. 24.This is now a linear first-order ODE. The integrating factor isAttention( _q, k, v_ ) =_n_ \ufffd _\u03b1ivi_ (23)_i_ =1Here, _ai_ is the raw attention logit between the query and each key, and the scaling factor _\u221ad_ prevents large dot prod ucts from destabilizing the softmax (Vaswani et al., 2017).A.2. Neuronal Circuit Policies (NCPs)NCPs represent a biologically inspired framework for developing interpretable neural control agents by adapting the tap-withdrawal circuit found in the nematode _C. elegans_ (Lechner et al., 2018). Unlike traditional spiking neural networks, the majority of neurons in this circuit exhibit electronic dynamics, characterized by the passive flow of electrical charges, resulting in graded potentials. NCPs are structured as a four-layer hierarchical architecture comprising sensory neurons ( _Ns_ ), interneurons ( _Ni_ ), command neurons ( _Nc_ ), and motor neurons ( _Nm_ ). The _Ns_ perceive and respond to external stimulus inputs and are responsible for the initial signal transduction. Each _Ns_ consists of subneurons _Sp_ and _Sn_ and a system variable _x_ . The activation of _Sp_ and _Sn_ depends upon the sign of _x_ : _Sp_ becomes activated for _x >_ 0, whereas _Sn_ becomes activated for _x <_ 0. The variable _x_ is mapped to the membrane potential range of [ _\u2212_ 70 mV _, \u2212_ 20 mV], which is consistent with the biophysical behavior of nerve cells, which typically\ufffd _\u03c9\u03c4 dt_ _\u00b5_ = _e_ \ufffd \ufffd= _e_ _[\u03c9][\u03c4][ t]_ _._ (25)Multiply both sides by _\u00b5_ ( _t_ ):_[da][t]_ _e_ _[\u03c9][\u03c4][ t]_ _dt_ [+] _[ \u03c9][\u03c4]_ _[e][\u03c9][\u03c4][ t][a][t]_ [ =] _[ \u03d5e][\u03c9][\u03c4][ t][.]_ (26)Recognize the left-hand side as the derivative of _e_ _[\u03c9][\u03c4][ t]_ _at_ :_d_ \ufffd _e_ _[\u03c9][\u03c4][ t]_ _at_ \ufffd = _\u03d5e_ _[\u03c9][\u03c4][ t]_ _._ (27)_dt_Integrate from 0 to _t_ :_t_ _e_ _[\u03c9][\u03c4][ t]_ _at \u2212_ _e_ [0] _a_ 0 = _\u03d5_ _e_ _[\u03c9][\u03c4][ s]_ _ds._ (28)\ufffd0Compute the integral (since _\u03c9\u03c4 \u0338_ = 0):\ufffd0 _t_ _e_ _[\u03c9][\u03c4][ s]_ _ds_ = [1] 0 _\u03c9\u03c4_ \ufffd _e_ _[\u03c9][\u03c4][ t]_ _\u2212_ 1\ufffd _._ (29)_\u03c9\u03c4_11Rearrange:_e_ _[\u03c9][\u03c4][ t]_ _at_ = _a_ 0 + _[\u03d5]_ _\u03c9\u03c4_\ufffd _e_ _[\u03c9][\u03c4][ t]_ _\u2212_ 1\ufffd _._ (31)Divide both sides by _e_ _[\u03c9][\u03c4][ t]_ :_at_ = _a_ 0 _e_ _[\u2212][\u03c9][\u03c4][ t]_ + _[\u03d5]_ _\u03c9\u03c4_\ufffd1 _\u2212_ _e_ _[\u2212][\u03c9][\u03c4][ t]_ [\ufffd] _._ (32)Set _a_ _[\u2217]_ := _[\u03d5]_ . Then _at_ = _a_ _[\u2217]_ + ( _a_ 0 _\u2212_ _a_ _[\u2217]_ ) _e_ _[\u2212][\u03c9][\u03c4][ t]_, proved._\u03c9\u03c4_**B.2. Proof of Theorem 1**We divide the proof into two parts: (i) the single-connection case _M_ = 1, and (ii) the general multi-connection case _M >_ 1. The main technique is to evaluate the ODE at boundary values of the proposed invariant interval and show that the derivative points inward, ensuring that trajectoriescannot escape.CASE 1: SINGLE CONNECTION ( _M_ = 1).The ODE reduces to_da_ _A_ = _[\u03d5]_ _dt_ [=] _[ \u2212][\u03c9][\u03c4]_ _[a]_ [ +] _[ \u03d5]_ [ =] _[ \u2212][\u03c9][\u03c4]_ [(] _[a][ \u2212]_ _[A]_ [)] _[,]_ _\u03c9_ _._ (33)_\u03c9\u03c4_Here _A_ is the unique equilibrium. We now check both bounds.- _Upper bound:_ Let _M_ = max(0 _, A_ ). At _a_ = _M_,_da_ (34)_dt_ \ufffd\ufffd\ufffd _a_ = _M_ [=] _[ \u2212][\u03c9][\u03c4]_ [(] _[M][ \u2212]_ _[A]_ [)] _[.]_If _A \u2265_ 0, then _M_ = _A_ and _[da]_ If _A \u2265_ 0, then _M_ = _A_ and _dt_ [= 0][. If] _[ A <]_ [ 0][, then] _[ M]_ [ = 0][,]so _[da]_ _dt_ [=] _[ \u2212][\u03c9][\u03c4]_ [(0] _[ \u2212]_ _[A]_ [) =] _[ \u03c9][\u03c4]_ _[A][ \u2264]_ [0][ since] _[ A <]_ [ 0][. In both]cases, _[da]_ _[\u2264]_ [0][. Thus trajectories cannot cross above] _[ M]_ [.]_dt_ _[\u2264]_ [0][. Thus trajectories cannot cross above] _[ M]_ [.]- _Lower bound:_ Let _m_ = min(0 _, A_ ). At _a_ = _m_,_da_ (35)_dt_ \ufffd\ufffd\ufffd _a_ = _m_ [=] _[ \u2212][\u03c9][\u03c4]_ [(] _[m][ \u2212]_ _[A]_ [)] _[.]_If _A \u2264_ 0, then _m_ = _A_ and _[da]_ _dt_ [= 0][. If] _[ A >]_ [ 0][, then] _m_ = 0, so _[da]_ _dt_ [=] _[ \u2212][\u03c9][\u03c4]_ [(0] _[ \u2212]_ _[A]_ [) =] _[ \u03c9][\u03c4]_ _[A][ \u2265]_ [0][. In both cases,]_dadt_ _[\u2265]_ [0][. Thus trajectories cannot cross below] _[ m]_ [. Therefore,]the interval [ _m, M_ ] is forward-invariant.To see this explicitly under Euler discretization with step size \u2206 _t >_ 0,_a_ ( _t_ + \u2206 _t_ ) = _at_ + \u2206 _t \u00b7_ _[da]_ (36)_dt_ _[.]_At _a_ = _M_, _[da]_ _dt_ _[\u2264]_ [0 =] _[\u21d2]_ _[a]_ [(] _[t]_ [ + \u2206] _[t]_ [)] _[ \u2264]_ _[M]_ [. At] _[ a]_ [ =] _[ m]_ [,]_dadt_ _[\u2265]_ [0 =] _[\u21d2]_ _[a]_ [(] _[t]_ [ + \u2206] _[t]_ [)] _[ \u2265]_ _[m]_ [. By induction over steps,]_at \u2208_ [ _m, M_ ] for all _t \u2208_ [0 _, T_ ].12**Neuronal Attention Circuit (NAC) for Representation Learning**CASE 2: MULTIPLE CONNECTIONS ( _M >_ 1).The ODE iswith per-connection equilibria _Aj_ = _\u03d5j/fj_ . The effective equilibrium is_da_ _dt_ [=] _[ \u2212]_ \ufffd \ufffd _[M]_ \ufffd _fj_ \ufffd _a_ +_j_ =1_M_ \ufffd _fjAj,_ (37)_j_ =1_A_ =\ufffd _Mj_ =1 _[f][j][A][j]_ ~~\ufffd~~ _Mj_ =1 _[f][j]_ _._ (38)Since the weights ~~\ufffd~~ _fjfj_ are positive and sum to 1, _A_ is a convex combination of _{Aj}_ . Therefore,_A \u2208_ [ _A_ [min] _, A_ [max] ] _._ (39)- _Upper bound:_ Let _M_ = max(0 _, A_ [max] ). Then_da_ _dt_ \ufffd\ufffd\ufffd _a_ = _M_ [=]_M_ \ufffd _fj_ ( _Aj \u2212_ _M_ ) _._ (40)_j_ =1Since _Aj \u2264_ _A_ [max] _\u2264_ _M_, each term ( _Aj_ _\u2212M_ ) _\u2264_ 0, and thus \ufffd _fj_ ( _Aj \u2212_ _M_ ) _\u2264_ 0. Hence _dadt_ _[\u2264]_ [0][, proving trajectories]cannot exceed _M_ .- _Lower bound:_ Let _m_ = min(0 _, A_ [min] ). Then_da_ _dt_ \ufffd\ufffd\ufffd _a_ = _m_ [=]_M_ \ufffd _fj_ ( _Aj \u2212_ _m_ ) _._ (41)_j_ =1Since _Aj \u2265_ _A_ [min] _\u2265_ _m_, each ( _Aj \u2212_ _m_ ) _\u2265_ 0, so [\ufffd] _fj_ ( _Aj \u2212_ _m_ ) _\u2265_ 0. Hence _[da]_ _dt_ _[\u2265]_ [0][, proving trajectories cannot fall]below _m_ . Thus, the interval [ _m, M_ ] is forward-invariant._Remark_ 1 _._ This result guarantees that the continuous-time attention state converges within a well-defined interval dictated by the per-connection equilibria. In particular, for the single-connection case ( _M_ = 1), the state trajectory converges monotonically toward the closed-form equilibrium solution (Eqn. 18) without overshoot.**B.3. Proof for Theorem 2**The proof proceeds constructively by showing that the NAC layer can emulate a single-hidden-layer feedforward neural network with nonlinear activations, which is a universal approximator under the Universal Approximation Theorem (UAT). We assume self-attention on a single-token input _x \u2208_ R _[n]_ (setting sequence length _T_ = 1) and focus on the steady mode for simplicity. Without loss of generality, set _d_ model = _n_ + _m_ or adjust as needed for dimensionality.Constructively, set NCP sparsity _s_ = 0 for full connectivity, ensuring the backbone\u02dc _NN_ backbone approximates any _\u03d5_ : R [2] _[d]_ _\u2192_ [0 _,_ 1] with error _< \u03b4_ via stacked layers. For12**Neuronal Attention Circuit (NAC) for Representation Learning**multi-head, scale _H_ proportionally to target complexity, with output projection _Wo_ aggregating as in classical UAT proofs (Stinchcomb, 1989).**Input Projections:** The input _x_ is projected via NCPbased sensory projections to obtain query _q_ = _q_ proj( _x_ ), key _k_ = _k_ proj( _x_ ), and value _v_ = _v_ proj( _x_ ), each in R _[d]_ [model] . For emulation, set _q_ proj = _k_ proj = _In_ (identity on R _[n]_ ) and adjust**Head Splitting and Sparse Top-** _**k**_ **Pairwise Computation:**Split into _H_ heads, yielding _q_ [(] _[h]_ [)] _, k_ [(] _[h]_ [)] _\u2208_ R _[d]_ per head _h_, where _d_ = _d_ model _/H_ . For _T_ = 1, compute sparse top-_k_ pairs, but since _T_ = 1, _K_ eff = 1, yielding concatenated pair _u_ [(] _[h]_ [)] = [ _q_ [(] _[h]_ [)] ; _k_ [(] _[h]_ [)] ] _\u2208_ R [2] _[d]_ . Since _q_ [(] _[h]_ [)] = _k_ [(] _[h]_ [)], this is[ _x_ [(] _[h]_ [)] ; _x_ [(] _[h]_ [)] ], but the NCP processes it generally.**Computation of** _\u03d5_ [(] _[h]_ [)] **and** _\u03c9\u03c4_ [(] _[h]_ [)] **:** The scalar _\u03d5_ [(] _[h]_ [)] is computed via the NCP-based inter-to-motor projection on the pair:_\u03d5_ [(] _[h]_ [)] = _\u03c3_ ( _NN_ backbone( _u_ [(] _[h]_ [)] )) (42)where _\u03c3_ ( _z_ ) = (1 + _e_ _[\u2212][z]_ ) _[\u2212]_ [1] is the sigmoid. This NCP, with sufficiently large units and low sparsity, approximates any continuous scalar function _\u03d5_ [\u02dc] : R [2] _[d]_ _\u2192_ [0 _,_ 1] to arbitrary precision on compact sets (by the UAT for multi-layer networks (Stinchcomb, 1989)). Similarly, _\u03c9\u03c4_ [(] _[h]_ [)] is computed via:_\u03c9\u03c4_ [(] _[h]_ [)] = softplus( _NN_ backbone( _u_ [(] _[h]_ [)] )) + _\u03b5,_ _\u03b5 >_ 0 (43)By setting weights to make _\u03c9\u03c4_ [(] _[h]_ [)] _\u2261_ 1 (constant), the steadymode logit simplifies to _a_ [(] _[h]_ [)] = _\u03d5_ [(] _[h]_ [)] _/\u03c9\u03c4_ [(] _[h]_ [)] = _\u03d5_ [(] _[h]_ [)] . Thus,_a_ [(] _[h]_ [)] _\u2248_ _\u03c3_ \ufffd _w_ [(] _[h]_ [)] _x_ + _b_ [(] _[h]_ [)][\ufffd] for chosen weights _w_ [(] _[h]_ [)] _, b_ [(] _[h]_ [)], emulating a sigmoid hidden unit.**Attention Weights and output:** For _T_ = 1, the softmax over one \u201ckey\u201d yields _\u03b1_ [(] _[h]_ [)] = exp( _a_ [(] _[h]_ [)] ) _/_ exp( _a_ [(] _[h]_ [)] ) = 1.The head output is _y_ [(] _[h]_ [)] = \ufffd _T_ _[\u03b1]_ [(] _[h]_ [)] _[v]_ [(] _[h]_ [)] _[dt]_ [. Set] _[ v]_ [proj][ such that] _v_ [(] _[h]_ [)] = 1 (scalar), yielding _y_ [(] _[h]_ [)] _\u2248_ _\u03c3_ \ufffd _w_ [(] _[h]_ [)] _x_ + _b_ [(] _[h]_ [)][\ufffd] . For vector-valued _v_ [(] _[h]_ [)], more complex combinations are possible, but scalars suffice here.**Output Projection:** Concatenate head outputs: _Y_ = [ _y_ [(1)] ; _y_ [(2)] ; _. . ._ ; _y_ [(] _[H]_ [)] ] _\u2208_ R _[H]_ . Apply the final dense layer:_g_ ( _x_ ) = ( _Y \u00b7 Wo_ ) + _bo \u2208_ R _[m]_ _._ (44)With _y_ [(] _[h]_ [)] _\u2248_ _\u03c3_ \ufffd _w_ [(] _[h]_ [)] _x_ + _b_ [(] _[h]_ [)][\ufffd], this matches a single-hiddenlayer network with _H_ units. By the UAT, for large _H_, such networks approximate any continuous _f_ on compact _K_ to accuracy _\u03f5_, by choosing appropriate _w_ [(] _[h]_ [)] _, b_ [(] _[h]_ [)] _, Wo, bo_ .**C. Training, Gradients and Complexity**C.1. Gradient CharacterizationWe analyze the sensitivity of the dynamics with respect to the underlying learnable parameters. Specifically, we compute closed-form derivatives of both the steady state and the full trajectory _at_ with respect to the parameters _\u03d5_ and _\u03c9\u03c4_ . These expressions illuminate how gradients flow through the system, and provide guidance for selecting parameterizations that avoid vanishing or exploding gradients.C.1.1. TRAJECTORY SENSITIVITIES FOR CLOSED-FORM FORMULATIONThe trajectory is given by_at_ = _a_ _[\u2217]_ + ( _a_ 0 _\u2212_ _a_ _[\u2217]_ ) _e_ _[\u2212][\u03c9][\u03c4][ t]_ _,_ (45)", "metadata": null}}
{"nodes": [{"id": "dynamics", "type": "Concept"}, {"id": "learnable parameters", "type": "Concept"}, {"id": "closed-form derivatives", "type": "Concept"}, {"id": "steady state", "type": "Concept"}, {"id": "full trajectory", "type": "Concept"}, {"id": "at", "type": "Concept"}, {"id": "parameters", "type": "Concept"}, {"id": "\u03d5", "type": "Concept"}, {"id": "\u03c9\u03c4", "type": "Concept"}, {"id": "gradients", "type": "Concept"}, {"id": "system", "type": "Concept"}, {"id": "parameterizations", "type": "Concept"}, {"id": "vanishing gradients", "type": "Concept"}, {"id": "exploding gradients", "type": "Concept"}, {"id": "trajectory", "type": "Concept"}, {"id": "a*", "type": "Concept"}, {"id": "a0", "type": "Concept"}, {"id": "e^(-\u03c9\u03c4 t)", "type": "Concept"}, {"id": "equilibrium", "type": "Concept"}, {"id": "exponential term", "type": "Concept"}, {"id": "gradient", "type": "Concept"}, {"id": "learning", "type": "Concept"}, {"id": "slowing learning", "type": "Concept"}, {"id": "small \u03c9\u03c4", "type": "Concept"}, {"id": "large steady-state gradients", "type": "Concept"}, {"id": "optimization", "type": "Concept"}, {"id": "destabilize optimization", "type": "Concept"}, {"id": "transient term", "type": "Concept"}, {"id": "te^(-\u03c9\u03c4 t)", "type": "Concept"}, {"id": "steady-state contribution", "type": "Concept"}, {"id": "-\u03d5/\u03c9\u03c4", "type": "Concept"}, {"id": "Neural ODEs", "type": "Model"}, {"id": "Chen et al., 2018", "type": "Citation"}, {"id": "CT-RNNs", "type": "Model"}, {"id": "Rubanova et al., 2019", "type": "Citation"}, {"id": "NAC", "type": "Model"}, {"id": "differentiable computational graphs", "type": "Concept"}, {"id": "gradient-based optimization", "type": "Method"}, {"id": "adjoint sensitivity method", "type": "Method"}, {"id": "Cao et al., 2003", "type": "Citation"}, {"id": "BPTT", "type": "Method"}, {"id": "LeCun et al., 1988", "type": "Citation"}, {"id": "numerical errors", "type": "Concept"}, {"id": "Zhuang et al., 2020", "type": "Citation"}, {"id": "Table 3", "type": "Concept"}, {"id": "computational complexity", "type": "Concept"}, {"id": "sequence models", "type": "Model Type"}, {"id": "sequence prediction", "type": "Task"}, {"id": "length n", "type": "Parameter"}, {"id": "hidden dimension k", "type": "Parameter"}, {"id": "RNNs", "type": "Model"}, {"id": "Attention", "type": "Model"}, {"id": "linearly", "type": "Concept"}, {"id": "O(nk)", "type": "Complexity Metric"}, {"id": "quadratically", "type": "Concept"}, {"id": "O(n^2k)", "type": "Complexity Metric"}, {"id": "ODE-based models", "type": "Model Type"}, {"id": "LNNs", "type": "Model"}, {"id": "multiplicative factor S", "type": "Parameter"}, {"id": "solver steps", "type": "Concept"}, {"id": "single-time-step prediction", "type": "Task"}, {"id": "LSTMs", "type": "Model"}, {"id": "O(k)", "type": "Complexity Metric"}, {"id": "LNN (ODEsolve)", "type": "Model"}, {"id": "O(nk * S)", "type": "Complexity Metric"}, {"id": "O(k * S)", "type": "Complexity Metric"}, {"id": "NAC-Exact", "type": "Model"}, {"id": "NAC-Euler", "type": "Model"}, {"id": "related works", "type": "Concept"}, {"id": "four subcategories", "type": "Concept"}, {"id": "RNN", "type": "Model"}, {"id": "Rumelhart et al., 1985", "type": "Citation"}, {"id": "sequential dependencies", "type": "Concept"}, {"id": "time-series data", "type": "Concept"}, {"id": "hidden state", "type": "Concept"}, {"id": "current observation", "type": "Concept"}, {"id": "previous state", "type": "Concept"}, {"id": "LSTM", "type": "Model"}, {"id": "Hochreiter & Schmidhuber, 1997", "type": "Citation"}, {"id": "input gate", "type": "Concept"}, {"id": "output gate", "type": "Concept"}, {"id": "forget gate", "type": "Concept"}, {"id": "long-term memory", "type": "Concept"}, {"id": "long-term dependencies", "type": "Concept"}, {"id": "time-series sequences", "type": "Concept"}, {"id": "GRU", "type": "Model"}, {"id": "Cho et al., 2014", "type": "Citation"}, {"id": "LSTM architecture", "type": "Concept"}, {"id": "update gate", "type": "Concept"}, {"id": "CT-RNN", "type": "Model"}, {"id": "Rubanova et al., 2019", "type": "Citation"}, {"id": "temporal dynamics", "type": "Concept"}, {"id": "differential equations", "type": "Concept"}, {"id": "hidden states", "type": "Concept"}, {"id": "irregularly sampled time-series data", "type": "Concept"}, {"id": "PhasedLSTM", "type": "Model"}, {"id": "Neil et al., 2016", "type": "Citation"}, {"id": "time gate", "type": "Concept"}, {"id": "rhythmic schedule", "type": "Concept"}, {"id": "asynchronous time-series", "type": "Concept"}, {"id": "irregularly sampled time-series", "type": "Concept"}, {"id": "GRU-ODE", "type": "Model"}, {"id": "De Brouwer et al., 2019", "type": "Citation"}, {"id": "continuous time", "type": "Concept"}, {"id": "ODEs", "type": "Concept"}, {"id": "non-uniform time intervals", "type": "Concept"}, {"id": "mmRNNs", "type": "Model"}, {"id": "Lechner & Hasani, 2022", "type": "Citation"}, {"id": "short-term memory units", "type": "Concept"}, {"id": "long-term memory units", "type": "Concept"}, {"id": "fast-changing patterns", "type": "Concept"}, {"id": "slowly evolving patterns", "type": "Concept"}, {"id": "sequential data", "type": "Concept"}, {"id": "LTC", "type": "Model"}, {"id": "Hasani et al., 2021", "type": "Citation"}, {"id": "neurons", "type": "Concept"}, {"id": "learnable time constants", "type": "Concept"}, {"id": "input-dependent time constants", "type": "Concept"}, {"id": "speed of dynamics", "type": "Concept"}, {"id": "complex temporal patterns", "type": "Concept"}, {"id": "continuous-time data", "type": "Concept"}, {"id": "CfC", "type": "Model"}, {"id": "Hasani et al., 2022", "type": "Citation"}, {"id": "LTC dynamics", "type": "Concept"}, {"id": "numerical ODE solvers", "type": "Method"}, {"id": "efficient continuous-time modeling", "type": "Concept"}, {"id": "Attention", "type": "Model"}, {"id": "Vaswani et al., 2017", "type": "Citation"}, {"id": "attention weights", "type": "Concept"}, {"id": "queries", "type": "Concept"}, {"id": "keys", "type": "Concept"}, {"id": "softmax", "type": "Technique"}, {"id": "time-step contributions", "type": "Concept"}, {"id": "Multi-Head Attention", "type": "Model"}, {"id": "parallel scaled dot-product attention mechanisms", "type": "Mechanism"}, {"id": "complex time-series modeling", "type": "Concept"}, {"id": "mTAN", "type": "Model"}, {"id": "Shukla & Marlin, 2021", "type": "Citation"}, {"id": "continuous-time embeddings", "type": "Concept"}, {"id": "time-based attention", "type": "Mechanism"}, {"id": "irregular observations", "type": "Concept"}, {"id": "fixed-length representation", "type": "Concept"}, {"id": "encoder-decoder modeling", "type": "Task"}, {"id": "CTA", "type": "Model"}, {"id": "Chien & Chen, 2021", "type": "Citation"}, {"id": "discrete-time attention", "type": "Mechanism"}, {"id": "context vectors", "type": "Concept"}, {"id": "attention scores", "type": "Concept"}, {"id": "neural networks", "type": "Model Type"}, {"id": "ODE solvers", "type": "Method"}, {"id": "irregular sequences", "type": "Concept"}, {"id": "ODEFormer", "type": "Model"}, {"id": "d\u2019Ascoli et al., 2023", "type": "Citation"}, {"id": "sequence-to-sequence transformer", "type": "Model"}, {"id": "synthetic trajectories", "type": "Concept"}, {"id": "symbolic ODE system", "type": "Concept"}, {"id": "noisy time-series data", "type": "Concept"}, {"id": "ContiFormer", "type": "Model"}, {"id": "Chen et al., 2023", "type": "Citation"}, {"id": "continuous-time Transformer", "type": "Model"}, {"id": "ODE-defined latent trajectories", "type": "Concept"}, {"id": "time-aware attention mechanism", "type": "Mechanism"}, {"id": "dynamic relationships", "type": "Concept"}, {"id": "variants", "type": "Concept"}, {"id": "ablation", "type": "Concept"}, {"id": "NAC-2k", "type": "Model Variant"}, {"id": "Top-K=2", "type": "Hyperparameter"}, {"id": "logits", "type": "Concept"}, {"id": "NAC-32k", "type": "Model Variant"}, {"id": "Top-K=32", "type": "Hyperparameter"}, {"id": "exact computation mode", "type": "Computation Mode"}, {"id": "50% Sparsity", "type": "Sparsity Level"}, {"id": "NAC-02s", "type": "Model Variant"}, {"id": "20% Sparsity", "type": "Sparsity Level"}, {"id": "NAC-09s", "type": "Model Variant"}, {"id": "90% Sparsity", "type": "Sparsity Level"}, {"id": "NAC-PW", "type": "Model Variant"}, {"id": "full pairwise concatenation", "type": "Technique"}, {"id": "input curation", "type": "Process"}, {"id": "NAC-FC", "type": "Model Variant"}, {"id": "sparse NCP gating mechanism", "type": "Mechanism"}, {"id": "fully connected layer", "type": "Neural Network Component"}, {"id": "Top-K=8", "type": "Hyperparameter"}, {"id": "explicit Euler integration method", "type": "Method"}, {"id": "NAC-Steady", "type": "Model Variant"}, {"id": "steady-state solution", "type": "Concept"}, {"id": "exact formulation", "type": "Concept"}, {"id": "NAC-Exact/05s/8k", "type": "Model Variant"}, {"id": "closed-form exact solution", "type": "Concept"}, {"id": "modes", "type": "Computation Mode"}, {"id": "\u03b4t=1.0", "type": "Parameter"}, {"id": "sensitivity", "type": "Concept"}, {"id": "\u03b4t", "type": "Parameter"}, {"id": "Figure 4", "type": "Figure"}, {"id": "MNIST Dataset", "type": "Dataset"}, {"id": "Deng, 2012", "type": "Citation"}, {"id": "computer vision", "type": "Field"}, {"id": "image classification tasks", "type": "Task"}, {"id": "70,000 grayscale images", "type": "Dataset Component"}, {"id": "handwritten digits", "type": "Concept"}, {"id": "28x28 pixels", "type": "Image Dimension"}, {"id": "60,000 training samples", "type": "Dataset Split"}, {"id": "10,000 testing samples", "type": "Dataset Split"}, {"id": "preprocessing pipeline", "type": "Method"}, {"id": "Lechner & Hasani, 2022", "type": "Citation"}, {"id": "threshold", "type": "Technique"}, {"id": "8-bit pixel values", "type": "Data Type"}, {"id": "binary values", "type": "Data Type"}, {"id": "28x28 image", "type": "Data Item"}, {"id": "one-dimensional time series", "type": "Data Structure"}, {"id": "length 784", "type": "Data Length"}, {"id": "binary time series", "type": "Data Type"}, {"id": "event-based format", "type": "Data Format"}, {"id": "encoding", "type": "Method"}, {"id": "temporal dimension", "type": "Concept"}, {"id": "sequences", "type": "Data Type"}, {"id": "784 time steps", "type": "Data Length"}, {"id": "53 time steps", "type": "Data Length"}, {"id": "sequence", "type": "Data Type"}, {"id": "fixed length of 256", "type": "Data Length"}, {"id": "time dimension", "type": "Concept"}, {"id": "one unit of time", "type": "Time Unit"}, {"id": "dataset", "type": "Dataset"}, {"id": "per-sequence classification problem", "type": "Task Type"}, {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, {"id": "compact convolutional layers", "type": "Neural Network Component"}, {"id": "counterparts baselines", "type": "Model Type"}, {"id": "Hyperparameter", "type": "Parameter"}, {"id": "architectural specifications", "type": "Specification"}, {"id": "Table 4", "type": "Table"}, {"id": "Localized Person Activity Recognition dataset", "type": "Dataset"}, {"id": "UC Irvine", "type": "Organization"}, {"id": "Vidulin et al., 2010", "type": "Citation"}, {"id": "25 recordings", "type": "Dataset Component"}, {"id": "human participants", "type": "Entity Group"}, {"id": "physical activities", "type": "Activity Type"}, {"id": "walking", "type": "Activity"}, {"id": "falling", "type": "Activity"}, {"id": "lying down", "type": "Activity"}, {"id": "lying", "type": "Activity"}, {"id": "sitting down", "type": "Activity"}, {"id": "sitting", "type": "Activity"}, {"id": "standing up from lying", "type": "Activity"}, {"id": "on all fours", "type": "Activity"}, {"id": "sitting on the ground", "type": "Activity"}, {"id": "standing up from sitting", "type": "Activity"}, {"id": "standing up from sitting on the ground", "type": "Activity"}, {"id": "experiment", "type": "Concept"}, {"id": "participant's activity", "type": "Concept"}, {"id": "inertial sensors", "type": "Sensor Type"}, {"id": "per-time-step classification problem", "type": "Task Type"}, {"id": "input data", "type": "Data Type"}, {"id": "sensor readings", "type": "Data Type"}, {"id": "four inertial measurement units", "type": "Sensor Type"}, {"id": "participants' arms", "type": "Body Part"}, {"id": "participants' feet", "type": "Body Part"}, {"id": "fixed interval of 211 ms", "type": "Time Interval"}, {"id": "recordings", "type": "Data Type"}, {"id": "phase shifts", "type": "Phenomenon"}, {"id": "participant's recordings", "type": "Data Type"}, {"id": "sequence identity", "type": "Concept"}, {"id": "elapsed time", "type": "Concept"}, {"id": "sampling period", "type": "Concept"}, {"id": "class imbalance", "type": "Problem"}, {"id": "excess samples", "type": "Data Subset"}, {"id": "overrepresented classes", "type": "Data Subset"}, {"id": "smallest class", "type": "Data Subset"}, {"id": "data", "type": "Data Type"}, {"id": "standard scaler", "type": "Preprocessing Tool"}, {"id": "90:10 ratio", "type": "Split Ratio"}, {"id": "training", "type": "Concept"}, {"id": "testing", "type": "Concept"}, {"id": "convolutional heads", "type": "Neural Network Component"}, {"id": "data collection methodology", "type": "Methodology"}, {"id": "Razzaq & Hongwei, 2023", "type": "Citation"}, {"id": "OpenAI CarRacing", "type": "Environment"}, {"id": "PPO-trained agent", "type": "Agent Type"}, {"id": "5M timesteps", "type": "Simulation Metric"}, {"id": "20 episodes", "type": "Simulation Metric"}, {"id": "48,174 RGB images", "type": "Dataset Component"}, {"id": "92x92x3", "type": "Image Dimension"}, {"id": "action labels", "type": "Data Type"}, {"id": "five discrete actions", "type": "Action Type"}, {"id": "no-act", "type": "Action"}, {"id": "move left", "type": "Action"}, {"id": "forward", "type": "Action"}, {"id": "move right", "type": "Action"}, {"id": "stop", "type": "Action"}, {"id": "10% testing", "type": "Dataset Split"}, {"id": "90% training", "type": "Dataset Split"}, {"id": "Udacity simulator", "type": "Environment"}, {"id": "vehicle", "type": "Concept"}, {"id": "50 minutes", "type": "Time Duration"}, {"id": "15647 RGB images", "type": "Dataset Component"}, {"id": "320x160x3", "type": "Image Dimension"}, {"id": "three camera streams", "type": "Input Source"}, {"id": "left camera stream", "type": "Input Source Component"}, {"id": "center camera stream", "type": "Input Source Component"}, {"id": "right camera stream", "type": "Input Source Component"}, {"id": "continuous steering values", "type": "Data Type"}, {"id": "20% testing", "type": "Dataset Split"}, {"id": "80% training", "type": "Dataset Split"}, {"id": "preprocessing", "type": "Method"}, {"id": "OpenAI-CarRacing dataset", "type": "Dataset"}, {"id": "preprocessing steps", "type": "Method"}, {"id": "Shibuya, 2017", "type": "Citation"}, {"id": "image", "type": "Data Item"}, {"id": "irrelevant regions", "type": "Image Component"}, {"id": "66x120x3", "type": "Image Dimension"}, {"id": "Images", "type": "Data Type"}, {"id": "RGB color space", "type": "Color Space"}, {"id": "YUV color space", "type": "Color Space"}, {"id": "network input", "type": "Data Type"}, {"id": "robustness", "type": "Quality Metric"}, {"id": "data augmentation techniques", "type": "Technique"}, {"id": "random flips", "type": "Augmentation Technique"}, {"id": "translations", "type": "Augmentation Technique"}, {"id": "shadow overlays", "type": "Augmentation Technique"}, {"id": "brightness variations", "type": "Augmentation Technique"}, {"id": "lateral shifts", "type": "Phenomenon"}, {"id": "diverse lighting conditions", "type": "Condition"}, {"id": "neural network architecture", "type": "Neural Network Architecture"}, {"id": "compact CNN layers", "type": "Neural Network Component"}, {"id": "spatial feature extraction", "type": "Task"}, {"id": "LNN layers", "type": "Neural Network Component"}, {"id": "comparable alternatives", "type": "Model Type"}, {"id": "hyperparameter configurations", "type": "Configuration"}, {"id": "network", "type": "Neural Network Architecture"}, {"id": "Bojarski et al., 2016", "type": "Citation"}, {"id": "latent MLP layers", "type": "Neural Network Component"}, {"id": "counterparts", "type": "Model Type"}, {"id": "saliency map", "type": "Visual Representation"}, {"id": "regions of the input", "type": "Image Component"}, {"id": "model", "type": "Model"}, {"id": "decisions", "type": "Concept"}, {"id": "Figure 5", "type": "Figure"}, {"id": "saliency maps", "type": "Visual Representation"}, {"id": "OpenAI CarRacing environment", "type": "Environment"}, {"id": "road's horizon", "type": "Location"}, {"id": "other models", "type": "Model Type"}, {"id": "sides", "type": "Location"}, {"id": "task", "type": "Task"}, {"id": "Figure 6", "type": "Figure"}, {"id": "Udacity Simulator", "type": "Environment"}, {"id": "accurate visual maps", "type": "Visual Representation"}, {"id": "attention", "type": "Concept"}, {"id": "comparable performance", "type": "Performance Metric"}, {"id": "reasonable saliency maps", "type": "Visual Representation"}, {"id": "focus", "type": "Concept"}, {"id": "scene", "type": "Environment Component"}, {"id": "relevant regions", "type": "Image Component"}, {"id": "blurry maps", "type": "Visual Representation"}, {"id": "one side of the road", "type": "Location"}, {"id": "results", "type": "Concept"}, {"id": "NAC\u2019s ability to understand task", "type": "Capability"}, {"id": "PRONOSTIA", "type": "Dataset"}, {"id": "benchmark dataset", "type": "Dataset Type"}, {"id": "condition monitoring", "type": "Field"}, {"id": "degradation estimation", "type": "Task Type"}, {"id": "rolling-element bearings", "type": "Component"}, {"id": "Nectoux et al., 2012", "type": "Citation"}, {"id": "PRONOSTIA experimental platform", "type": "Platform"}, {"id": "16 run-to-failure experiments", "type": "Experiment"}, {"id": "accelerated wear conditions", "type": "Condition"}, {"id": "Algorithm 3", "type": "Algorithm"}, {"id": "windowed signal", "type": "Signal Type"}, {"id": "Iw", "type": "Variable"}, {"id": "critical frequency", "type": "Parameter"}, {"id": "fc", "type": "Variable"}, {"id": "operating frequency", "type": "Parameter"}, {"id": "fo", "type": "Variable"}, {"id": "sampling period", "type": "Parameter"}, {"id": "Tsampling", "type": "Variable"}, {"id": "windowed physical constraints", "type": "Constraint Type"}, {"id": "tw", "type": "Variable"}, {"id": "Tw", "type": "Variable"}, {"id": "amin", "type": "Variable"}, {"id": "fmax", "type": "Variable"}, {"id": "amax", "type": "Variable"}, {"id": "fmin", "type": "Variable"}, {"id": "Wavelets", "type": "Concept"}, {"id": "\u0393 iw(a, b)", "type": "Mathematical Expression"}, {"id": "\u03c8*", "type": "Variable"}, {"id": "t", "type": "Variable"}, {"id": "a", "type": "Variable"}, {"id": "b", "type": "Variable"}, {"id": "Energy", "type": "Metric"}, {"id": "E", "type": "Variable"}, {"id": "Dominant frequency", "type": "Metric"}, {"id": "fd", "type": "Variable"}, {"id": "ascale", "type": "Variable"}, {"id": "Entropy", "type": "Metric"}, {"id": "h", "type": "Variable"}, {"id": "Kurtosis", "type": "Metric"}, {"id": "K", "type": "Variable"}, {"id": "Skewness", "type": "Metric"}, {"id": "sk", "type": "Variable"}, {"id": "mean", "type": "Metric"}, {"id": "\u00b5", "type": "Variable"}, {"id": "standard deviation", "type": "Metric"}, {"id": "\u03c3", "type": "Variable"}], "relationships": [{"source": {"id": "dynamics", "type": "Concept"}, "target": {"id": "learnable parameters", "type": "Concept"}, "type": "HAS_SENSITIVITY_TO"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "steady state", "type": "Concept"}, "type": "COMPUTED_FOR"}, {"source": {"id": "closed-form derivatives", "type": "Concept"}, "target": {"id": "full trajectory", "type": "Concept"}, "type": "COMPUTED_FOR"}, {"source": {"id": "full trajectory", "type": "Concept"}, "target": {"id": "at", "type": "Concept"}, "type": "IDENTIFIED_AS"}, {"source": {"id": "parameters", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "parameters", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Concept"}, "type": "INCLUDES"}, {"source": {"id": "gradients", "type": "Concept"}, "target": {"id": "system", "type": "Concept"}, "type": "FLOW_THROUGH"}, {"source": {"id": "parameterizations", "type": "Concept"}, "target": {"id": "vanishing gradients", "type": "Concept"}, "type": "AVOIDS"}, {"source": {"id": "parameterizations", "type": "Concept"}, "target": {"id": "exploding gradients", "type": "Concept"}, "type": "AVOIDS"}, {"source": {"id": "trajectory", "type": "Concept"}, "target": {"id": "at", "type": "Concept"}, "type": "GIVEN_BY"}, {"source": {"id": "at", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Concept"}, "type": "DEPENDS_ON"}, {"source": {"id": "at", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Concept"}, "type": "DEPENDS_ON"}, {"source": {"id": "at", "type": "Concept"}, "target": {"id": "equilibrium", "type": "Concept"}, "type": "DEPENDS_ON_THROUGH"}, {"source": {"id": "at", "type": "Concept"}, "target": {"id": "exponential term", "type": "Concept"}, "type": "DEPENDS_ON_THROUGH"}, {"source": {"id": "gradient", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Concept"}, "type": "WITH_RESPECT_TO"}, {"source": {"id": "\u03c9\u03c4", "type": "Concept"}, "target": {"id": "slowing learning", "type": "Concept"}, "type": "CAUSES_IF_LARGE"}, {"source": {"id": "slowing learning", "type": "Concept"}, "target": {"id": "\u03d5", "type": "Concept"}, "type": "OF"}, {"source": {"id": "small \u03c9\u03c4", "type": "Concept"}, "target": {"id": "large steady-state gradients", "type": "Concept"}, "type": "LEADS_TO"}, {"source": {"id": "large steady-state gradients", "type": "Concept"}, "target": {"id": "optimization", "type": "Concept"}, "type": "MAY_DESTABILIZE"}, {"source": {"id": "gradient", "type": "Concept"}, "target": {"id": "\u03c9\u03c4", "type": "Concept"}, "type": "WITH_RESPECT_TO"}, {"source": {"id": "gradient", "type": "Concept"}, "target": {"id": "transient term", "type": "Concept"}, "type": "CONTAINS"}, {"source": {"id": "transient term", "type": "Concept"}, "target": {"id": "te^(-\u03c9\u03c4 t)", "type": "Concept"}, "type": "PROPORTIONAL_TO"}, {"source": {"id": "gradient", "type": "Concept"}, "target": {"id": "steady-state contribution", "type": "Concept"}, "type": "CONTAINS"}, {"source": {"id": "steady-state contribution", "type": "Concept"}, "target": {"id": "-\u03d5/\u03c9\u03c4", "type": "Concept"}, "type": "PROPORTIONAL_TO"}, {"source": {"id": "Neural ODEs", "type": "Model"}, "target": {"id": "differentiable computational graphs", "type": "Concept"}, "type": "PRODUCES"}, {"source": {"id": "CT-RNNs", "type": "Model"}, "target": {"id": "differentiable computational graphs", "type": "Concept"}, "type": "PRODUCES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "differentiable computational graphs", "type": "Concept"}, "type": "PRODUCES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "gradient-based optimization", "type": "Method"}, "type": "TRAINED_USING"}, {"source": {"id": "gradient-based optimization", "type": "Method"}, "target": {"id": "adjoint sensitivity method", "type": "Method"}, "type": "INCLUDES"}, {"source": {"id": "gradient-based optimization", "type": "Method"}, "target": {"id": "BPTT", "type": "Method"}, "type": "INCLUDES"}, {"source": {"id": "adjoint sensitivity method", "type": "Method"}, "target": {"id": "Cao et al., 2003", "type": "Citation"}, "type": "PROPOSED_BY"}, {"source": {"id": "BPTT", "type": "Method"}, "target": {"id": "LeCun et al., 1988", "type": "Citation"}, "type": "PROPOSED_BY"}, {"source": {"id": "adjoint sensitivity method", "type": "Method"}, "target": {"id": "numerical errors", "type": "Concept"}, "type": "CAN_INTRODUCE"}, {"source": {"id": "Zhuang et al., 2020", "type": "Citation"}, "target": {"id": "numerical errors", "type": "Concept"}, "type": "IDENTIFIED_ISSUE_WITH"}, {"source": {"id": "Table 3", "type": "Concept"}, "target": {"id": "computational complexity", "type": "Concept"}, "type": "SUMMARIZES"}, {"source": {"id": "computational complexity", "type": "Concept"}, "target": {"id": "sequence models", "type": "Model Type"}, "type": "OF"}, {"source": {"id": "RNNs", "type": "Model"}, "target": {"id": "linearly", "type": "Concept"}, "type": "SCALES"}, {"source": {"id": "RNNs", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "HAS_COMPUTATIONAL_COMPLEXITY"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "quadratically", "type": "Concept"}, "type": "SCALES"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "O(n^2k)", "type": "Complexity Metric"}, "type": "HAS_COMPUTATIONAL_COMPLEXITY"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "quadratically", "type": "Concept"}, "type": "SCALES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "O(n^2k)", "type": "Complexity Metric"}, "type": "HAS_COMPUTATIONAL_COMPLEXITY"}, {"source": {"id": "ODE-based models", "type": "Model Type"}, "target": {"id": "LNNs", "type": "Model"}, "type": "INCLUDE"}, {"source": {"id": "LNNs", "type": "Model"}, "target": {"id": "multiplicative factor S", "type": "Parameter"}, "type": "INCURS"}, {"source": {"id": "multiplicative factor S", "type": "Parameter"}, "target": {"id": "solver steps", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "RNNs", "type": "Model"}, "target": {"id": "O(k)", "type": "Complexity Metric"}, "type": "REQUIRES_COMPLEXITY_FOR_SINGLE_TIME_STEP_PREDICTION"}, {"source": {"id": "LSTMs", "type": "Model"}, "target": {"id": "O(k)", "type": "Complexity Metric"}, "type": "REQUIRES_COMPLEXITY_FOR_SINGLE_TIME_STEP_PREDICTION"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "REQUIRES_COMPLEXITY_FOR_SINGLE_TIME_STEP_PREDICTION"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "REQUIRES_COMPLEXITY_FOR_SINGLE_TIME_STEP_PREDICTION"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "HAS_SEQUENCE_COMPLEXITY"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "O(k)", "type": "Complexity Metric"}, "type": "HAS_TIME_STEP_COMPLEXITY"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "O(n^2k)", "type": "Complexity Metric"}, "type": "HAS_SEQUENCE_COMPLEXITY"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "HAS_TIME_STEP_COMPLEXITY"}, {"source": {"id": "LNN (ODEsolve)", "type": "Model"}, "target": {"id": "O(nk * S)", "type": "Complexity Metric"}, "type": "HAS_SEQUENCE_COMPLEXITY"}, {"source": {"id": "LNN (ODEsolve)", "type": "Model"}, "target": {"id": "O(k * S)", "type": "Complexity Metric"}, "type": "HAS_TIME_STEP_COMPLEXITY"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "O(n^2k)", "type": "Complexity Metric"}, "type": "HAS_SEQUENCE_COMPLEXITY"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "HAS_TIME_STEP_COMPLEXITY"}, {"source": {"id": "NAC-Euler", "type": "Model"}, "target": {"id": "O(n^2k)", "type": "Complexity Metric"}, "type": "HAS_SEQUENCE_COMPLEXITY"}, {"source": {"id": "NAC-Euler", "type": "Model"}, "target": {"id": "O(nk)", "type": "Complexity Metric"}, "type": "HAS_TIME_STEP_COMPLEXITY"}, {"source": {"id": "related works", "type": "Concept"}, "target": {"id": "four subcategories", "type": "Concept"}, "type": "DIVIDED_INTO"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "Rumelhart et al., 1985", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "sequential dependencies", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "sequential dependencies", "type": "Concept"}, "target": {"id": "time-series data", "type": "Concept"}, "type": "IN"}, {"source": {"id": "RNN", "type": "Model"}, "target": {"id": "hidden state", "type": "Concept"}, "type": "UPDATES"}, {"source": {"id": "hidden state", "type": "Concept"}, "target": {"id": "current observation", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "hidden state", "type": "Concept"}, "target": {"id": "previous state", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "Hochreiter & Schmidhuber, 1997", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "RNNs", "type": "Model"}, "type": "EXTENDS"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "input gate", "type": "Concept"}, "type": "WITH"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "output gate", "type": "Concept"}, "type": "WITH"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "forget gate", "type": "Concept"}, "type": "WITH"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "long-term memory", "type": "Concept"}, "type": "MAINTAINS"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "long-term memory", "type": "Concept"}, "type": "UPDATES"}, {"source": {"id": "LSTM", "type": "Model"}, "target": {"id": "long-term dependencies", "type": "Concept"}, "type": "IMPROVES_MODELING_OF"}, {"source": {"id": "long-term dependencies", "type": "Concept"}, "target": {"id": "time-series sequences", "type": "Concept"}, "type": "IN"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "Cho et al., 2014", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "LSTM architecture", "type": "Concept"}, "type": "SIMPLIFIES"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "forget gate", "type": "Concept"}, "type": "COMBINES"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "input gate", "type": "Concept"}, "type": "COMBINES"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "update gate", "type": "Concept"}, "type": "INTO"}, {"source": {"id": "GRU", "type": "Model"}, "target": {"id": "long-term dependencies", "type": "Concept"}, "type": "ALLOWS_MODELING_OF"}, {"source": {"id": "long-term dependencies", "type": "Concept"}, "target": {"id": "time-series sequences", "type": "Concept"}, "type": "IN"}, {"source": {"id": "CT-RNN", "type": "Model"}, "target": {"id": "Rubanova et al., 2019", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "CT-RNN", "type": "Model"}, "target": {"id": "temporal dynamics", "type": "Concept"}, "type": "MODELS"}, {"source": {"id": "CT-RNN", "type": "Model"}, "target": {"id": "differential equations", "type": "Concept"}, "type": "USES"}, {"source": {"id": "CT-RNN", "type": "Model"}, "target": {"id": "hidden states", "type": "Concept"}, "type": "ENABLES_EVOLUTION_FOR"}, {"source": {"id": "CT-RNN", "type": "Model"}, "target": {"id": "irregularly sampled time-series data", "type": "Concept"}, "type": "USEFUL_FOR"}, {"source": {"id": "PhasedLSTM", "type": "Model"}, "target": {"id": "Neil et al., 2016", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "PhasedLSTM", "type": "Model"}, "target": {"id": "time gate", "type": "Concept"}, "type": "INTRODUCES"}, {"source": {"id": "time gate", "type": "Concept"}, "target": {"id": "hidden states", "type": "Concept"}, "type": "UPDATES"}, {"source": {"id": "hidden states", "type": "Concept"}, "target": {"id": "rhythmic schedule", "type": "Concept"}, "type": "ACCORDING_TO"}, {"source": {"id": "PhasedLSTM", "type": "Model"}, "target": {"id": "asynchronous time-series", "type": "Concept"}, "type": "ENABLES_MODELING_OF"}, {"source": {"id": "PhasedLSTM", "type": "Model"}, "target": {"id": "irregularly sampled time-series", "type": "Concept"}, "type": "ENABLES_MODELING_OF"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "De Brouwer et al., 2019", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "GRU", "type": "Model"}, "type": "EXTENDS"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "continuous time", "type": "Concept"}, "type": "TO"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "hidden states", "type": "Concept"}, "type": "EVOLVES"}, {"source": {"id": "hidden states", "type": "Concept"}, "target": {"id": "ODEs", "type": "Concept"}, "type": "VIA"}, {"source": {"id": "GRU-ODE", "type": "Model"}, "target": {"id": "non-uniform time intervals", "type": "Concept"}, "type": "HANDLES"}, {"source": {"id": "mmRNNs", "type": "Model"}, "target": {"id": "Lechner & Hasani, 2022", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "mmRNNs", "type": "Model"}, "target": {"id": "short-term memory units", "type": "Concept"}, "type": "COMBINES"}, {"source": {"id": "mmRNNs", "type": "Model"}, "target": {"id": "long-term memory units", "type": "Concept"}, "type": "COMBINES"}, {"source": {"id": "mmRNNs", "type": "Model"}, "target": {"id": "fast-changing patterns", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "mmRNNs", "type": "Model"}, "target": {"id": "slowly evolving patterns", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "fast-changing patterns", "type": "Concept"}, "target": {"id": "sequential data", "type": "Concept"}, "type": "IN"}, {"source": {"id": "slowly evolving patterns", "type": "Concept"}, "target": {"id": "sequential data", "type": "Concept"}, "type": "IN"}, {"source": {"id": "LTC", "type": "Model"}, "target": {"id": "Hasani et al., 2021", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "LTC", "type": "Model"}, "target": {"id": "neurons", "type": "Concept"}, "type": "USES"}, {"source": {"id": "neurons", "type": "Concept"}, "target": {"id": "learnable time constants", "type": "Concept"}, "type": "HAVE"}, {"source": {"id": "neurons", "type": "Concept"}, "target": {"id": "input-dependent time constants", "type": "Concept"}, "type": "HAVE"}, {"source": {"id": "LTC", "type": "Model"}, "target": {"id": "speed of dynamics", "type": "Concept"}, "type": "ADAPTS"}, {"source": {"id": "LTC", "type": "Model"}, "target": {"id": "complex temporal patterns", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "complex temporal patterns", "type": "Concept"}, "target": {"id": "continuous-time data", "type": "Concept"}, "type": "IN"}, {"source": {"id": "CfC", "type": "Model"}, "target": {"id": "Hasani et al., 2022", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "CfC", "type": "Model"}, "target": {"id": "LTC dynamics", "type": "Concept"}, "type": "APPROXIMATES_ANALYTICALLY"}, {"source": {"id": "CfC", "type": "Model"}, "target": {"id": "numerical ODE solvers", "type": "Method"}, "type": "DOES_NOT_RELY_ON"}, {"source": {"id": "CfC", "type": "Model"}, "target": {"id": "efficient continuous-time modeling", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "Vaswani et al., 2017", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "attention weights", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "attention weights", "type": "Concept"}, "target": {"id": "queries", "type": "Concept"}, "type": "BY_MEASURING_SIMILARITY_BETWEEN"}, {"source": {"id": "attention weights", "type": "Concept"}, "target": {"id": "keys", "type": "Concept"}, "type": "BY_MEASURING_SIMILARITY_BETWEEN"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "softmax", "type": "Technique"}, "type": "APPLIES"}, {"source": {"id": "softmax", "type": "Technique"}, "target": {"id": "time-step contributions", "type": "Concept"}, "type": "TO_WEIGH"}, {"source": {"id": "Multi-Head Attention", "type": "Model"}, "target": {"id": "Vaswani et al., 2017", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "Multi-Head Attention", "type": "Model"}, "target": {"id": "parallel scaled dot-product attention mechanisms", "type": "Mechanism"}, "type": "APPLIES"}, {"source": {"id": "Multi-Head Attention", "type": "Model"}, "target": {"id": "temporal dependencies", "type": "Concept"}, "type": "CAPTURES"}, {"source": {"id": "temporal dependencies", "type": "Concept"}, "target": {"id": "complex time-series modeling", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "Shukla & Marlin, 2021", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "continuous-time embeddings", "type": "Concept"}, "type": "LEARNS"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "time-based attention", "type": "Mechanism"}, "type": "USES"}, {"source": {"id": "time-based attention", "type": "Mechanism"}, "target": {"id": "irregular observations", "type": "Concept"}, "type": "TO_INTERPOLATE"}, {"source": {"id": "irregular observations", "type": "Concept"}, "target": {"id": "fixed-length representation", "type": "Concept"}, "type": "INTO"}, {"source": {"id": "fixed-length representation", "type": "Concept"}, "target": {"id": "encoder-decoder modeling", "type": "Task"}, "type": "FOR"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "Chien & Chen, 2021", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "discrete-time attention", "type": "Mechanism"}, "type": "GENERALIZES"}, {"source": {"id": "discrete-time attention", "type": "Mechanism"}, "target": {"id": "continuous-time", "type": "Concept"}, "type": "TO"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "hidden states", "type": "Concept"}, "type": "REPRESENTS_AS_FUNCTIONS"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "context vectors", "type": "Concept"}, "type": "REPRESENTS_AS_FUNCTIONS"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "attention scores", "type": "Concept"}, "type": "REPRESENTS_AS_FUNCTIONS"}, {"source": {"id": "dynamics", "type": "Concept"}, "target": {"id": "neural networks", "type": "Model Type"}, "type": "MODELED_VIA"}, {"source": {"id": "dynamics", "type": "Concept"}, "target": {"id": "ODE solvers", "type": "Method"}, "type": "INTEGRATED_USING"}, {"source": {"id": "ODE solvers", "type": "Method"}, "target": {"id": "irregular sequences", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "ODEFormer", "type": "Model"}, "target": {"id": "d\u2019Ascoli et al., 2023", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "ODEFormer", "type": "Model"}, "target": {"id": "synthetic trajectories", "type": "Concept"}, "type": "TRAINS_ON"}, {"source": {"id": "ODEFormer", "type": "Model"}, "target": {"id": "symbolic ODE system", "type": "Concept"}, "type": "OUTPUTS"}, {"source": {"id": "symbolic ODE system", "type": "Concept"}, "target": {"id": "noisy time-series data", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "symbolic ODE system", "type": "Concept"}, "target": {"id": "irregularly sampled time-series data", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "Chen et al., 2023", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "continuous-time Transformer", "type": "Model"}, "type": "BUILDS"}, {"source": {"id": "continuous-time Transformer", "type": "Model"}, "target": {"id": "ODE-defined latent trajectories", "type": "Concept"}, "type": "PAIRS_WITH"}, {"source": {"id": "continuous-time Transformer", "type": "Model"}, "target": {"id": "time-aware attention mechanism", "type": "Mechanism"}, "type": "PAIRS_WITH"}, {"source": {"id": "continuous-time Transformer", "type": "Model"}, "target": {"id": "dynamic relationships", "type": "Concept"}, "type": "MODELS"}, {"source": {"id": "dynamic relationships", "type": "Concept"}, "target": {"id": "irregularly sampled time-series data", "type": "Concept"}, "type": "IN"}, {"source": {"id": "variants", "type": "Concept"}, "target": {"id": "four subcategories", "type": "Concept"}, "type": "DIVIDED_INTO"}, {"source": {"id": "ablation", "type": "Concept"}, "target": {"id": "four subcategories", "type": "Concept"}, "type": "DIVIDED_INTO"}, {"source": {"id": "NAC-2k", "type": "Model Variant"}, "target": {"id": "Top-K=2", "type": "Hyperparameter"}, "type": "USES"}, {"source": {"id": "Top-K=2", "type": "Hyperparameter"}, "target": {"id": "logits", "type": "Concept"}, "type": "TO_COMPUTE"}, {"source": {"id": "NAC-32k", "type": "Model Variant"}, "target": {"id": "Top-K=32", "type": "Hyperparameter"}, "type": "USES"}, {"source": {"id": "Top-K=32", "type": "Hyperparameter"}, "target": {"id": "logits", "type": "Concept"}, "type": "TO_COMPUTE"}, {"source": {"id": "variants", "type": "Concept"}, "target": {"id": "exact computation mode", "type": "Computation Mode"}, "type": "USES"}, {"source": {"id": "variants", "type": "Concept"}, "target": {"id": "50% Sparsity", "type": "Sparsity Level"}, "type": "USES"}, {"source": {"id": "NAC-02s", "type": "Model Variant"}, "target": {"id": "20% Sparsity", "type": "Sparsity Level"}, "type": "USES"}, {"source": {"id": "20% Sparsity", "type": "Sparsity Level"}, "target": {"id": "logits", "type": "Concept"}, "type": "TO_COMPUTE"}, {"source": {"id": "NAC-09s", "type": "Model Variant"}, "target": {"id": "90% Sparsity", "type": "Sparsity Level"}, "type": "USES"}, {"source": {"id": "90% Sparsity", "type": "Sparsity Level"}, "target": {"id": "logits", "type": "Concept"}, "type": "TO_COMPUTE"}, {"source": {"id": "NAC-PW", "type": "Model Variant"}, "target": {"id": "full pairwise concatenation", "type": "Technique"}, "type": "EMPLOYS"}, {"source": {"id": "full pairwise concatenation", "type": "Technique"}, "target": {"id": "input curation", "type": "Process"}, "type": "FOR"}, {"source": {"id": "NAC-FC", "type": "Model Variant"}, "target": {"id": "sparse NCP gating mechanism", "type": "Mechanism"}, "type": "REPLACES"}, {"source": {"id": "NAC-FC", "type": "Model Variant"}, "target": {"id": "fully connected layer", "type": "Neural Network Component"}, "type": "WITH"}, {"source": {"id": "variants", "type": "Concept"}, "target": {"id": "exact computation mode", "type": "Computation Mode"}, "type": "USES"}, {"source": {"id": "variants", "type": "Concept"}, "target": {"id": "Top-K=8", "type": "Hyperparameter"}, "type": "USES"}, {"source": {"id": "NAC-Euler", "type": "Model Variant"}, "target": {"id": "attention logits", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "attention logits", "type": "Concept"}, "target": {"id": "explicit Euler integration method", "type": "Method"}, "type": "USING"}, {"source": {"id": "NAC-Steady", "type": "Model Variant"}, "target": {"id": "attention logits", "type": "Concept"}, "type": "DERIVES"}, {"source": {"id": "attention logits", "type": "Concept"}, "target": {"id": "steady-state solution", "type": "Concept"}, "type": "FROM"}, {"source": {"id": "steady-state solution", "type": "Concept"}, "target": {"id": "exact formulation", "type": "Concept"}, "type": "OF"}, {"source": {"id": "NAC-Exact/05s/8k", "type": "Model Variant"}, "target": {"id": "attention logits", "type": "Concept"}, "type": "COMPUTES"}, {"source": {"id": "attention logits", "type": "Concept"}, "target": {"id": "closed-form exact solution", "type": "Concept"}, "type": "USING"}, {"source": {"id": "modes", "type": "Computation Mode"}, "target": {"id": "Top-K=8", "type": "Hyperparameter"}, "type": "USES"}, {"source": {"id": "modes", "type": "Computation Mode"}, "target": {"id": "50% Sparsity", "type": "Sparsity Level"}, "type": "USES"}, {"source": {"id": "modes", "type": "Computation Mode"}, "target": {"id": "\u03b4t=1.0", "type": "Parameter"}, "type": "USES"}, {"source": {"id": "sensitivity", "type": "Concept"}, "target": {"id": "NAC", "type": "Model"}, "type": "OF"}, {"source": {"id": "sensitivity", "type": "Concept"}, "target": {"id": "\u03b4t", "type": "Parameter"}, "type": "TO"}, {"source": {"id": "sensitivity", "type": "Concept"}, "target": {"id": "Figure 4", "type": "Figure"}, "type": "VISUALIZED_IN"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "Deng, 2012", "type": "Citation"}, "type": "INTRODUCED_BY"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "computer vision", "type": "Field"}, "type": "USED_FOR"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "image classification tasks", "type": "Task"}, "type": "USED_FOR"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "70,000 grayscale images", "type": "Dataset Component"}, "type": "CONSISTS_OF"}, {"source": {"id": "70,000 grayscale images", "type": "Dataset Component"}, "target": {"id": "handwritten digits", "type": "Concept"}, "type": "ARE"}, {"source": {"id": "70,000 grayscale images", "type": "Dataset Component"}, "target": {"id": "28x28 pixels", "type": "Image Dimension"}, "type": "HAVE_SIZE"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "60,000 training samples", "type": "Dataset Split"}, "type": "INCLUDES"}, {"source": {"id": "MNIST Dataset", "type": "Dataset"}, "target": {"id": "10,000 testing samples", "type": "Dataset Split"}, "type": "INCLUDES"}, {"source": {"id": "preprocessing pipeline", "type": "Method"}, "target": {"id": "Lechner & Hasani, 2022", "type": "Citation"}, "type": "DESCRIBED_IN"}, {"source": {"id": "threshold", "type": "Technique"}, "target": {"id": "8-bit pixel values", "type": "Data Type"}, "type": "APPLIED_TO_CONVERT"}, {"source": {"id": "8-bit pixel values", "type": "Data Type"}, "target": {"id": "binary values", "type": "Data Type"}, "type": "INTO"}, {"source": {"id": "28x28 image", "type": "Data Item"}, "target": {"id": "one-dimensional time series", "type": "Data Structure"}, "type": "RESHAPED_INTO"}, {"source": {"id": "one-dimensional time series", "type": "Data Structure"}, "target": {"id": "length 784", "type": "Data Length"}, "type": "HAS_LENGTH"}, {"source": {"id": "binary time series", "type": "Data Type"}, "target": {"id": "event-based format", "type": "Data Format"}, "type": "ENCODED_IN"}, {"source": {"id": "encoding", "type": "Method"}, "target": {"id": "temporal dimension", "type": "Concept"}, "type": "INTRODUCES"}, {"source": {"id": "encoding", "type": "Method"}, "target": {"id": "sequences", "type": "Data Type"}, "type": "COMPRESSES"}, {"source": {"id": "sequences", "type": "Data Type"}, "target": {"id": "784 time steps", "type": "Data Length"}, "type": "FROM"}, {"source": {"id": "sequences", "type": "Data Type"}, "target": {"id": "53 time steps", "type": "Data Length"}, "type": "TO"}, {"source": {"id": "sequence", "type": "Data Type"}, "target": {"id": "fixed length of 256", "type": "Data Length"}, "type": "PADDED_TO"}, {"source": {"id": "time dimension", "type": "Concept"}, "target": {"id": "one unit of time", "type": "Time Unit"}, "type": "NORMALIZED_TO"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "per-sequence classification problem", "type": "Task Type"}, "type": "DEFINES"}, {"source": {"id": "per-sequence classification problem", "type": "Task Type"}, "target": {"id": "irregularly sampled time series", "type": "Concept"}, "type": "ON"}, {"source": {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, "target": {"id": "compact convolutional layers", "type": "Neural Network Component"}, "type": "COMBINES"}, {"source": {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, "target": {"id": "NAC", "type": "Model"}, "type": "COMBINES"}, {"source": {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, "target": {"id": "counterparts baselines", "type": "Model Type"}, "type": "COMBINES"}, {"source": {"id": "Hyperparameter", "type": "Parameter"}, "target": {"id": "Table 4", "type": "Table"}, "type": "PROVIDED_IN"}, {"source": {"id": "architectural specifications", "type": "Specification"}, "target": {"id": "Table 4", "type": "Table"}, "type": "PROVIDED_IN"}, {"source": {"id": "Localized Person Activity Recognition dataset", "type": "Dataset"}, "target": {"id": "UC Irvine", "type": "Organization"}, "type": "PROVIDED_BY"}, {"source": {"id": "Localized Person Activity Recognition dataset", "type": "Dataset"}, "target": {"id": "Vidulin et al., 2010", "type": "Citation"}, "type": "DESCRIBED_BY"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "25 recordings", "type": "Dataset Component"}, "type": "COMPRISES"}, {"source": {"id": "25 recordings", "type": "Dataset Component"}, "target": {"id": "human participants", "type": "Entity Group"}, "type": "OF"}, {"source": {"id": "human participants", "type": "Entity Group"}, "target": {"id": "physical activities", "type": "Activity Type"}, "type": "PERFORMING"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "walking", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "falling", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "lying down", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "lying", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "sitting down", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "sitting", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "standing up from lying", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "on all fours", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "sitting on the ground", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "standing up from sitting", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "physical activities", "type": "Activity Type"}, "target": {"id": "standing up from sitting on the ground", "type": "Activity"}, "type": "INCLUDES"}, {"source": {"id": "experiment", "type": "Concept"}, "target": {"id": "participant's activity", "type": "Concept"}, "type": "OBJECTIVE_TO_RECOGNIZE"}, {"source": {"id": "participant's activity", "type": "Concept"}, "target": {"id": "inertial sensors", "type": "Sensor Type"}, "type": "FROM"}, {"source": {"id": "task", "type": "Task"}, "target": {"id": "per-time-step classification problem", "type": "Task Type"}, "type": "FORMULATED_AS"}, {"source": {"id": "input data", "type": "Data Type"}, "target": {"id": "sensor readings", "type": "Data Type"}, "type": "CONSIST_OF"}, {"source": {"id": "sensor readings", "type": "Data Type"}, "target": {"id": "four inertial measurement units", "type": "Sensor Type"}, "type": "FROM"}, {"source": {"id": "four inertial measurement units", "type": "Sensor Type"}, "target": {"id": "participants' arms", "type": "Body Part"}, "type": "PLACED_ON"}, {"source": {"id": "four inertial measurement units", "type": "Sensor Type"}, "target": {"id": "participants' feet", "type": "Body Part"}, "type": "PLACED_ON"}, {"source": {"id": "sensors", "type": "Concept"}, "target": {"id": "fixed interval of 211 ms", "type": "Time Interval"}, "type": "SAMPLED_AT"}, {"source": {"id": "recordings", "type": "Data Type"}, "target": {"id": "phase shifts", "type": "Phenomenon"}, "type": "EXHIBIT"}, {"source": {"id": "recordings", "type": "Data Type"}, "target": {"id": "irregularly sampled time series", "type": "Concept"}, "type": "TREATED_AS"}, {"source": {"id": "participant's recordings", "type": "Data Type"}, "target": {"id": "sequence identity", "type": "Concept"}, "type": "SEPARATED_BASED_ON"}, {"source": {"id": "elapsed time", "type": "Concept"}, "target": {"id": "sampling period", "type": "Concept"}, "type": "CALCULATED_USING"}, {"source": {"id": "excess samples", "type": "Data Subset"}, "target": {"id": "class imbalance", "type": "Problem"}, "type": "REMOVED_TO_MITIGATE"}, {"source": {"id": "excess samples", "type": "Data Subset"}, "target": {"id": "overrepresented classes", "type": "Data Subset"}, "type": "REMOVED_FROM"}, {"source": {"id": "removed samples", "type": "Data Subset"}, "target": {"id": "smallest class", "type": "Data Subset"}, "type": "TO_MATCH_SIZE_OF"}, {"source": {"id": "data", "type": "Data Type"}, "target": {"id": "standard scaler", "type": "Preprocessing Tool"}, "type": "NORMALIZED_USING"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "90:10 ratio", "type": "Split Ratio"}, "type": "SPLIT_INTO"}, {"source": {"id": "90:10 ratio", "type": "Split Ratio"}, "target": {"id": "training", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "90:10 ratio", "type": "Split Ratio"}, "target": {"id": "testing", "type": "Concept"}, "type": "FOR"}, {"source": {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, "target": {"id": "convolutional heads", "type": "Neural Network Component"}, "type": "COMBINES"}, {"source": {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, "target": {"id": "NAC", "type": "Model"}, "type": "COMBINES"}, {"source": {"id": "end-to-end hybrid neural network", "type": "Neural Network Architecture"}, "target": {"id": "other baselines", "type": "Model Type"}, "type": "COMBINES"}, {"source": {"id": "Hyperparameter", "type": "Parameter"}, "target": {"id": "Table 4", "type": "Table"}, "type": "SUMMARIZED_IN"}, {"source": {"id": "data collection methodology", "type": "Methodology"}, "target": {"id": "Razzaq & Hongwei, 2023", "type": "Citation"}, "type": "DESCRIBED_IN"}, {"source": {"id": "PPO-trained agent", "type": "Agent Type"}, "target": {"id": "20 episodes", "type": "Simulation Metric"}, "type": "USED_TO_RECORD"}, {"source": {"id": "20 episodes", "type": "Simulation Metric"}, "target": {"id": "48,174 RGB images", "type": "Dataset Component"}, "type": "YIELDED"}, {"source": {"id": "48,174 RGB images", "type": "Dataset Component"}, "target": {"id": "92x92x3", "type": "Image Dimension"}, "type": "HAS_SIZE"}, {"source": {"id": "48,174 RGB images", "type": "Dataset Component"}, "target": {"id": "action labels", "type": "Data Type"}, "type": "WITH"}, {"source": {"id": "action labels", "type": "Data Type"}, "target": {"id": "five discrete actions", "type": "Action Type"}, "type": "ACROSS"}, {"source": {"id": "five discrete actions", "type": "Action Type"}, "target": {"id": "no-act", "type": "Action"}, "type": "INCLUDES"}, {"source": {"id": "five discrete actions", "type": "Action Type"}, "target": {"id": "move left", "type": "Action"}, "type": "INCLUDES"}, {"source": {"id": "five discrete actions", "type": "Action Type"}, "target": {"id": "forward", "type": "Action"}, "type": "INCLUDES"}, {"source": {"id": "five discrete actions", "type": "Action Type"}, "target": {"id": "move right", "type": "Action"}, "type": "INCLUDES"}, {"source": {"id": "five discrete actions", "type": "Action Type"}, "target": {"id": "stop", "type": "Action"}, "type": "INCLUDES"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "10% testing", "type": "Dataset Split"}, "type": "SPLIT_INTO"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "90% training", "type": "Dataset Split"}, "type": "SPLIT_INTO"}, {"source": {"id": "Udacity simulator", "type": "Environment"}, "target": {"id": "15647 RGB images", "type": "Dataset Component"}, "type": "PRODUCED"}, {"source": {"id": "15647 RGB images", "type": "Dataset Component"}, "target": {"id": "320x160x3", "type": "Image Dimension"}, "type": "HAS_SIZE"}, {"source": {"id": "15647 RGB images", "type": "Dataset Component"}, "target": {"id": "three camera streams", "type": "Input Source"}, "type": "CAPTURED_FROM"}, {"source": {"id": "three camera streams", "type": "Input Source"}, "target": {"id": "left camera stream", "type": "Input Source Component"}, "type": "INCLUDES"}, {"source": {"id": "three camera streams", "type": "Input Source"}, "target": {"id": "center camera stream", "type": "Input Source Component"}, "type": "INCLUDES"}, {"source": {"id": "three camera streams", "type": "Input Source"}, "target": {"id": "right camera stream", "type": "Input Source Component"}, "type": "INCLUDES"}, {"source": {"id": "15647 RGB images", "type": "Dataset Component"}, "target": {"id": "continuous steering values", "type": "Data Type"}, "type": "ALONG_WITH"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "20% testing", "type": "Dataset Split"}, "type": "SPLIT_INTO"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "80% training", "type": "Dataset Split"}, "type": "SPLIT_INTO"}, {"source": {"id": "preprocessing", "type": "Method"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "NOT_APPLIED_TO"}, {"source": {"id": "preprocessing steps", "type": "Method"}, "target": {"id": "Udacity simulator", "type": "Environment"}, "type": "FOR"}, {"source": {"id": "preprocessing steps", "type": "Method"}, "target": {"id": "Shibuya, 2017", "type": "Citation"}, "type": "DESCRIBED_IN"}, {"source": {"id": "image", "type": "Data Item"}, "target": {"id": "irrelevant regions", "type": "Image Component"}, "type": "CROPPED_TO_REMOVE"}, {"source": {"id": "image", "type": "Data Item"}, "target": {"id": "66x120x3", "type": "Image Dimension"}, "type": "RESIZED_TO"}, {"source": {"id": "Images", "type": "Data Type"}, "target": {"id": "RGB color space", "type": "Color Space"}, "type": "CONVERTED_FROM"}, {"source": {"id": "Images", "type": "Data Type"}, "target": {"id": "YUV color space", "type": "Color Space"}, "type": "CONVERTED_TO"}, {"source": {"id": "YUV color space", "type": "Color Space"}, "target": {"id": "network input", "type": "Data Type"}, "type": "TO_MATCH"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "robustness", "type": "Quality Metric"}, "type": "APPLIED_TO_IMPROVE"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "random flips", "type": "Augmentation Technique"}, "type": "INCLUDE"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "translations", "type": "Augmentation Technique"}, "type": "INCLUDE"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "shadow overlays", "type": "Augmentation Technique"}, "type": "INCLUDE"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "brightness variations", "type": "Augmentation Technique"}, "type": "INCLUDE"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "lateral shifts", "type": "Phenomenon"}, "type": "TO_SIMULATE"}, {"source": {"id": "data augmentation techniques", "type": "Technique"}, "target": {"id": "diverse lighting conditions", "type": "Condition"}, "type": "TO_SIMULATE"}, {"source": {"id": "neural network architecture", "type": "Neural Network Architecture"}, "target": {"id": "OpenAI CarRacing", "type": "Environment"}, "type": "FOR"}, {"source": {"id": "neural network architecture", "type": "Neural Network Architecture"}, "target": {"id": "Razzaq & Hongwei, 2023", "type": "Citation"}, "type": "PROPOSED_IN"}, {"source": {"id": "neural network architecture", "type": "Neural Network Architecture"}, "target": {"id": "compact CNN layers", "type": "Neural Network Component"}, "type": "COMBINES"}, {"source": {"id": "compact CNN layers", "type": "Neural Network Component"}, "target": {"id": "spatial feature extraction", "type": "Task"}, "type": "FOR"}, {"source": {"id": "neural network architecture", "type": "Neural Network Architecture"}, "target": {"id": "LNNs", "type": "Model"}, "type": "COMBINES"}, {"source": {"id": "LNNs", "type": "Model"}, "target": {"id": "temporal dynamics", "type": "Concept"}, "type": "TO_CAPTURE"}, {"source": {"id": "LNN layers", "type": "Neural Network Component"}, "target": {"id": "NAC", "type": "Model"}, "type": "REPLACED_WITH"}, {"source": {"id": "LNN layers", "type": "Neural Network Component"}, "target": {"id": "comparable alternatives", "type": "Model Type"}, "type": "REPLACED_WITH"}, {"source": {"id": "hyperparameter configurations", "type": "Configuration"}, "target": {"id": "Table 4", "type": "Table"}, "type": "PROVIDED_IN"}, {"source": {"id": "network", "type": "Neural Network Architecture"}, "target": {"id": "Udacity simulator", "type": "Environment"}, "type": "FOR"}, {"source": {"id": "network", "type": "Neural Network Architecture"}, "target": {"id": "Bojarski et al., 2016", "type": "Citation"}, "type": "PROPOSED_IN"}, {"source": {"id": "network", "type": "Neural Network Architecture"}, "target": {"id": "latent MLP layers", "type": "Neural Network Component"}, "type": "REPLACED"}, {"source": {"id": "latent MLP layers", "type": "Neural Network Component"}, "target": {"id": "NAC", "type": "Model"}, "type": "WITH"}, {"source": {"id": "latent MLP layers", "type": "Neural Network Component"}, "target": {"id": "counterparts", "type": "Model Type"}, "type": "WITH"}, {"source": {"id": "Hyperparameter", "type": "Parameter"}, "target": {"id": "Table 4", "type": "Table"}, "type": "SUMMARIZED_IN"}, {"source": {"id": "saliency map", "type": "Visual Representation"}, "target": {"id": "regions of the input", "type": "Image Component"}, "type": "VISUALIZES"}, {"source": {"id": "model", "type": "Model"}, "target": {"id": "regions of the input", "type": "Image Component"}, "type": "ATTENDS_TO"}, {"source": {"id": "model", "type": "Model"}, "target": {"id": "decisions", "type": "Concept"}, "type": "MAKES"}, {"source": {"id": "Figure 5", "type": "Figure"}, "target": {"id": "saliency maps", "type": "Visual Representation"}, "type": "SHOWS"}, {"source": {"id": "saliency maps", "type": "Visual Representation"}, "target": {"id": "OpenAI CarRacing environment", "type": "Environment"}, "type": "FOR"}, {"source": {"id": "NAC-Steady", "type": "Model Variant"}, "target": {"id": "road's horizon", "type": "Location"}, "type": "MAINTAINS_FOCUS_ON"}, {"source": {"id": "NAC-Euler", "type": "Model Variant"}, "target": {"id": "road's horizon", "type": "Location"}, "type": "MAINTAINS_FOCUS_ON"}, {"source": {"id": "other models", "type": "Model Type"}, "target": {"id": "sides", "type": "Location"}, "type": "FOCUS_ON"}, {"source": {"id": "other models", "type": "Model Type"}, "target": {"id": "task", "type": "Task"}, "type": "UNRESPONSIVE_TO"}, {"source": {"id": "Figure 6", "type": "Figure"}, "target": {"id": "saliency maps", "type": "Visual Representation"}, "type": "PRESENTS"}, {"source": {"id": "saliency maps", "type": "Visual Representation"}, "target": {"id": "Udacity Simulator", "type": "Environment"}, "type": "FOR"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "accurate visual maps", "type": "Visual Representation"}, "type": "PRODUCES"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "accurate visual maps", "type": "Visual Representation"}, "type": "PRODUCES"}, {"source": {"id": "NAC-Exact", "type": "Model"}, "target": {"id": "attention", "type": "Concept"}, "type": "MAINTAINS"}, {"source": {"id": "attention", "type": "Concept"}, "target": {"id": "road's horizon", "type": "Location"}, "type": "ON"}, {"source": {"id": "CTA", "type": "Model"}, "target": {"id": "attention", "type": "Concept"}, "type": "MAINTAINS"}, {"source": {"id": "ContiFormer", "type": "Model"}, "target": {"id": "comparable performance", "type": "Performance Metric"}, "type": "ACHIEVES"}, {"source": {"id": "mTAN", "type": "Model"}, "target": {"id": "comparable performance", "type": "Performance Metric"}, "type": "ACHIEVES"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "reasonable saliency maps", "type": "Visual Representation"}, "type": "GENERATES"}, {"source": {"id": "PhasedLSTM", "type": "Model"}, "target": {"id": "reasonable saliency maps", "type": "Visual Representation"}, "type": "GENERATES"}, {"source": {"id": "focus", "type": "Concept"}, "target": {"id": "scene", "type": "Environment Component"}, "type": "DISPERSED_ACROSS"}, {"source": {"id": "other models", "type": "Model Type"}, "target": {"id": "relevant regions", "type": "Image Component"}, "type": "FAIL_TO_IDENTIFY"}, {"source": {"id": "other models", "type": "Model Type"}, "target": {"id": "blurry maps", "type": "Visual Representation"}, "type": "PRODUCES"}, {"source": {"id": "other models", "type": "Model Type"}, "target": {"id": "one side of the road", "type": "Location"}, "type": "FOCUS_ON"}, {"source": {"id": "results", "type": "Concept"}, "target": {"id": "NAC\u2019s ability to understand task", "type": "Capability"}, "type": "DEMONSTRATE"}, {"source": {"id": "NAC\u2019s ability to understand task", "type": "Capability"}, "target": {"id": "task", "type": "Task"}, "type": "FOR"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "benchmark dataset", "type": "Dataset Type"}, "type": "IS_A"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "condition monitoring", "type": "Field"}, "type": "USED_FOR"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "degradation estimation", "type": "Task Type"}, "type": "USED_FOR"}, {"source": {"id": "degradation estimation", "type": "Task Type"}, "target": {"id": "rolling-element bearings", "type": "Component"}, "type": "OF"}, {"source": {"id": "Nectoux et al., 2012", "type": "Citation"}, "target": {"id": "PRONOSTIA", "type": "Dataset"}, "type": "DEVELOPED"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "PRONOSTIA experimental platform", "type": "Platform"}, "type": "PART_OF"}, {"source": {"id": "dataset", "type": "Dataset"}, "target": {"id": "16 run-to-failure experiments", "type": "Experiment"}, "type": "COMPRISES"}, {"source": {"id": "16 run-to-failure experiments", "type": "Experiment"}, "target": {"id": "accelerated wear conditions", "type": "Condition"}, "type": "PERFORMED_UNDER"}, {"source": {"id": "Algorithm 3", "type": "Algorithm"}, "target": {"id": "windowed signal", "type": "Signal Type"}, "type": "REQUIRES"}, {"source": {"id": "Algorithm 3", "type": "Algorithm"}, "target": {"id": "critical frequency", "type": "Parameter"}, "type": "REQUIRES"}, {"source": {"id": "Algorithm 3", "type": "Algorithm"}, "target": {"id": "operating frequency", "type": "Parameter"}, "type": "REQUIRES"}, {"source": {"id": "Algorithm 3", "type": "Algorithm"}, "target": {"id": "sampling period", "type": "Parameter"}, "type": "REQUIRES"}, {"source": {"id": "Algorithm 3", "type": "Algorithm"}, "target": {"id": "windowed physical constraints", "type": "Constraint Type"}, "type": "REQUIRES"}, {"source": {"id": "windowed signal", "type": "Signal Type"}, "target": {"id": "Iw", "type": "Variable"}, "type": "IDENTIFIED_AS"}, {"source": {"id": "critical frequency", "type": "Parameter"}, "target": {"id": "fc", "type": "Variable"}, "type": "IDENTIFIED_AS"}, {"source": {"id": "operating frequency", "type": "Parameter"}, "target": {"id": "fo", "type": "Variable"}, "type": "IDENTIFIED_AS"}, {"source": {"id": "sampling period", "type": "Parameter"}, "target": {"id": "Tsampling", "type": "Variable"}, "type": "IDENTIFIED_AS"}, {"source": {"id": "windowed physical constraints", "type": "Constraint Type"}, "target": {"id": "tw", "type": "Variable"}, "type": "INCLUDE"}, {"source": {"id": "windowed physical constraints", "type": "Constraint Type"}, "target": {"id": "Tw", "type": "Variable"}, "type": "INCLUDE"}, {"source": {"id": "Wavelets", "type": "Concept"}, "target": {"id": "\u0393 iw(a, b)", "type": "Mathematical Expression"}, "type": "DEFINED_BY"}, {"source": {"id": "Energy", "type": "Metric"}, "target": {"id": "E", "type": "Variable"}, "type": "CALCULATED_AS"}, {"source": {"id": "Dominant frequency", "type": "Metric"}, "target": {"id": "fd", "type": "Variable"}, "type": "CALCULATED_AS"}, {"source": {"id": "Entropy", "type": "Metric"}, "target": {"id": "h", "type": "Variable"}, "type": "CALCULATED_AS"}, {"source": {"id": "Kurtosis", "type": "Metric"}, "target": {"id": "K", "type": "Variable"}, "type": "CALCULATED_AS"}, {"source": {"id": "Skewness", "type": "Metric"}, "target": {"id": "sk", "type": "Variable"}, "type": "CALCULATED_AS"}, {"source": {"id": "mean", "type": "Metric"}, "target": {"id": "\u00b5", "type": "Variable"}, "type": "CALCULATED_AS"}, {"source": {"id": "standard deviation", "type": "Metric"}, "target": {"id": "\u03c3", "type": "Variable"}, "type": "CALCULATED_AS"}], "source": {"page_content": " # Knowledge Graph Construction Instructions\n\n## 1. Role and Objective\nYou are an advanced information extraction model specializing in transforming unstructured text into structured knowledge graph data.  \nYour task is to read the given text and extract all **entities (nodes)** and **relationships (edges)** relevant for constructing a knowledge graph.  \nEach relationship is a **triple** in the form of:\n\n```\nSource_Node ~~ Relationship ~~ Target_Node\n````\n\nYour goal:\n- Maintain **semantic accuracy**, **naming consistency**, and **clean minimalism**.\n- Produce results that can be directly converted into graph database nodes and edges.\n- Ensure consistent capitalization and spelling so that nodes referring to the same concept are identical.\n\n\n## 2. Node and Relationship Guidelines\n\n### \ud83d\udfe2 Node Rules\n- **Nodes represent real-world entities or abstract concepts.**\n- Label every node with a general, simple **type** (e.g., \"Person\", \"Organization\", \"Location\", \"Event\", \"Concept\").\n- The node **id** should be the entity name or phrase as it appears in the text (clean and human-readable).\n- Example: `\"Elon Musk\"` \u2192 `{\"id\": \"Elon Musk\", \"type\": \"Person\"}`\n\n### \ud83d\udfe0 Relationship Rules\n- Relationships should describe **clear, meaningful connections** (verbs or prepositions).\n- Use uppercase snake case (e.g., `FOUNDED`, `BORN_IN`, `LOCATED_AT`, `WORKS_FOR`, `PART_OF`).\n- Keep them **directional** \u2014 from subject (source) to object (target).\n- Example: `\"Elon Musk founded SpaceX\"` \u2192 `{\"source\": \"Elon Musk\", \"target\": \"SpaceX\", \"type\": \"FOUNDED\"}`\n\n---\n\n## 3. Data Normalization and Attributes\n- **No separate nodes for numeric or date values.**\n  - Attach such data as node attributes.\n  - Example: `\"Elon Musk (born 1971)\"` \u2192 `{\"id\": \"Elon Musk\", \"type\": \"Person\", \"attributes\": {\"birthYear\": 1971}}`\n- **Use camelCase for property names** (e.g., `birthDate`, `foundedYear`).\n- Do **not** escape quotes within values.\n\n---\n\n## 4. Coreference and Entity Consistency\n- If an entity is referred to by pronouns or abbreviations later, always use its **most complete name**.\n  - Example: \u201cMusk\u201d \u2192 \u201cElon Musk\u201d\n- The goal is a **coherent and unified graph**, not duplicate nodes.\n\n## 5. Pre-existing Entities\nThe following entities have already been extracted from previous chunks. If you encounter these entities again, reuse their exact IDs and types:\n5-fold Cross-Validation, 50% Sparsity, A, A theoretical framework for back-propagation, AI, AI Models, A_max, A_min, Accelerates Convergence During Training, Accuracy, Accuracy Level, Accurate RUL Estimation, Adaptive Remapping, Adaptive Temporal Dynamics, Adaptive Top-K Selection, Adaptive checkpoint adjoint method, Adjacency Matrices, Adjoint sensitivity analysis for differential-algebraic equations, Advances in Neural Information Processing Systems, Advances in neural information processing systems, Advances in psychology, Aguiar-Conraria, L., Aj, Algorithm 1, Algorithm 2, Appendix A. Preliminaries, Appendix D.3.3, Architectural improvement, Attention, Attention Logits, Attention Mechanisms, Attention Output, Attention Trajectory, Attention Weights, Attention Weights and output, Attention is all you need, Auditable Autonomy, AutoNCP, Autonomous Systems, Autonomous Vehicles (AVs), BMC research notes, BPTT, Backbone Network, Bearing 1, Beltagy et al., 2020, Beltagy, I., Benchmark Datasets, Benefits, BigBird, Biological Nervous Systems, Biologically Inspired Approach, Biologically Inspired Attention Mechanism, Biologically Plausible Attention Mechanisms, Biologically Plausible CT-Attention Mechanism, Bojarski, M., Bounded Representation of Time, Boundedness of Attention Logit State Trajectory, Brockman et al., 2016, Brockman, G., C. elegans, C. elegans Neuronal Circuit Policies (NCPs), CASE 1: Single Connection (M=1), CASE 2: Multiple Connections (M>1), CT Baselines, CT-Attention Models, CT-RNN Models, CT-transformer, Camera Fusion, Cao, Y., Car behavioral cloning, CarRacing Benchmark, Carle, Causal Structure, CfC, Chen et al., 2018, Chen et al., 2023, Chen, R. T., Chen, Y., Chen, Y.-H., Chien & Chen, 2021, Chien, J.-T., Cho et al., 2014, Cho, K., Classification Task, Classifying Steering Actions, Closed form continuous-time neural networks, Code for reproducibility, Cohan, A., Communications on Pure and Applied Mathematics, Compact Architectures, Components, Computation of phi(h) and omega_tau(h), Computational Requirements, Content Alignments, Content-Target Gate, Context, ContiFormer, Continuous Analogue of Standard Weighted Sums, Continuous modeling of sporadicallyobserved time series, Continuous-depth Models, Continuous-time (CT) modeling, Continuous-time Attention (CTA), Continuous-time RNNs (CT-RNNs), Continuous-time attention for sequential learning, Continuous-time transformer for irregular time series modeling, Convergence, Convergence Rate, Corollary 1, Corollary 2, Corollary 3, Cost, Cross-Validation, Cross-Validation Capability, DT Attention, Dataset, De Brouwer, E., Decoder, Degradation Features, Deng, L., Department of Automation, University of Science & Technology of China, Deriving Closed-form (Exact) Solution, Different Datasets, Ding et al., 2021, Ding, Y., Discrete-time Recurrent Neural Networks (DT-RNNs), Dynamic Compatibilities, Early Works, Efficiency, Efficient content-based sparse attention with routing transformers, Electronics, Elsevier, Empirical evaluations, Encoder Outputs, End to end learning for self-driving cars, Equation 1, Equation 18, Equation 24, Equation 25, Equation 26, Equation 27, Equation 28, Equation 29, Equation 30, Equation 31, Equation 32, Equation 33, Equation 34, Equation 35, Equation 37, Equation 38, Equation 39, Equation 40, Equation 41, Equation 42, Equation 43, Equation 44, Equation 45, Euler Mode, Evaluation, Event-based Format, Event-based MNIST, Exact Closed-Form Solution, Exact Mode, Expected Degradation, Experiment, Experimental Videos, Experiments, Explicit Euler Integration, Explicit Euler Solver, Exponential Convergence, Exponential Decay Bound, Expression Extent, Expression Speed, Expressive Similarities, Expressiveness, Fastest, Feature extraction based on morlet wavelet, Figure 1, Figure 1(a), Figure 2, Figure 3, First Place, Fixed-Length Sequences, Flexibility, Flexibility of NAC, Flexible Recurrent Architecture, Full Pairwise Concatenation, Future Work, GRU, GRU-ODE, Gated Recurrent Unit (GRU), Generalization, GitHub Repository, Google Colab T4-GPU, Gradient Characterization, Grosu, R., Group-Wise Masking, Gru-ode-bayes, H, H heads, H units, HUST, HUST Bearing, Hasani et al., 2021, Hasani et al., 2022, Hasani, R., Hasani, R. M., Head Layers, Head Splitting and Sparse Top-K Pairwise Computation, Head-specific Attention Outputs, Heads, Hefei, Hefei Comprehensive National Science Center, Hochreiter & Schmidhuber, 1997, Hochreiter, S., Hong, H. S., Hongwei, M., Hyperparameter, IEEE International Conference on Prognostics and Health Management, PHM\u201912, IEEE signal processing magazine, In, Independent Subspaces, Industrial Prognostics, Industry 4.0, Inertial Measurement Sensors, Input Curation, Input Projections, Input Sequence, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Inter-to-Motor Pathways, International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, International conference on machine learning, Interneuron, Introduction to self-driving cars, Irregular Sampling, Irregular Time-Series Classification, Irregularly Sampled Data, Irregularly Sampled Series, Izis Kankaraway, John, F., John, F. (1952), Jordan, 1997, Jordan, M. I., Journal of economic surveys, Journal of sound and vibration, K, K_eff, Key Tensors, LSTM, LTC, Lane marking detection, Lane-Keeping for Autonomous Vehicles, Large Models, Latent ordinary differential equations for irregularly-sampled time series, LeCun, Y., Learnable Time-Constant Gate, Learnable Time-Constant Gate Head, Learning internal representations by error propagation, Learning phrase representations using rnn encoder-decoder for statistical machine translation, Lechner & Hasani, 2022, Lechner et al., 2018, Lechner et al., 2020, Lechner, M., Lidar, Limitations, Lin, J., Linear First-Order ODE, Linear Projection, Liquid Neural Networks (LNNs), Localized Person Activity Dataset, Localized Safety, Long Sequences, Long-short term memory (LSTM), Longformer, Lower bound, MNIST Dataset, MSE, Machine Failures, Manufacturing, Marlin, B. M., Memory, Memory Consumption, Memory Requirements, Mendeley Data, Mixed-memory RNNs (mmRNNs), Mn, Model, Model Dimension, Motor Neurons, Mp, Multi-Head Attention (MHA), Multi-Head Extension, Multi-time attention networks for irregularly sampled time series, Multilayered feedforward networks, NAC Ablation Configurations, NAC Layer, NAC Sparsity, NAC layer, NAC-02s, NAC-2k, NAC-32k, NAC-Exact, NAC-Exact/05s/8k, NAC-FC, NAC-PW, NAC-Steady, NCP architecture, NCP sparsity s, NCP-based inter-to-motor projection, NCP-based sensory projections, NN sensory, Nature Machine Intelligence, Nc, Nectoux et al., 2012, Nectoux, P., Neil, D., Nervous System of C. elegans, Neural Network Layer Design, Neural Networks, Neural Processing Letters, Neural circuit policies enabling auditable autonomy, Neural circuit policies imposing visual perceptual autonomy, Neural computation, NeuralODE, Neuronal Attention Circuit (NAC), Neuronal Circuit Policies, Neuronal Circuit Policies (NCPs), Ni, Nishijima, 2021, Nishijima, T., Nm, Nonlinear Activations, Nonlinear Backbone, Nonlinear Content-Target Head, Nonlinear Interlinked Gates, Ns, ODEFormer, Objective, OpenAI CarRacing, OpenAI Gym, Operating Condition, Ordinary Differential Equations (ODEs), Output Projection, PMLR, PRONOSTIA, Pairwise Logits, Paper, Park et al., 2021, Park, M., Peak Memory Usage, Performance, Person Activity Recognition (PAR), Peters, M. E., Phased LSTM, Predicting Steering Values, Probability Distribution, Proceedings of the 1988 connectionist models summer school, Proceedings of the AAAI Conference on Artificial Intelligence, Proceedings of the AAAI conference on artificial intelligence, Prognostic Health Management (PHM) Systems, Proof for Theorem 2, Proof of Theorem 1, Proofs, Pseudo-Time Step, Pseudo-Time Vector, Q, QK[\u22a4] matrix, Qu, L., Query Tensors, Query-Key Pair, RNN, RNNs, R^(2d), R^(d_model), R^H, R^d, R^m, R^n, Rate of Convergence, Razzaq & Hongwei, 2023, Recent Research, Recurrent Connections, Recurrent Layer, Reliability Engineering & System Safety, Remaining Useful Life (RUL) Estimation, Remaining useful life estimation using deep metric transfer learning for kernel regression, Remark 1, Representation Learning, Repurposed NCPCell, Research, Resource-Constrained Devices, Results, Riemann-Style Approach, Road's Horizon, Robotics, Robustness, Rolling Element Bearings (REB), Roy et al., 2021, Roy, A., Rubanova et al., 2019, Rubanova, Y., Rumelhart et al., 1985, Rumelhart, D. E., Runge-Kutta, Runtime, S, SIAM journal on scientific computing, Saliency Maps, Sample Complexity to \u03b4-accuracy, Saturation of Preferences, Scaled-Dot Attention, Schmidhuber, J., Score Metric, Second Place, Sensory Gate, Sensory Neurons, Sequence Length, Sequential Data, Serial order: A parallel distributed processing approach, Shared Representations, Shibuya, N., Shukla & Marlin, 2021, Shukla, S. N., Sigmoid Function, Sigmoidal Transformation, Soares, M. J., Soft Computing, Softmax Normalization, Sparse Attention, Sparse Backbone Network, Sparse Input, Sparse Sensory Gates, Sparse Top-K Pairwise Concatenation, Sparse Top-K Pairwise Concatenation Scheme, Sparse Top-K Selection, Sparse sinkhorn attention, Sparsity, Sparsity of NAC Layer, Sparsity s, Speed of Preferences, Standard Attention, State Stability, Steady Mode, Steady State, Steady-State Amplitude, Steady-State Approximation, Steering Actions, Steering Commands, Steering Values, Stinchcomb, M., Stinchcomb, M. (1989), Structural Dependencies, Surveillance, Symbolic regression of dynamical systems with transformers, Synaptic Transmission, TRAJECTORY SENSITIVITIES FOR CLOSED-FORM FORMULATION, Table 1, Target Signal Strength, Target Token, Tay et al., 2020, Tay, Y., Technical report, Temporal Dependencies, Temporal convolution-based transferable cross-domain adaptation approach, The continuous wavelet transform, The long-document transformer, Theorem 1, Theorem 2, Third Place, Throughput, Thuan & Hong, 2023, Thuan, N., Thuan, N. D., Tiang et al., 2018, Tiang, Y., Time Series, Time Vector Construction, Time-Based Attention, Time-Varying Datasets, Timestamp, Top-K Interactions, Top-K Selection, Top-K=8, Training, Training, Gradients and Complexity, Transactions of the Association for Computational Linguistics, Transformers for longer sequences, U, U topk, UAT proofs, UC Irvine, UCI Machine Learning Repository, Udacity Benchmark, Udacity Self-Driving Car Simulator, Uniform Initialization Bound, Universal Approximation Theorem (UAT), Universal Approximation by NAC, Universal Approximator, University of Science & Technology of China, Unseen Conditions, Upper bound, V, Value Matrix, Value Tensors, Vanishing Gradients, Vaswani et al., 2017, Vaswani, A., Vidulin et al., 2010, Vidulin, V., Waleed Razzaq, Wang et al., 2018, Wang, B., XJTU-SY, Y, Yun-Bo Zhao, Zaheer et al., 2020, Zaheer, M., Zhuang et al., 2021, Zhuang, J., a(h), a*, a0, abstraction of neural circuits, accuracy, accuracy epsilon, activation potential, adaptive temporal processing, alpha(h), approximation assumption, arXiv preprint arXiv:1406.1078, arXiv preprint arXiv:1604.07316, arXiv preprint arXiv:1606.01540, arXiv preprint arXiv:1803.08554, arXiv preprint arXiv:2004.05150, arXiv preprint arXiv:2101.10318, arXiv preprint arXiv:2102.10993, arXiv preprint arXiv:2310.05573, architectural size, at, b(h), back-propagation, backbone units, ball bearing fault diagnosis, bearings accelerated degradation tests, biological sparsity, biologically plausible range, bo, closed-form derivatives, closed-form equilibrium solution, closed-form solution, compact K, computational modes, concatenated pair u(h), connectome of NCPs, constant, content-based sparse attention, continuous function f, continuous scalar function phi~, continuous-time attention state, continuous-time dynamics, controllable variable y, convex combination, convolutional neural network-based end-to-end self-driving, derivative, destabilizing the softmax, discrete attention, distance-aware uncertainty quantification methods, diverse tasks, dynamics, d\u2019Ascoli et al., 2023, d\u2019Ascoli, S., effective equilibrium, efficient architectures, emulation, epsilon, equilibrium, equilibrium states, error \u03b4, ethical concerns, experimental platform, exponential error bounds, feedforward connections, final dense layer, fj, forward-invariant, frozen-coefficient approximation, full connectivity, function \u03d5, g(x), gradient estimation in neural ode, gradients, hardware-aware optimization, head h, head output y(h), https://arxiv.org/abs/2512.08499, https://github.com/itxwaleedrazzaq/neuronal_attention_circuit, https://github.com/naokishibuya/car-behavioral-cloning, https://www.udacity.com/course/intro-to-self-driving-cars--nd113, hybrid deep-shallow learning framework, identity function, improved key scoring, input u, input variations, input x, integrating factor, integrating factor \u00b5, integration, integration of parabolic equations by difference methods, interval [m, M], interval length, irregularly sampled time series, irregularly sampled time-series benchmarks, irregularly-sampled time series, k, k proj, k(h), learnable parameters, linear first-order ODE, long or event-based sequences, long-term dependencies, mTAN, mechanical fault diagnosis, memory intensity, multi-connection case M=1, multi-head, multi-layer networks, n, natural wiring, neural networks, nonlinear activations, nonlinear functions, nonlinear, interlinked gates, number of units, omega_tau(h), output motor neurons, output projection Wo, parameterizations, patch proposal network (ppn), per-connection equilibria, physics-guided neural networks, predetermined wiring, pseudo-time integration interval, q, q proj, q(h), query\u2013key pair, randomized wiring, recurrent connections, recurrent network training, relaxation rate \u03c9\u03c4, reliable bearing health prediction, resource-limited settings, resting potential, robust AI, robust and explainable RUL estimation, robust temporal modeling, routing transformers, scalar phi(h), scaling factor, self-attention, sensitivity analysis, sequence length T, sigma(z), sigmoid, sigmoid hidden unit, single-connection case M=1, single-hidden-layer feedforward neural network, single-token input x, softplus, sparse top-k pairs, sparse, adaptive networks, stacked layers, state trajectory, state-of-the-art performance, steady mode, steady-mode logit, system, t, ta, target complexity, tb, traditional scaled dot-product attention, universal approximator, user-defined NCPs configurations, v, v proj, v(h), vanishing or exploding gradients, visual perceptual autonomy, w(h), weights, weights fj, well-defined interval, wiring, y, \u03c9\u03c4, \u03d5, \u03d5j\n\n---\n\n## 6. Output Format\n- Return **only** a valid JSON object matching the GraphDocument structure:\n- Example:\n```json\n{\n  \"nodes\": [\n    {\n      \"id\": \"Rex\",\n      \"type\": \"Animal\"\n    },\n    {\n      \"id\": \"London\",\n      \"type\": \"Location\"\n    }\n  ],\n  \"relationships\": [\n    {\n      \"source\": {\n        \"id\": \"Rex\",\n        \"type\": \"Animal\"\n      },\n      \"target\": {\n        ", "metadata": []}}
{"nodes": [{"id": "Wavelets", "type": "Concept"}, {"id": "\u0393 iw(a, b)", "type": "Formula_Component"}, {"id": "Energy", "type": "Concept"}, {"id": "E", "type": "Variable"}, {"id": "Dominant frequency", "type": "Concept"}, {"id": "fd", "type": "Variable"}, {"id": "Entropy", "type": "Concept"}, {"id": "h", "type": "Variable"}, {"id": "Kurtosis", "type": "Concept"}, {"id": "K", "type": "Variable"}, {"id": "Skewness", "type": "Concept"}, {"id": "sk", "type": "Variable"}, {"id": "mean", "type": "Concept"}, {"id": "\u00b5", "type": "Variable"}, {"id": "standard deviation", "type": "Concept"}, {"id": "\u03c3", "type": "Variable"}, {"id": "ITFR", "type": "Data_Representation"}, {"id": "Xn", "type": "Variable"}, {"id": "log(E)", "type": "Expression"}, {"id": "X1", "type": "Variable"}, {"id": "X2", "type": "Variable"}, {"id": "XNs", "type": "Variable"}, {"id": "tn", "type": "Variable"}, {"id": "Tn", "type": "Variable"}, {"id": "NAC", "type": "Model"}, {"id": "Representation Learning", "type": "Task"}, {"id": "Table 4", "type": "Document_Element"}, {"id": "Key Hyperparameters", "type": "Concept"}, {"id": "Experiments", "type": "Event"}, {"id": "Conv layers", "type": "Model_Component"}, {"id": "Dense", "type": "Model_Component"}, {"id": "Dropout", "type": "Regularization"}, {"id": "Optimizer type", "type": "Hyperparameter_Type"}, {"id": "Learning Rate", "type": "Hyperparameter_Type"}, {"id": "Loss Function type", "type": "Hyperparameter_Type"}, {"id": "Evaluation Metric type", "type": "Hyperparameter_Type"}, {"id": "Batch Size", "type": "Hyperparameter_Type"}, {"id": "Number of Epochs", "type": "Hyperparameter_Type"}, {"id": "MNIST", "type": "Dataset"}, {"id": "PAR", "type": "Dataset"}, {"id": "CarRacing", "type": "Dataset"}, {"id": "Udacity", "type": "Dataset"}, {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, {"id": "2x 1D (64@5) Conv Configuration", "type": "Configuration"}, {"id": "1D (64@5, 64@3) Conv Configuration", "type": "Configuration"}, {"id": "3xTD- 2D (10\u201330@3\u20135) Conv Configuration", "type": "Configuration"}, {"id": "5x 2D (24\u201364@5\u20133, ELU) Conv Configuration", "type": "Configuration"}, {"id": "2x 1D (32@3, 16@2) Conv Configuration", "type": "Configuration"}, {"id": "64-d, 8h NAC Configuration", "type": "Configuration"}, {"id": "32-d, 4h NAC Configuration", "type": "Configuration"}, {"id": "64-d, 16h NAC Configuration", "type": "Configuration"}, {"id": "100-d, 16h NAC Configuration", "type": "Configuration"}, {"id": "16-d, 8h NAC Configuration", "type": "Configuration"}, {"id": "32\u201310(SM) Dense Configuration", "type": "Configuration"}, {"id": "32\u201311(SM) Dense Configuration", "type": "Configuration"}, {"id": "64\u20135(SM) Dense Configuration", "type": "Configuration"}, {"id": "64\u20131(Lin) Dense Configuration", "type": "Configuration"}, {"id": "1(Lin) Dense Configuration", "type": "Configuration"}, {"id": "0.2 Dropout Value", "type": "Hyperparameter_Value"}, {"id": "0.5 Dropout Value", "type": "Hyperparameter_Value"}, {"id": "AdamW", "type": "Optimizer"}, {"id": "Adam", "type": "Optimizer"}, {"id": "0.001 Learning Rate", "type": "Hyperparameter_Value"}, {"id": "0.0001 Learning Rate", "type": "Hyperparameter_Value"}, {"id": "SCE", "type": "Loss_Function"}, {"id": "MSE", "type": "Concept"}, {"id": "Acc", "type": "Evaluation_Metric"}, {"id": "MAE", "type": "Evaluation_Metric"}, {"id": "Score", "type": "Evaluation_Metric"}, {"id": "32 Batch Size", "type": "Hyperparameter_Value"}, {"id": "20 Batch Size", "type": "Hyperparameter_Value"}, {"id": "150 Epochs", "type": "Hyperparameter_Value"}, {"id": "500 Epochs", "type": "Hyperparameter_Value"}, {"id": "100 Epochs", "type": "Hyperparameter_Value"}, {"id": "10 Epochs", "type": "Hyperparameter_Value"}, {"id": "Sparse Categorical Crossentropy", "type": "Loss_Function"}, {"id": "Accuracy", "type": "Evaluation_Metric"}, {"id": "Mean Absolute Error", "type": "Evaluation_Metric"}, {"id": "Mean Squared Error (Loss)", "type": "Loss_Function"}, {"id": "Mean Squared Error (Metric)", "type": "Evaluation_Metric"}, {"id": "softmax function", "type": "Activation_Function"}, {"id": "Linear activation function", "type": "Activation_Function"}, {"id": "TimeDistributed layer", "type": "Layer_Type"}, {"id": "Conv1D/2D layer", "type": "Layer_Type"}, {"id": "Model Dimension", "type": "Concept"}, {"id": "Heads", "type": "Concept"}, {"id": "RNNs", "type": "Model_Family"}, {"id": "CT", "type": "Model_Characteristic"}, {"id": "DT", "type": "Model_Characteristic"}, {"id": "Attention", "type": "Model"}, {"id": "hidden units", "type": "Model_Component"}, {"id": "1D/2D Layer Type", "type": "Layer_Type"}, {"id": "Table 5", "type": "Document_Element"}, {"id": "Data distributions", "type": "Concept"}, {"id": "PRONOSTIA", "type": "Dataset"}, {"id": "XJTU-SY", "type": "Dataset"}, {"id": "HUST", "type": "Dataset"}, {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, {"id": "100 Hz", "type": "Frequency"}, {"id": "4 kN", "type": "Radial_Load"}, {"id": "1800 rpm", "type": "Speed"}, {"id": "4.2 kN", "type": "Radial_Load"}, {"id": "1650 rpm", "type": "Speed"}, {"id": "5 kN", "type": "Radial_Load"}, {"id": "1500 rpm", "type": "Speed"}, {"id": "4 ~ 7 Training Samples", "type": "Data_Split_Range"}, {"id": "1 ~ 3 Testing Samples", "type": "Data_Split_Range"}, {"id": "1 ~ 7 Testing Samples", "type": "Data_Split_Range"}, {"id": "35 Hz", "type": "Frequency"}, {"id": "12 kN", "type": "Radial_Load"}, {"id": "2100 rpm", "type": "Speed"}, {"id": "1 ~ 5 Testing Samples", "type": "Data_Split_Range"}, {"id": "37.5 Hz", "type": "Frequency"}, {"id": "11 kN", "type": "Radial_Load"}, {"id": "2250 rpm", "type": "Speed"}, {"id": "40 Hz", "type": "Frequency"}, {"id": "10 kN", "type": "Radial_Load"}, {"id": "2400 rpm", "type": "Speed"}, {"id": "0 W", "type": "Power"}, {"id": "200 W", "type": "Power"}, {"id": "400 W", "type": "Power"}, {"id": "training", "type": "Purpose"}, {"id": "generalization testing", "type": "Purpose"}, {"id": "three different operating settings", "type": "Operating_Condition_Category"}, {"id": "Vibration data", "type": "Data_Type"}, {"id": "accelerometers", "type": "Sensor"}, {"id": "horizontal axes", "type": "Physical_Axis"}, {"id": "vertical axes", "type": "Physical_Axis"}, {"id": "25.6 kHz Sampling Rate", "type": "Sampling_Rate"}, {"id": "temperature readings", "type": "Data_Type"}, {"id": "10 Hz Sampling Rate", "type": "Sampling_Rate"}, {"id": "Xi\u2019an Jiaotong University", "type": "Organization"}, {"id": "Changxing Sumyoung Technology", "type": "Organization"}, {"id": "Wang et al., 2018", "type": "Publication"}, {"id": "15 complete run-to-failure experiments", "type": "Experiment"}, {"id": "accelerated degradation conditions", "type": "Condition"}, {"id": "accelerometer", "type": "Sensor"}, {"id": "cross-validation test", "type": "Purpose"}, {"id": "Hanoi University of Science and Technology", "type": "Organization"}, {"id": "ball bearing fault diagnosis", "type": "Task"}, {"id": "Hong & Thuan, 2023", "type": "Publication"}, {"id": "five bearing types", "type": "Component_Category"}, {"id": "6204", "type": "Bearing_Type"}, {"id": "6205", "type": "Bearing_Type"}, {"id": "6206", "type": "Bearing_Type"}, {"id": "6207", "type": "Bearing_Type"}, {"id": "6208", "type": "Bearing_Type"}, {"id": "three different load conditions", "type": "Operating_Condition_Category"}, {"id": "Six fault categories", "type": "Fault_Category"}, {"id": "single faults", "type": "Fault_Type"}, {"id": "inner race", "type": "Fault_Location"}, {"id": "outer race", "type": "Fault_Location"}, {"id": "ball", "type": "Fault_Location"}, {"id": "compound faults", "type": "Fault_Type"}, {"id": "inner\u2013outer", "type": "Fault_Combination"}, {"id": "inner\u2013ball", "type": "Fault_Combination"}, {"id": "outer\u2013ball", "type": "Fault_Combination"}, {"id": "early-stage defects", "type": "Defect_Type"}, {"id": "0.2 mm micro-cracks", "type": "Defect_Description"}, {"id": "real degradation scenarios", "type": "Scenario"}, {"id": "51.2 kHz Sampling Rate", "type": "Sampling_Rate"}, {"id": "10-second recordings", "type": "Recording_Duration"}, {"id": "Condition monitoring data", "type": "Data_Type"}, {"id": "1D non-stationary vibrational signals", "type": "Data_Type"}, {"id": "multiple sensors", "type": "Component_Category"}, {"id": "meaningful information", "type": "Concept"}, {"id": "features", "type": "Concept"}, {"id": "physical interpretability", "type": "Concept"}, {"id": "preprocessing", "type": "Process"}, {"id": "Razzaq & Zhao, 2025a", "type": "Publication"}, {"id": "labels", "type": "Concept"}, {"id": "Razzaq & Zhao, 2025b", "type": "Publication"}, {"id": "signal", "type": "Concept"}, {"id": "segmented", "type": "Process"}, {"id": "rectangularized vectors", "type": "Data_Structure"}, {"id": "windowing technique (w)", "type": "Method"}, {"id": "localization of transient characteristics", "type": "Purpose"}, {"id": "continuous wavelet transform (CWT)", "type": "Method"}, {"id": "Aguiar-Conraria & Soares, 2014", "type": "Publication"}, {"id": "Morlet wavelet", "type": "Wavelet_Function"}, {"id": "Lin & Qu, 2000", "type": "Publication"}, {"id": "mother wavelet", "type": "Role"}, {"id": "time-frequency representation (TFR)", "type": "Data_Representation"}, {"id": "a", "type": "Parameter"}, {"id": "b", "type": "Parameter"}, {"id": "\u03c8", "type": "Function"}, {"id": "Morlet wavelet function", "type": "Function"}, {"id": "statistical features", "type": "Feature_Type"}, {"id": "domain-specific features", "type": "Feature_Type"}, {"id": "operational condition of the bearing", "type": "Concept"}, {"id": "feature extraction procedure", "type": "Procedure"}, {"id": "Algorithm 3", "type": "Algorithm"}, {"id": "Neural Network Architecture", "type": "Concept"}, {"id": "compact neural network", "type": "Model_Type"}, {"id": "degradation dynamics", "type": "Concept"}, {"id": "resource-constrained devices", "type": "Device_Category"}, {"id": "localized prognostics", "type": "Task"}, {"id": "personalized prognostics", "type": "Task"}, {"id": "individual machines", "type": "Target_System"}, {"id": "compact convolutional network", "type": "Model_Type"}, {"id": "CNN component", "type": "Model_Component"}, {"id": "spatial degradation features", "type": "Feature_Type"}, {"id": "training data", "type": "Data_Type"}, {"id": "temporal filtering", "type": "Process"}, {"id": "informative features", "type": "Feature_Type"}, {"id": "architecture", "type": "Model_Type"}, {"id": "small model size", "type": "Characteristic"}, {"id": "representational capacity", "type": "Characteristic"}, {"id": "hyperparameter configurations", "type": "Concept"}, {"id": "IEEE PHM", "type": "Organization"}, {"id": "scoring function", "type": "Concept"}, {"id": "asymmetric", "type": "Characteristic"}, {"id": "overestimations", "type": "Error_Type"}, {"id": "early predictions", "type": "Prediction_Type"}, {"id": "practical considerations", "type": "Concept"}, {"id": "late maintenance prediction", "type": "Prediction_Type"}, {"id": "unexpected failures", "type": "Event"}, {"id": "severe consequences", "type": "Consequence"}, {"id": "early intervention", "type": "Action"}], "relationships": [{"source": {"id": "Wavelets", "type": "Concept"}, "target": {"id": "\u0393 iw(a, b)", "type": "Formula_Component"}, "type": "DEFINED_BY"}, {"source": {"id": "Energy", "type": "Concept"}, "target": {"id": "E", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "Dominant frequency", "type": "Concept"}, "target": {"id": "fd", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "Entropy", "type": "Concept"}, "target": {"id": "h", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "Kurtosis", "type": "Concept"}, "target": {"id": "K", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "Skewness", "type": "Concept"}, "target": {"id": "sk", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "mean", "type": "Concept"}, "target": {"id": "\u00b5", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "standard deviation", "type": "Concept"}, "target": {"id": "\u03c3", "type": "Variable"}, "type": "DEFINED_AS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "log(E)", "type": "Expression"}, "type": "CONTAINS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "fd", "type": "Variable"}, "type": "CONTAINS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "h", "type": "Variable"}, "type": "CONTAINS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "K", "type": "Variable"}, "type": "CONTAINS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "sk", "type": "Variable"}, "type": "CONTAINS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "\u00b5", "type": "Variable"}, "type": "CONTAINS"}, {"source": {"id": "Xn", "type": "Variable"}, "target": {"id": "\u03c3", "type": "Variable"}, "type": "CONTAINS"}, {"source": {"id": "ITFR", "type": "Data_Representation"}, "target": {"id": "X1", "type": "Variable"}, "type": "CONCATENATES"}, {"source": {"id": "ITFR", "type": "Data_Representation"}, "target": {"id": "X2", "type": "Variable"}, "type": "CONCATENATES"}, {"source": {"id": "ITFR", "type": "Data_Representation"}, "target": {"id": "XNs", "type": "Variable"}, "type": "CONCATENATES"}, {"source": {"id": "ITFR", "type": "Data_Representation"}, "target": {"id": "tn", "type": "Variable"}, "type": "CONCATENATES"}, {"source": {"id": "ITFR", "type": "Data_Representation"}, "target": {"id": "Tn", "type": "Variable"}, "type": "CONCATENATES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "Representation Learning", "type": "Task"}, "type": "FOR"}, {"source": {"id": "Table 4", "type": "Document_Element"}, "target": {"id": "Key Hyperparameters", "type": "Concept"}, "type": "SUMMARIZES"}, {"source": {"id": "Key Hyperparameters", "type": "Concept"}, "target": {"id": "Experiments", "type": "Event"}, "type": "PART_OF"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "Conv layers", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Conv layers", "type": "Model_Component"}, "target": {"id": "2x 1D (64@5) Conv Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "Conv layers", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Conv layers", "type": "Model_Component"}, "target": {"id": "1D (64@5, 64@3) Conv Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "Conv layers", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Conv layers", "type": "Model_Component"}, "target": {"id": "3xTD- 2D (10\u201330@3\u20135) Conv Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "Conv layers", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Conv layers", "type": "Model_Component"}, "target": {"id": "5x 2D (24\u201364@5\u20133, ELU) Conv Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "Conv layers", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Conv layers", "type": "Model_Component"}, "target": {"id": "2x 1D (32@3, 16@2) Conv Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "NAC", "type": "Model"}, "type": "USES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "64-d, 8h NAC Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "NAC", "type": "Model"}, "type": "USES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "32-d, 4h NAC Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "NAC", "type": "Model"}, "type": "USES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "64-d, 16h NAC Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "NAC", "type": "Model"}, "type": "USES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "100-d, 16h NAC Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "NAC", "type": "Model"}, "type": "USES"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "16-d, 8h NAC Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "Dense", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Dense", "type": "Model_Component"}, "target": {"id": "32\u201310(SM) Dense Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "Dense", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Dense", "type": "Model_Component"}, "target": {"id": "32\u201311(SM) Dense Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "Dense", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Dense", "type": "Model_Component"}, "target": {"id": "64\u20135(SM) Dense Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "Dense", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Dense", "type": "Model_Component"}, "target": {"id": "64\u20131(Lin) Dense Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "Dense", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "Dense", "type": "Model_Component"}, "target": {"id": "1(Lin) Dense Configuration", "type": "Configuration"}, "type": "HAS_CONFIGURATION"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "Dropout", "type": "Regularization"}, "type": "USES"}, {"source": {"id": "Dropout", "type": "Regularization"}, "target": {"id": "0.2 Dropout Value", "type": "Hyperparameter_Value"}, "type": "HAS_VALUE"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "Dropout", "type": "Regularization"}, "type": "USES"}, {"source": {"id": "Dropout", "type": "Regularization"}, "target": {"id": "0.5 Dropout Value", "type": "Hyperparameter_Value"}, "type": "HAS_VALUE"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "AdamW", "type": "Optimizer"}, "type": "USES"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "AdamW", "type": "Optimizer"}, "type": "USES"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "Adam", "type": "Optimizer"}, "type": "USES"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "AdamW", "type": "Optimizer"}, "type": "USES"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "AdamW", "type": "Optimizer"}, "type": "USES"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "0.001 Learning Rate", "type": "Hyperparameter_Value"}, "type": "HAS_LEARNING_RATE"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "0.001 Learning Rate", "type": "Hyperparameter_Value"}, "type": "HAS_LEARNING_RATE"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "0.0001 Learning Rate", "type": "Hyperparameter_Value"}, "type": "HAS_LEARNING_RATE"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "0.001 Learning Rate", "type": "Hyperparameter_Value"}, "type": "HAS_LEARNING_RATE"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "0.001 Learning Rate", "type": "Hyperparameter_Value"}, "type": "HAS_LEARNING_RATE"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "SCE", "type": "Loss_Function"}, "type": "USES_LOSS_FUNCTION"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "SCE", "type": "Loss_Function"}, "type": "USES_LOSS_FUNCTION"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "SCE", "type": "Loss_Function"}, "type": "USES_LOSS_FUNCTION"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "MSE", "type": "Concept"}, "type": "USES_LOSS_FUNCTION"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "MSE", "type": "Concept"}, "type": "USES_LOSS_FUNCTION"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "Acc", "type": "Evaluation_Metric"}, "type": "USES_METRIC"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "Acc", "type": "Evaluation_Metric"}, "type": "USES_METRIC"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "Acc", "type": "Evaluation_Metric"}, "type": "USES_METRIC"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "MAE", "type": "Evaluation_Metric"}, "type": "USES_METRIC"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "Score", "type": "Evaluation_Metric"}, "type": "USES_METRIC"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "32 Batch Size", "type": "Hyperparameter_Value"}, "type": "HAS_BATCH_SIZE"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "20 Batch Size", "type": "Hyperparameter_Value"}, "type": "HAS_BATCH_SIZE"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "32 Batch Size", "type": "Hyperparameter_Value"}, "type": "HAS_BATCH_SIZE"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "32 Batch Size", "type": "Hyperparameter_Value"}, "type": "HAS_BATCH_SIZE"}, {"source": {"id": "MNIST", "type": "Dataset"}, "target": {"id": "150 Epochs", "type": "Hyperparameter_Value"}, "type": "HAS_EPOCHS"}, {"source": {"id": "PAR", "type": "Dataset"}, "target": {"id": "500 Epochs", "type": "Hyperparameter_Value"}, "type": "HAS_EPOCHS"}, {"source": {"id": "CarRacing", "type": "Dataset"}, "target": {"id": "100 Epochs", "type": "Hyperparameter_Value"}, "type": "HAS_EPOCHS"}, {"source": {"id": "Udacity", "type": "Dataset"}, "target": {"id": "10 Epochs", "type": "Hyperparameter_Value"}, "type": "HAS_EPOCHS"}, {"source": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "target": {"id": "150 Epochs", "type": "Hyperparameter_Value"}, "type": "HAS_EPOCHS"}, {"source": {"id": "SCE", "type": "Loss_Function"}, "target": {"id": "Sparse Categorical Crossentropy", "type": "Loss_Function"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "Acc", "type": "Evaluation_Metric"}, "target": {"id": "Accuracy", "type": "Evaluation_Metric"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "MAE", "type": "Evaluation_Metric"}, "target": {"id": "Mean Absolute Error", "type": "Evaluation_Metric"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "MSE", "type": "Concept"}, "target": {"id": "Mean Squared Error (Loss)", "type": "Loss_Function"}, "type": "IS_ACRONYM_FOR_LOSS"}, {"source": {"id": "MSE", "type": "Concept"}, "target": {"id": "Mean Squared Error (Metric)", "type": "Evaluation_Metric"}, "type": "IS_ACRONYM_FOR_METRIC"}, {"source": {"id": "softmax function", "type": "Activation_Function"}, "target": {"id": "softmax function", "type": "Activation_Function"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "Linear activation function", "type": "Activation_Function"}, "target": {"id": "Linear activation function", "type": "Activation_Function"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "TimeDistributed layer", "type": "Layer_Type"}, "target": {"id": "TimeDistributed layer", "type": "Layer_Type"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "Conv1D/2D layer", "type": "Layer_Type"}, "target": {"id": "Conv1D/2D layer", "type": "Layer_Type"}, "type": "IS_ACRONYM_FOR"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "Model Dimension", "type": "Concept"}, "type": "HAS_PROPERTY"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "Heads", "type": "Concept"}, "type": "HAS_PROPERTY"}, {"source": {"id": "RNNs", "type": "Model_Family"}, "target": {"id": "hidden units", "type": "Model_Component"}, "type": "USES"}, {"source": {"id": "CT", "type": "Model_Characteristic"}, "target": {"id": "RNNs", "type": "Model_Family"}, "type": "CHARACTERIZES"}, {"source": {"id": "DT", "type": "Model_Characteristic"}, "target": {"id": "RNNs", "type": "Model_Family"}, "type": "CHARACTERIZES"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "Model Dimension", "type": "Concept"}, "type": "USES"}, {"source": {"id": "Attention", "type": "Model"}, "target": {"id": "Heads", "type": "Concept"}, "type": "USES"}, {"source": {"id": "Table 5", "type": "Document_Element"}, "target": {"id": "Data distributions", "type": "Concept"}, "type": "DESCRIBES"}, {"source": {"id": "Data distributions", "type": "Concept"}, "target": {"id": "PRONOSTIA", "type": "Dataset"}, "type": "OF"}, {"source": {"id": "Data distributions", "type": "Concept"}, "target": {"id": "XJTU-SY", "type": "Dataset"}, "type": "OF"}, {"source": {"id": "Data distributions", "type": "Concept"}, "target": {"id": "HUST", "type": "Dataset"}, "type": "OF"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "100 Hz", "type": "Frequency"}, "type": "HAS_FREQUENCY"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "4 kN", "type": "Radial_Load"}, "type": "HAS_RADIAL_LOAD"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "1800 rpm", "type": "Speed"}, "type": "HAS_SPEED"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "100 Hz", "type": "Frequency"}, "type": "HAS_FREQUENCY"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "4.2 kN", "type": "Radial_Load"}, "type": "HAS_RADIAL_LOAD"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "1650 rpm", "type": "Speed"}, "type": "HAS_SPEED"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "100 Hz", "type": "Frequency"}, "type": "HAS_FREQUENCY"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "5 kN", "type": "Radial_Load"}, "type": "HAS_RADIAL_LOAD"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "1500 rpm", "type": "Speed"}, "type": "HAS_SPEED"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "4 ~ 7 Training Samples", "type": "Data_Split_Range"}, "type": "HAS_TRAIN_SPLIT"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "1 ~ 3 Testing Samples", "type": "Data_Split_Range"}, "type": "HAS_TEST_SPLIT"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "1 ~ 7 Testing Samples", "type": "Data_Split_Range"}, "type": "HAS_TEST_SPLIT"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "35 Hz", "type": "Frequency"}, "type": "HAS_FREQUENCY"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "12 kN", "type": "Radial_Load"}, "type": "HAS_RADIAL_LOAD"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "2100 rpm", "type": "Speed"}, "type": "HAS_SPEED"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "1 ~ 5 Testing Samples", "type": "Data_Split_Range"}, "type": "HAS_TEST_SPLIT"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "37.5 Hz", "type": "Frequency"}, "type": "HAS_FREQUENCY"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "11 kN", "type": "Radial_Load"}, "type": "HAS_RADIAL_LOAD"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "2250 rpm", "type": "Speed"}, "type": "HAS_SPEED"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "40 Hz", "type": "Frequency"}, "type": "HAS_FREQUENCY"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "10 kN", "type": "Radial_Load"}, "type": "HAS_RADIAL_LOAD"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "2400 rpm", "type": "Speed"}, "type": "HAS_SPEED"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 1", "type": "Operating_Condition_Identifier"}, "target": {"id": "0 W", "type": "Power"}, "type": "HAS_POWER"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "1 ~ 5 Testing Samples", "type": "Data_Split_Range"}, "type": "HAS_TEST_SPLIT"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 2", "type": "Operating_Condition_Identifier"}, "target": {"id": "200 W", "type": "Power"}, "type": "HAS_POWER"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "type": "HAS_CONDITION"}, {"source": {"id": "Condition 3", "type": "Operating_Condition_Identifier"}, "target": {"id": "400 W", "type": "Power"}, "type": "HAS_POWER"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "training", "type": "Purpose"}, "type": "UTILIZED_FOR"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "generalization testing", "type": "Purpose"}, "type": "UTILIZED_FOR"}, {"source": {"id": "PRONOSTIA", "type": "Dataset"}, "target": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "type": "COLLECTED_UNDER"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "1800 rpm", "type": "Speed"}, "type": "INCLUDES_SPEED"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "4 kN", "type": "Radial_Load"}, "type": "INCLUDES_RADIAL_LOAD"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "1650 rpm", "type": "Speed"}, "type": "INCLUDES_SPEED"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "4.2 kN", "type": "Radial_Load"}, "type": "INCLUDES_RADIAL_LOAD"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "1500 rpm", "type": "Speed"}, "type": "INCLUDES_SPEED"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "5 kN", "type": "Radial_Load"}, "type": "INCLUDES_RADIAL_LOAD"}, {"source": {"id": "three different operating settings", "type": "Operating_Condition_Category"}, "target": {"id": "100 Hz", "type": "Frequency"}, "type": "INCLUDES_FREQUENCY"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "accelerometers", "type": "Sensor"}, "type": "RECORDED_USING"}, {"source": {"id": "accelerometers", "type": "Sensor"}, "target": {"id": "horizontal axes", "type": "Physical_Axis"}, "type": "PLACED_ON"}, {"source": {"id": "accelerometers", "type": "Sensor"}, "target": {"id": "vertical axes", "type": "Physical_Axis"}, "type": "PLACED_ON"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "25.6 kHz Sampling Rate", "type": "Sampling_Rate"}, "type": "SAMPLED_AT"}, {"source": {"id": "temperature readings", "type": "Data_Type"}, "target": {"id": "10 Hz Sampling Rate", "type": "Sampling_Rate"}, "type": "COLLECTED_AT"}, {"source": {"id": "Table 5", "type": "Document_Element"}, "target": {"id": "Data distributions", "type": "Concept"}, "type": "PROVIDES"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Xi\u2019an Jiaotong University", "type": "Organization"}, "type": "DEVELOPED_BY"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Changxing Sumyoung Technology", "type": "Organization"}, "type": "DEVELOPED_BY"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "Wang et al., 2018", "type": "Publication"}, "type": "REFERENCED_BY"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "15 complete run-to-failure experiments", "type": "Experiment"}, "type": "COMPRISES"}, {"source": {"id": "15 complete run-to-failure experiments", "type": "Experiment"}, "target": {"id": "accelerated degradation conditions", "type": "Condition"}, "type": "PERFORMED_UNDER"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "accelerometer", "type": "Sensor"}, "type": "RECORDED_USING"}, {"source": {"id": "accelerometer", "type": "Sensor"}, "target": {"id": "horizontal axes", "type": "Physical_Axis"}, "type": "MOUNTED_ON"}, {"source": {"id": "accelerometer", "type": "Sensor"}, "target": {"id": "vertical axes", "type": "Physical_Axis"}, "type": "MOUNTED_ON"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "25.6 kHz Sampling Rate", "type": "Sampling_Rate"}, "type": "SAMPLED_AT"}, {"source": {"id": "XJTU-SY", "type": "Dataset"}, "target": {"id": "cross-validation test", "type": "Purpose"}, "type": "USED_FOR"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Hanoi University of Science and Technology", "type": "Organization"}, "type": "DEVELOPED_BY"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "ball bearing fault diagnosis", "type": "Task"}, "type": "SUPPORTS"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Hong & Thuan, 2023", "type": "Publication"}, "type": "REFERENCED_BY"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Vibration data", "type": "Data_Type"}, "type": "INCLUDES"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "five bearing types", "type": "Component_Category"}, "type": "COLLECTED_FROM"}, {"source": {"id": "five bearing types", "type": "Component_Category"}, "target": {"id": "6204", "type": "Bearing_Type"}, "type": "INCLUDES"}, {"source": {"id": "five bearing types", "type": "Component_Category"}, "target": {"id": "6205", "type": "Bearing_Type"}, "type": "INCLUDES"}, {"source": {"id": "five bearing types", "type": "Component_Category"}, "target": {"id": "6206", "type": "Bearing_Type"}, "type": "INCLUDES"}, {"source": {"id": "five bearing types", "type": "Component_Category"}, "target": {"id": "6207", "type": "Bearing_Type"}, "type": "INCLUDES"}, {"source": {"id": "five bearing types", "type": "Component_Category"}, "target": {"id": "6208", "type": "Bearing_Type"}, "type": "INCLUDES"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "three different load conditions", "type": "Operating_Condition_Category"}, "type": "COLLECTED_UNDER"}, {"source": {"id": "three different load conditions", "type": "Operating_Condition_Category"}, "target": {"id": "0 W", "type": "Power"}, "type": "INCLUDES"}, {"source": {"id": "three different load conditions", "type": "Operating_Condition_Category"}, "target": {"id": "200 W", "type": "Power"}, "type": "INCLUDES"}, {"source": {"id": "three different load conditions", "type": "Operating_Condition_Category"}, "target": {"id": "400 W", "type": "Power"}, "type": "INCLUDES"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "Six fault categories", "type": "Fault_Category"}, "type": "INCLUDES"}, {"source": {"id": "Six fault categories", "type": "Fault_Category"}, "target": {"id": "single faults", "type": "Fault_Type"}, "type": "CONSISTS_OF"}, {"source": {"id": "Six fault categories", "type": "Fault_Category"}, "target": {"id": "compound faults", "type": "Fault_Type"}, "type": "CONSISTS_OF"}, {"source": {"id": "single faults", "type": "Fault_Type"}, "target": {"id": "inner race", "type": "Fault_Location"}, "type": "INCLUDES"}, {"source": {"id": "single faults", "type": "Fault_Type"}, "target": {"id": "outer race", "type": "Fault_Location"}, "type": "INCLUDES"}, {"source": {"id": "single faults", "type": "Fault_Type"}, "target": {"id": "ball", "type": "Fault_Location"}, "type": "INCLUDES"}, {"source": {"id": "compound faults", "type": "Fault_Type"}, "target": {"id": "inner\u2013outer", "type": "Fault_Combination"}, "type": "INCLUDES"}, {"source": {"id": "compound faults", "type": "Fault_Type"}, "target": {"id": "inner\u2013ball", "type": "Fault_Combination"}, "type": "INCLUDES"}, {"source": {"id": "compound faults", "type": "Fault_Type"}, "target": {"id": "outer\u2013ball", "type": "Fault_Combination"}, "type": "INCLUDES"}, {"source": {"id": "Faults", "type": "Concept"}, "target": {"id": "early-stage defects", "type": "Defect_Type"}, "type": "CREATED_AS"}, {"source": {"id": "early-stage defects", "type": "Defect_Type"}, "target": {"id": "0.2 mm micro-cracks", "type": "Defect_Description"}, "type": "DESCRIBED_AS"}, {"source": {"id": "0.2 mm micro-cracks", "type": "Defect_Description"}, "target": {"id": "real degradation scenarios", "type": "Scenario"}, "type": "SIMULATES"}, {"source": {"id": "Vibration data", "type": "Data_Type"}, "target": {"id": "51.2 kHz Sampling Rate", "type": "Sampling_Rate"}, "type": "SAMPLED_AT"}, {"source": {"id": "recordings", "type": "Concept"}, "target": {"id": "10-second recordings", "type": "Recording_Duration"}, "type": "HAS_DURATION"}, {"source": {"id": "HUST", "type": "Dataset"}, "target": {"id": "cross-validation test", "type": "Purpose"}, "type": "USED_FOR"}, {"source": {"id": "Condition monitoring data", "type": "Data_Type"}, "target": {"id": "1D non-stationary vibrational signals", "type": "Data_Type"}, "type": "COMPRISES"}, {"source": {"id": "1D non-stationary vibrational signals", "type": "Data_Type"}, "target": {"id": "multiple sensors", "type": "Component_Category"}, "type": "COLLECTED_FROM"}, {"source": {"id": "1D non-stationary vibrational signals", "type": "Data_Type"}, "target": {"id": "features", "type": "Concept"}, "type": "TRANSFORMED_INTO"}, {"source": {"id": "features", "type": "Concept"}, "target": {"id": "physical interpretability", "type": "Concept"}, "type": "POSSESS"}, {"source": {"id": "preprocessing", "type": "Process"}, "target": {"id": "Razzaq & Zhao, 2025a", "type": "Publication"}, "type": "PROPOSED_IN"}, {"source": {"id": "labels", "type": "Concept"}, "target": {"id": "Razzaq & Zhao, 2025b", "type": "Publication"}, "type": "GENERATED_ACCORDING_TO"}, {"source": {"id": "signal", "type": "Concept"}, "target": {"id": "windowing technique (w)", "type": "Method"}, "type": "SEGMENTED_USING"}, {"source": {"id": "windowing technique (w)", "type": "Method"}, "target": {"id": "localization of transient characteristics", "type": "Purpose"}, "type": "ENABLES"}, {"source": {"id": "continuous wavelet transform (CWT)", "type": "Method"}, "target": {"id": "signal", "type": "Concept"}, "type": "APPLIED_TO"}, {"source": {"id": "continuous wavelet transform (CWT)", "type": "Method"}, "target": {"id": "Aguiar-Conraria & Soares, 2014", "type": "Publication"}, "type": "REFERENCED_BY"}, {"source": {"id": "Morlet wavelet", "type": "Wavelet_Function"}, "target": {"id": "continuous wavelet transform (CWT)", "type": "Method"}, "type": "USED_AS_MOTHER_WAVELET_FOR"}, {"source": {"id": "Morlet wavelet", "type": "Wavelet_Function"}, "target": {"id": "Lin & Qu, 2000", "type": "Publication"}, "type": "REFERENCED_BY"}, {"source": {"id": "continuous wavelet transform (CWT)", "type": "Method"}, "target": {"id": "time-frequency representation (TFR)", "type": "Data_Representation"}, "type": "OBTAINS"}, {"source": {"id": "a", "type": "Parameter"}, "target": {"id": "scale", "type": "Parameter"}, "type": "DENOTES"}, {"source": {"id": "b", "type": "Parameter"}, "target": {"id": "translation parameters", "type": "Parameter"}, "type": "DENOTES"}, {"source": {"id": "\u03c8", "type": "Function"}, "target": {"id": "Morlet wavelet function", "type": "Function"}, "type": "IS_A_TYPE_OF"}, {"source": {"id": "features", "type": "Concept"}, "target": {"id": "time-frequency representation (TFR)", "type": "Data_Representation"}, "type": "EXTRACTED_FROM"}, {"source": {"id": "features", "type": "Concept"}, "target": {"id": "statistical features", "type": "Feature_Type"}, "type": "ARE_OF_TYPE"}, {"source": {"id": "features", "type": "Concept"}, "target": {"id": "domain-specific features", "type": "Feature_Type"}, "type": "ARE_OF_TYPE"}, {"source": {"id": "features", "type": "Concept"}, "target": {"id": "operational condition of the bearing", "type": "Concept"}, "type": "CHARACTERIZE"}, {"source": {"id": "feature extraction procedure", "type": "Procedure"}, "target": {"id": "Algorithm 3", "type": "Algorithm"}, "type": "DESCRIBED_IN"}, {"source": {"id": "Neural Network Architecture", "type": "Concept"}, "target": {"id": "compact neural network", "type": "Model_Type"}, "type": "DESIGNS"}, {"source": {"id": "compact neural network", "type": "Model_Type"}, "target": {"id": "degradation dynamics", "type": "Concept"}, "type": "MODELS"}, {"source": {"id": "compact neural network", "type": "Model_Type"}, "target": {"id": "resource-constrained devices", "type": "Device_Category"}, "type": "FEASIBLE_FOR_DEPLOYMENT_ON"}, {"source": {"id": "compact neural network", "type": "Model_Type"}, "target": {"id": "localized prognostics", "type": "Task"}, "type": "ENABLES"}, {"source": {"id": "compact neural network", "type": "Model_Type"}, "target": {"id": "personalized prognostics", "type": "Task"}, "type": "ENABLES"}, {"source": {"id": "localized prognostics", "type": "Task"}, "target": {"id": "individual machines", "type": "Target_System"}, "type": "TARGETS"}, {"source": {"id": "personalized prognostics", "type": "Task"}, "target": {"id": "individual machines", "type": "Target_System"}, "type": "TARGETS"}, {"source": {"id": "architecture", "type": "Model_Type"}, "target": {"id": "compact convolutional network", "type": "Model_Type"}, "type": "COMBINES"}, {"source": {"id": "architecture", "type": "Model_Type"}, "target": {"id": "NAC", "type": "Model"}, "type": "COMBINES"}, {"source": {"id": "CNN component", "type": "Model_Component"}, "target": {"id": "spatial degradation features", "type": "Feature_Type"}, "type": "EXTRACTS"}, {"source": {"id": "spatial degradation features", "type": "Feature_Type"}, "target": {"id": "training data", "type": "Data_Type"}, "type": "FROM"}, {"source": {"id": "NAC", "type": "Model"}, "target": {"id": "temporal filtering", "type": "Process"}, "type": "PERFORMS"}, {"source": {"id": "temporal filtering", "type": "Process"}, "target": {"id": "informative features", "type": "Feature_Type"}, "type": "EMPHASIZES"}, {"source": {"id": "architecture", "type": "Model_Type"}, "target": {"id": "small model size", "type": "Characteristic"}, "type": "MAINTAINS"}, {"source": {"id": "architecture", "type": "Model_Type"}, "target": {"id": "representational capacity", "type": "Characteristic"}, "type": "WITHOUT_SACRIFICING"}, {"source": {"id": "hyperparameter configurations", "type": "Concept"}, "target": {"id": "Table 4", "type": "Document_Element"}, "type": "REPORTED_IN"}, {"source": {"id": "Score", "type": "Evaluation_Metric"}, "target": {"id": "Remaining Useful Life (RUL) Estimation", "type": "Task"}, "type": "DESIGNED_FOR"}, {"source": {"id": "Score", "type": "Evaluation_Metric"}, "target": {"id": "IEEE PHM", "type": "Organization"}, "type": "DEFINED_BY"}, {"source": {"id": "Score", "type": "Evaluation_Metric"}, "target": {"id": "Nectoux et al., 2012", "type": "Publication"}, "type": "REFERENCED_BY"}, {"source": {"id": "scoring function", "type": "Concept"}, "target": {"id": "asymmetric", "type": "Characteristic"}, "type": "IS"}, {"source": {"id": "scoring function", "type": "Concept"}, "target": {"id": "overestimations", "type": "Error_Type"}, "type": "PENALIZES_MORE_HEAVILY"}, {"source": {"id": "scoring function", "type": "Concept"}, "target": {"id": "early predictions", "type": "Prediction_Type"}, "type": "THAN"}, {"source": {"id": "late maintenance prediction", "type": "Prediction_Type"}, "target": {"id": "unexpected failures", "type": "Event"}, "type": "CAN_LEAD_TO"}, {"source": {"id": "unexpected failures", "type": "Event"}, "target": {"id": "severe consequences", "type": "Consequence"}, "type": "HAS"}], "source": {"page_content": "Wavelets: \u0393 _iw_ ( _a, b_ ) = \ufffd _\u2212\u221e\u221e_ _[i][w][\u03c8][\u2217]_ [\ufffd] _[t][\u2212]_ _a_ _[b]_ \ufffd _dt._\n\nEnergy: _E_ = [\ufffd] _[M]_ _m_ =1 _[|]_ [\u0393] _[iw]_ [(] _[a, b]_ [)] _[|]_ [2]\n\nDominant frequency: _fd_ = _a_ scale [arg max( _E_ )].\nEntropy: _h_ = _\u2212_ [\ufffd] _[M]_ _i_ = _m_ _[P]_ [(] _[i][w]_ [(] _[t]_ [)) log] _[ P]_ [(] _[i][w]_ [(] _[t]_ [))][.]\n\nKurtosis: _K_ = [E][[(] _[i][w]_ [(] _\u03c3_ _[t]_ [4][)] _[\u2212][\u00b5]_ [)][4][]] .\n\nSkewness: _sk_ = [E][[(] _[i][w]_ [(] _\u03c3_ _[t]_ [3][)] _[\u2212][\u00b5]_ [)][3][]] .\n\n1 _M_\nmean: _\u00b5_ = _M_ \ufffd _m_ =1 _[i][w]_ [(] _[m]_ [)][.]\n\n\n1 _M_\n\nstandard deviation: _\u03c3_ = ~~\ufffd~~ _M_ ~~\ufffd~~ _i_ =1 [(] _[i][w]_ [(] _[m]_ [)] _[ \u2212]_ _[\u00b5]_ [)][2][.]\n\n_Xn \u2190_ [log( _E_ ) _, fd, h, K, sk, \u00b5, \u03c3_ ]\n**end for**\n**return** _IT F R_ = _Concat_ ( _X_ 1 _, X_ 2 _. . . XNs_ _, tn, Tn_ )\n\n\n\n16\n\n\n**Neuronal Attention Circuit (NAC) for Representation Learning**\n\n\n_Table 4._ Summary of Key Hyperparameters of All Experiments\n\n\n**Param.** **MNIST** **PAR** **CarRacing** **Udacity** **RUL EST.**\n\n\nConv layers 2\u00d7 **1D** (64@5) **1D** (64@5, 64@3) 3\u00d7TD- **2D** (10\u201330@3\u20135) 5\u00d7 **2D** (24\u201364@5\u20133, ELU) 2\u00d7 **1D** (32@3, 16@2)\nNAC 64-d, 8h 32-d, 4h 64-d, 16h 100-d, 16h 16-d, 8h\nDense 32\u201310(SM) 32\u201311(SM) 64\u20135(SM) 64\u20131(Lin) 1(Lin)\nDropout \u2013 \u2013 0.2 0.5 \u2013\nOpt. AdamW AdamW Adam AdamW AdamW\nLR 0.001 0.001 0.0001 0.001 0.001\n\nLoss SCE SCE SCE MSE MSE\n\nMetric Acc Acc Acc MAE Score\n\nBatch 32 20 32 \u2013 32\n\nEpochs 150 500 100 10 150\n\n\n**Note:** SCE = Sparse Categorical Crossentropy; Acc = Accuracy; MAE = Mean Absolute Error; MSE =\nsoftmax; Lin = Linear; TD = TimeDistributed; Conv1D/2D = Conv1D/2D; _d_ = model dimension; _h_ = attention heads.\n\n**Baselines Hyperparameters Clarification:** All (CT & DT) RNNs use the same number of hidden units as NAC\u2019s _d_ model, and all (DT & \nCT) Attention use the same _d_ model and _heads_ as NAC. The other layers, including 1D/2D, Dense, and the remaining hyperparameters, are\nthe same during our tests.\n\n\n_Table 5._ Data distributions of PRONOSTIA, XJTU-SY, and HUST datasets.\n\n\n**Dataset** **Condition** **Frequency** **Radial Load** **Speed** **Train** **Test**\n\n_Condition 1_ 100 Hz 4 kN 1800 rpm 4 _\u223c_ 7 1 _\u223c_ 3\n**PRONOSTIA** _Condition 2_ 100 Hz 4.2 kN 1650 rpm - 1 _\u223c_ 7\n_Condition 3_ 100 Hz 5 kN 1500 rpm - 1 _\u223c_ 3\n\n_Condition 1_ 35 Hz 4 kN 2100 rpm - 1 _\u223c_ 5\n**XJTU-SY** _Condition 2_ 37.5 Hz 4.2 kN 2250 rpm - 1 _\u223c_ 5\n_Condition 3_ 40 Hz 5 kN 2400 rpm - 1 _\u223c_ 5\n\n_Condition 1_ - 0 W - - 1 _\u223c_ 5\n\n**HUST** _Condition 2_ - 200 W - - 1 _\u223c_ 5\n\n_Condition 3_ - 400 W - - 1 _\u223c_ 5\n\n\n**Note:** The PRONOSTIA dataset is utilized for training and generalization testing, while the XJTU-SY and HUST datasets are employed\nto evaluate cross-validation testing. (-) values are either not available or not utilized.\n\n\n\nacross three different operating settings: 1800 rpm with 4\nkN radial load, 1650 rpm with a 4.2 kN load, and 1500 rpm\nwith a 5 kN load, all at a frequency of 100 Hz. Vibration\ndata were recorded using accelerometers placed along the\nhorizontal and vertical axes, which were sampled at 25.6\nkHz. Additionally, temperature readings were collected at a\nsampling rate of 10 Hz. The data distributions for training\nand testing are provided in Table 5.\n_XJTU-SY Dataset_ is another widely recognized benchmark\ndataset developed through collaboration between Xi\u2019an\nJiaotong University and Changxing Sumyoung Technology\n(Wang et al., 2018). The dataset comprises 15 complete runto-failure experiments performed under accelerated degradation conditions with three distinct operational settings: 1200\nrpm (35 Hz) with a 12 kN radial load, 2250 rpm (37.5 Hz)\nwith an 11 kN radial load, and 2400 rpm (40 Hz) with a 10\nkN radial load. Vibrational signals were recorded using an\naccelerometer mounted on the horizontal and vertical axes\n\nand sampled at 25.6 kHz. This dataset is only used for the\n\n\n\ncross-validation test.\n\n_HUST Dataset_ is a practical dataset developed by Hanoi\nUniversity of Science and Technology to support research\non ball bearing fault diagnosis (Hong & Thuan, 2023). The\ndataset includes vibration data collected from five bearing\ntypes (6204, 6205, 6206, 6207, and 6208) under three different load conditions: 0 W, 200 W, and 400 W. Six fault\ncategories were introduced, consisting of single faults (inner race, outer race, and ball) and compound faults (inner\u2013outer, inner\u2013ball, and outer\u2013ball). Faults were created\nas early-stage defects in the form of 0.2 mm micro-cracks,\nsimulating real degradation scenarios. The vibration signals\nwere sampled at 51.2 kHz with approximately 10-second\nrecordings for each case. This dataset is only used for the\ncross-validation test.\n\n**Preprocess:** Condition monitoring data comprises 1D nonstationary vibrational signals collected from multiple sensors. To extract meaningful information, these signals must\nbe transformed into features that possess meaningful physi\n\n\n17\n\n\n**Neuronal Attention Circuit (NAC) for Representation Learning**\n\n\ncal interpretability. We utilized the preprocessing proposed\nin (Razzaq & Zhao, 2025a) and labels are generated according to (Razzaq & Zhao, 2025b). Initially, the signal\nis segmented into small, rectangularized vectors using a\nwindowing technique ( _w_ ), enabling better localization of\ntransient characteristics. The continuous wavelet transform\n\n(CWT) (Aguiar-Conraria & Soares, 2014) with the Morlet\nwavelet (Lin & Qu, 2000) as the mother wavelet is then applied to obtain a time-frequency representation (TFR). The\nCWT is defined as \u0393( _a, b_ ) = \ufffd _\u2212\u221e\u221e_ _[x][w]_ [(] _[t]_ [)] ~~_\u221a_~~ [1] ~~_a_~~ _\u03c8_ _[\u2217]_ [\ufffd] _[t][\u2212]_ _a_ _[b]_ \ufffd _dt_,\n\nwhere _a_ and _b_ denote the scale and translation parameters,\nrespectively, and _\u03c8_ is the Morlet wavelet function. From\nthe resulting TFR, a compact set of statistical and domainspecific features is extracted to characterize the operational\ncondition of the bearing. The complete feature extraction\nprocedure is described in Algorithm 3.\n**Neural Network Architecture:** The objective of this problem is to design a compact neural network that can effectively model degradation dynamics while remaining feasible\nfor deployment on resource-constrained devices, enabling\nlocalized and personalized prognostics for individual machines. To achieve this, we combine a compact convolutional network with NAC. The CNN component extracts\nspatial degradation features from the training data, while\nNAC performs temporal filtering to emphasize informative\nfeatures. This architecture maintains a small model size\n\nwithout sacrificing representational capacity. Full hyperparameter configurations are reported in Table 4.\n**Evaluation Metric:** Score is a metric specifically designed\nfor RUL estimation in the IEEE PHM (Nectoux et al., 2012)\nto score the estimates. The scoring function is asymmetric and penalizes overestimations more heavily than early\npredictions. This reflects practical considerations, as late\nmaintenance prediction can lead to unexpected failures with\nmore severe consequences than early intervention can.\n\n\n\n_yi_ \u02c6 _\u2212yi_\n\n10 _\u2212_ 1\n\ufffd\n\n\n(48)\n\n\n\n_Score_ = \ufffd\n\n_i_ :\u02c6 _yi<yi_\n\n\n\n_e_ _[\u2212]_ _[yi]_ [\u02c6] 13 _[\u2212][yi]_ _\u2212_ 1 +\n\ufffd \ufffd \ufffd\n\n_i_ :\u02c6 _yi\u2265yi_\n\n\n\n_e_\n\ufffd\n\n\n\n18", "metadata": null}}
