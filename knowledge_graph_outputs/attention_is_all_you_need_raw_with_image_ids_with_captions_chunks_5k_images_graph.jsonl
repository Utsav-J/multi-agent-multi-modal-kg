{"nodes": [{"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::3 Model Architecture", "type": "Section", "metadata": []}, {"id": "Transformer architecture", "type": "Concept", "metadata": []}, {"id": "Encoder", "type": "Concept", "metadata": []}, {"id": "Decoder", "type": "Concept", "metadata": []}, {"id": "Multi-Head Attention", "type": "Concept", "metadata": []}, {"id": "Masked Multi-Head Attention", "type": "Concept", "metadata": []}, {"id": "Feed Forward Network", "type": "Concept", "metadata": []}, {"id": "Add & Norm layer", "type": "Concept", "metadata": []}, {"id": "Input Embedding", "type": "Concept", "metadata": []}, {"id": "Output Embedding", "type": "Concept", "metadata": []}, {"id": "Positional Encoding", "type": "Concept", "metadata": []}, {"id": "Linear layer", "type": "Concept", "metadata": []}, {"id": "Softmax layer", "type": "Concept", "metadata": []}, {"id": "Output Probabilities", "type": "Concept", "metadata": []}, {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::3.2 Attention", "type": "Section", "metadata": []}, {"id": "Q (query)", "type": "Concept", "metadata": []}, {"id": "K (key)", "type": "Concept", "metadata": []}, {"id": "V (value)", "type": "Concept", "metadata": []}, {"id": "Matrix Multiplication", "type": "Concept", "metadata": []}, {"id": "Scale operation", "type": "Concept", "metadata": []}, {"id": "Masking layer", "type": "Concept", "metadata": []}, {"id": "SoftMax function", "type": "Concept", "metadata": []}, {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, {"id": "Multi-head attention", "type": "Concept", "metadata": []}, {"id": "Scaled Dot-Product Attention", "type": "Concept", "metadata": []}, {"id": "Concatenation", "type": "Concept", "metadata": []}, {"id": "Query (Q)", "type": "Concept", "metadata": []}, {"id": "Key (K)", "type": "Concept", "metadata": []}, {"id": "Value (V)", "type": "Concept", "metadata": []}, {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::References", "type": "Section", "metadata": []}, {"id": "Attention mechanism", "type": "Concept", "metadata": []}, {"id": "Token relationships", "type": "Concept", "metadata": []}, {"id": "Natural Language Processing", "type": "Concept", "metadata": []}, {"id": "Sentence visualization", "type": "Concept", "metadata": []}, {"id": "Word embeddings", "type": "Concept", "metadata": []}, {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, {"id": "attention heads", "type": "Concept", "metadata": []}, {"id": "attention patterns", "type": "Concept", "metadata": []}, {"id": "anaphora resolution", "type": "Concept", "metadata": []}, {"id": "neural network layers", "type": "Concept", "metadata": []}, {"id": "word tokens", "type": "Concept", "metadata": []}, {"id": "attention weights", "type": "Concept", "metadata": []}, {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, {"id": "Attention map", "type": "Concept", "metadata": []}, {"id": "Self-attention mechanism", "type": "Concept", "metadata": []}, {"id": "Encoder attention head", "type": "Concept", "metadata": []}, {"id": "Tokens", "type": "Concept", "metadata": []}, {"id": "Attention weights", "type": "Concept", "metadata": []}, {"id": "Sentence structure", "type": "Concept", "metadata": []}], "relationships": [{"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, "type": "PART_OF"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::3 Model Architecture", "type": "Section", "metadata": []}, "type": "LOCATED_IN"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Transformer architecture", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Encoder", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Decoder", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Multi-Head Attention", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Masked Multi-Head Attention", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Feed Forward Network", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Add & Norm layer", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Input Embedding", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Output Embedding", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Positional Encoding", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Linear layer", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Softmax layer", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_2_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-2-0.png"}]}, "target": {"id": "Output Probabilities", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, "type": "PART_OF"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::3.2 Attention", "type": "Section", "metadata": []}, "type": "LOCATED_IN"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "Q (query)", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "K (key)", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "V (value)", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "Matrix Multiplication", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "Scale operation", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "Masking layer", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-0.png"}]}, "target": {"id": "SoftMax function", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, "type": "PART_OF"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::3.2 Attention", "type": "Section", "metadata": []}, "type": "LOCATED_IN"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Multi-head attention", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Scaled Dot-Product Attention", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Linear layer", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Concatenation", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Query (Q)", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Key (K)", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_3_1", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-3-1.png"}]}, "target": {"id": "Value (V)", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, "type": "PART_OF"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::References", "type": "Section", "metadata": []}, "type": "LOCATED_IN"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "Attention mechanism", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "Token relationships", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "Natural Language Processing", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "Sentence visualization", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_12_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-12-0.png"}]}, "target": {"id": "Word embeddings", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, "type": "PART_OF"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::References", "type": "Section", "metadata": []}, "type": "LOCATED_IN"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "attention heads", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "attention patterns", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "anaphora resolution", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "neural network layers", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "word tokens", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_13_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-13-0.png"}]}, "target": {"id": "attention weights", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions", "type": "Document", "metadata": []}, "type": "PART_OF"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "attention_is_all_you_need_raw_with_image_ids_with_captions::section::References", "type": "Section", "metadata": []}, "type": "LOCATED_IN"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "Attention map", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "Self-attention mechanism", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "Encoder attention head", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "Tokens", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "Attention weights", "type": "Concept", "metadata": []}, "type": "DEPICTS"}, {"source": {"id": "img_attention_is_all_you_need_14_0", "type": "Image", "metadata": [{"key": "source_path", "value": "E:/Python Stuff/MAS-for-multimodal-knowledge-graph/markdown_outputs/images/attention_is_all_you_need.pdf-14-0.png"}]}, "target": {"id": "Sentence structure", "type": "Concept", "metadata": []}, "type": "DEPICTS"}]}
