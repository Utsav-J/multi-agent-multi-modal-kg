{"id": "rag_paper_annotated_0", "content": "```\n### Figure - Elsevier Logo\n![Elsevier Logo](E:\\Python Stuff\\MAS-for-multimodal-knowledge-graph\\markdown_outputs\\images\\rag_paper.pdf-0-1.png)\n\n**Caption:** The image displays the official logo of Elsevier, a prominent academic publishing company. It features a detailed illustration of a tree with figures beneath it.\n\n**Description:**\n- The logo incorporates a complex, monochrome illustration of a tree with multiple branches and figures.\n- Two figures are depicted beneath the tree, suggesting a scene of learning or knowledge sharing.\n- The word \"ELSEVIER\" is prominently displayed in a bold, orange font below the illustration.\n\n```\n### Figure - Procedia Journal Logo\n![Procedia Journal Logo](rag_paper.pdf-0-2.png)\n\n**Caption:** The image displays the logo for the Procedia Computer Science journal. It highlights the journal's focus on computer science research. The logo is presented in a clean, professional design.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 0}
{"id": "rag_paper_annotated_1", "content": "**Description:**\n- The logo features the word \"Procedia\" in a bold, sans-serif typeface.\n- \"Computer Science\" is positioned below the main wordmark, indicating the journal's subject area.\n- The logo incorporates horizontal lines to create a structured and formal appearance.\n- The website address \"www.elsevier.com/locate/procedia\" is provided for accessing the journal.\n```\n\nAvailable online at www.sciencedirect.com\n\n## **ScienceDirect**\n\n\nProcedia Computer Science 246 (2024) 3781\u20133790\n\n\n28th International Conference on Knowledge-Based and Intelligent Information & Engineering\nSystems (KES 2024)\n\n# A Survey on RAG with LLMs\n\n### Muhammad Arslan [a] *, Hussam Ghanem [a], Saba Munawar [b] and Christophe Cruz [a]\n\n\n_aLaboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Dijon, France_\n_bNational University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan_\n\n\n**Abstract**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 1}
{"id": "rag_paper_annotated_2", "content": "In the fast-paced realm of digital transformation, businesses are increasingly pressured to innovate and boost efficiency to remain\ncompetitive and foster growth. Large Language Models (LLMs) have emerged as game-changers across industries,\nrevolutionizing various sectors by harnessing extensive text data to analyze and generate human-like text. Despite their\nimpressive capabilities, LLMs often encounter challenges when dealing with domain-specific queries, potentially leading to\ninaccuracies in their outputs. In response, Retrieval-Augmented Generation (RAG) has emerged as a viable solution. By\nseamlessly integrating external data retrieval into text generation processes, RAG aims to enhance the accuracy and relevance of\nthe generated content. However, existing literature reviews tend to focus primarily on the technological advancements of RAG,\noverlooking a comprehensive exploration of its applications. This paper seeks to address this gap by providing a thorough review", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 2}
{"id": "rag_paper_annotated_3", "content": "overlooking a comprehensive exploration of its applications. This paper seeks to address this gap by providing a thorough review\nof RAG applications, encompassing both task-specific and discipline-specific studies, while also outlining potential avenues for\nfuture research. By shedding light on current RAG research and outlining future directions, this review aims to catalyze further\nexploration and development in this dynamic field, thereby contributing to ongoing digital transformation efforts.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 3}
{"id": "rag_paper_annotated_4", "content": "\u00a9 2024 The Authors. Published by Elsevier B.V.\nThis is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)\nPeer-review under responsibility of the scientific committee of the 28th International Conference on Knowledge Based and\nIntelligent information and Engineering Systems\n\n\n_Keywords:_ Large Language Models (LLMs); Natural Language Processing (NLP); Retrieval-Augmented Generation (RAG); Text generation;\nDigital transformation.\n\n\n**1.** **Introduction**\n\n\nDigital transformation signifies the incorporation of digital technology across different facets of a business,\nreshaping its operations and value delivery to customers [1]. At the forefront of driving such transformative\npractices are Large Language Models (LLMs), advanced machine learning models trained extensively on textual\ndata to comprehend and produce human-like text [1]. LLMs, such as the Generative Pre-training Transformer (GPT)", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 4}
{"id": "rag_paper_annotated_5", "content": "- Corresponding author. Tel.: +33 03 80 39 50 00; fax: +33 03 80 39 50 69.\n_E-mail address:_ muhammad.arslan@u-bourgogne.fr\n\n\n1877-0509 \u00a9 2024 The Authors. Published by Elsevier B.V.\nThis is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)\nPeer-review under responsibility of the scientific committee of the 28th International Conference on Knowledge\nBased and Intelligent information and Engineering Systems\n10.1016/j.procs.2024.09.178\n\n\n3782 _Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790_", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 5}
{"id": "rag_paper_annotated_6", "content": "series [2, 3] and others, have demonstrated remarkable capabilities in NLP tasks [4]. However, these models face\nchallenges when dealing with domain-specific queries, often generating inaccurate or irrelevant information,\ncommonly referred to as \u201challucinations\u201d, particularly when data is sparse [5]. This limitation makes deploying\nLLMs in real-world settings impractical, as the generated output may not be reliable [4].\nIn the middle of 2020, Lewis et al. [6] introduced RAG, a significant advancement in the field of LLMs for\nimproving generative tasks (see Fig. 1 (a)). RAG incorporates an initial step where LLMs search an external data\nsource to retrieve relevant information before producing text or answering questions. RAG addresses these\nlimitations by integrating external data retrieval into the generative process, thereby enhancing the accuracy and\nrelevance of the generated output. By dynamically retrieving information from knowledge bases during inference,", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 6}
{"id": "rag_paper_annotated_7", "content": "relevance of the generated output. By dynamically retrieving information from knowledge bases during inference,\nRAG provides a more informed and evidence-based approach to language generation, significantly reducing the risk\nof hallucinations and improving the overall quality of the generated text [4, 6]. This approach has the potential to\nmake LLMs more practical for real-world applications, as it ensures that the generated output is grounded in\nretrieved evidence, leading to more reliable and accurate results. Fig. 1 (b) showcases how real-time business\nsystems can leverage the RAG with LLM architecture. As an example, without RAG, the system lacks access to\nreal-time or updated information. However, with RAG integration, leveraging external data sources such as news\narticles, the system can respond to current business events, presenting opportunities for business intelligence\nanalysts.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 7}
{"id": "rag_paper_annotated_8", "content": "(a)                                               (b)\nFig. 1. (a) A generic RAG architecture, where users\u2019 queries, potentially in different modalities (e.g., text, code, image, etc.), are inputted into\nboth the retriever and the generator. The retriever scans for relevant data sources in storage, while the generator engages with the retrieval\noutcomes, ultimately generating results across various modalities [6]; Fig. 1. (b) illustrates how RAG integration with the LLM handles queries\nthat fall outside the scope of the LLM\u2019s training data.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 8}
{"id": "rag_paper_annotated_9", "content": "While the field of RAG has seen substantial growth, several online surveys [4, 7, 8, 9] have explored\ntechnological advancements in RAG. Although these surveys provide valuable insights and references, they offer\nonly a limited overview of RAG applications. To address this gap, this paper aims to provide an exhaustive\noverview of RAG applications, including both task-specific and discipline-specific studies, as well as future\ndirections. By highlighting the current state of RAG research and its potential future directions, this review aims to\ninspire further investigation and development in this exciting field.\nThe paper\u2019s structure is as follows: Section 2 presents the adopted research methodology for this survey. In\nSection 3, we provide an overview of RAG applications, followed by a detailed discussion in Section 4. The paper\nconcludes in Section 5, summarizing the key findings and implications of the study.\n\n\n**2.** **Background**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 9}
{"id": "rag_paper_annotated_10", "content": "**2.** **Background**\n\n\nThe research method (see Fig. 2) employed in this paper involves a thorough review and analysis of research\npublications related to RAG. The main objective is to identify and categorize its applications across various NLP\ntasks and disciplines. The paper begins by collecting research publications specific to RAG, focusing on their\napplications. Since the RAG with LLM domain is relatively new and emerging, with many studies available as pre\n\n\n```\n### Figure - Multimodal Retrieval and Generation System\n![Retrieval and Generation Process](E:\\Python Stuff\\MAS-for-multimodal-knowledge-graph\\markdown_outputs\\images\\rag_paper.pdf-1-0.png)\n\n**Caption:** This figure illustrates a system for multimodal retrieval and generation, transforming input data into a corresponding result. The system utilizes a retriever and generator to process diverse input types.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 10}
{"id": "rag_paper_annotated_11", "content": "**Description:**\n- The system receives input data consisting of text, code, images, audio, and video.\n- A retriever component, which can operate on dense or sparse data, selects relevant information from the input data.\n- A generator component then utilizes the retrieved information to produce a result in the same multimodal format.\n- The output consists of text, code, images, audio, and video, mirroring the input.\n```\n\n```\n### Figure - RAG Architecture with and without Retrieval-Augmented Generation\n![RAG architecture diagram](rag_paper.pdf-1-1.png)\n\n**Caption:** This figure illustrates the difference between a Large Language Model (LLM) query without and with Retrieval-Augmented Generation (RAG). The RAG approach utilizes external data to enhance the LLM's response.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 11}
{"id": "rag_paper_annotated_12", "content": "**Description:**\n- The diagram shows two scenarios: \"Without RAG\" and \"With RAG,\" representing the LLM's response generation process.\n- An \"Analyst\" interacts with the LLM via an \"Input\" and receives an \"Output.\"\n- \"Without RAG\" indicates the LLM's response is solely based on its internal knowledge, limited by its last update in January 2022.\n- \"With RAG\" demonstrates the LLM querying a \"Domain data\" (external database) via a \"Query\" and receiving a \"Reply\" through \"RAG.\"\n- The \"LLM\" processes the \"Reply\" from the \"Domain data\" to generate the final \"Output.\"\n- The \"Domain data\" consists of \"News articles for business events.\"\n_Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790\b_ 3783", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 12}
{"id": "rag_paper_annotated_13", "content": "prints online, limiting the search to platforms such as Scopus or IEEE would greatly reduce the number of studies.\nTherefore, Google Scholar was utilized to access the studies on RAG. However, in cases where both pre-print and\npublished versions of a study were available, the published version was chosen to cover the maximum number of\npeer-reviewed studies. Each study underwent manual review to assess its comprehensiveness and depth, excluding\nshort studies. It is important to note that the purpose of the survey is not to cover the most optimal studies, but rather\nto provide an overview of how this field has attained significant attention in a short period, with researchers\nexploring diverse application scenarios.\nThe keywords used to collect research publications included \u201cretrieval augmented generation\u201d, \u201cRAG\napplications\u201d, \u201cgenerative models with retrieval\u201d, \u201cexternal data retrieval in text generation\u201d, \u201cenhancing text", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 13}
{"id": "rag_paper_annotated_14", "content": "applications\u201d, \u201cgenerative models with retrieval\u201d, \u201cexternal data retrieval in text generation\u201d, \u201cenhancing text\ngeneration with retrieval\u201d, \u201cintegrating retrieval into generative models\u201d, \u201cexternal knowledge in text generation\u201d,\n\u201cretrieval-based text generation\u201d, \u201cinformation retrieval for text generation\u201d, and \u201ccontextualized retrieval in\nlanguage models\u201d. These publications are then classified into two principal categories: task-based classification and\ndiscipline-based classification. Task-based classification focuses on categorizing RAG studies according to their\nexecution of information processing tasks, particularly within NLP. Conversely, discipline-based classification\ncategorizes studies based on their application to specific domains. Under the task-based classification, the\npublications are further subdivided into categories such as Question Answering (QA), Text Generation and", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 14}
{"id": "rag_paper_annotated_15", "content": "publications are further subdivided into categories such as Question Answering (QA), Text Generation and\nSummarization, Information Retrieval and Extraction, Text Analysis and Processing, Software Development and\nMaintenance (SDM), Decision Making and Applications, and Other Categories. Similarly, under the disciplinebased classification, the publications are further subdivided into categories such as Medical/Biomedical, Financial,\nEducational, Technology and Software Development, Social and Communication, Literature, and Other Categories.\nThese categories are selected based on an understanding of the context of the studies and the underlying problems\nthey address. Within both classification methods, \u201csoftware development\u201d stands out as a common category. It\ninvolves programming information processing tasks under task-based classification and encompasses systems for\ndeveloping various applications across different domains under discipline-based classification. Figure 3 illustrates", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 15}
{"id": "rag_paper_annotated_16", "content": "developing various applications across different domains under discipline-based classification. Figure 3 illustrates\nthe number of publications related to RAG applications from 2020 to February 2024. Specifically, there was a single\npublication found in 2020, 6 publications in 2022, 28 publications in 2023, and 16 publications until February 2024,\nindicating a growing interest and research activity in the field of RAG applications.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 16}
{"id": "rag_paper_annotated_17", "content": "Fig. 2. Research Method\n\n\n\n```\n### Figure - Application-Oriented Publication Classification Process\n![RAG Publication Classification](E:\\Python Stuff\\MAS-for-multimodal-knowledge-graph\\markdown_outputs\\images\\rag_paper.pdf-2-0.png)\n\n**Caption:** This figure illustrates a process for classifying application-oriented publications related to Retrieval-Augmented Generation (RAG). The process involves identifying use cases and applications, followed by classification based on task and discipline.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 17}
{"id": "rag_paper_annotated_18", "content": "**Description:**\n- The figure depicts a process flow starting with \u201cResearch publications on RAG.\u201d\n- The process then involves \u201cIdentification of use cases and applications,\u201d leading to \u201cClassification of applications.\u201d\n- \u201cClassification of applications\u201d is further divided into \u201cTask-based classification\u201d and \u201cDiscipline-based classification.\u201d\n- Task-based classification includes categories like \u201cQuestion Answering,\u201d \u201cText Generation and Summarization,\u201d and \u201cInformation Retrieval and Extraction.\u201d\n- Discipline-based classification lists categories such as \u201cMedical / Biomedical,\u201d \u201cFinancial,\u201d and \u201cEducational.\u201d\n- A green triangle indicates the selection of \u201capplication-oriented publications.\u201d\n3784 _Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790_\n\n\nFig. 3. Evolution of Research Publications on RAG Applications\n\n\n**3.** **Applications of RAG with LLMs**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 18}
{"id": "rag_paper_annotated_19", "content": "Upon thorough examination of the selected papers focusing on RAG applications, we uncovered a vast array of\ndiverse applications. These findings are distilled into a comprehensive table format (see Table 1), detailing three\ncrucial aspects: 1) Use case with RAG, 2) Used datasets/benchmarks, and 3) Application area. Noteworthy\napplications span various domains, including biomedical, financial, and medical inquiries, alongside text\nsummarization and book review generation. RAG\u2019s versatility extends to commonsense QA, table-based queries,\nand clinical decision-making, among others. It further encompasses educational decision making, textbook question\nanswering, and enterprise search functionalities. RAG is instrumental in sentiments classification, health education,\nand generating biomedical explanations, while also enhancing user writing accuracy and speed. Its utility spans", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 19}
{"id": "rag_paper_annotated_20", "content": "and generating biomedical explanations, while also enhancing user writing accuracy and speed. Its utility spans\nhumanitarian assistance, generating informative dialogues, crafting realistic images and intricate plotlines, and much", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 20}
{"id": "rag_paper_annotated_21", "content": "more.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 21}
{"id": "rag_paper_annotated_22", "content": "Additionally, RAG aids in natural language QA, disease identification, and information extraction. It handles\ndecision-making tasks, hashtag management, hate speech detection, and scientific document classification. RAG\nexcels in entity description generation, text correction, and SQL translation, while also enhancing open-domain QA\nand professional knowledge inquiries. Also, it extends the capabilities of machine translation tasks beyond text-toSQL, such as neural text re-ranking [6]. Moreover, it supports multicultural enterprise queries, e-commerce\nsearches, and personalized dialogue systems. Furthermore, RAG facilitates event argument extraction, intelligence\nreport generation, short-form QA, automated transactions, and private data handling. Lastly, it contributes to science\nQA, clinical writing, and pharmaceutical regulatory compliance inquiries.\nAfter compiling all the applications of RAG, the subsequent step involves categorizing them based on the", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 22}
{"id": "rag_paper_annotated_23", "content": "QA, clinical writing, and pharmaceutical regulatory compliance inquiries.\nAfter compiling all the applications of RAG, the subsequent step involves categorizing them based on the\nspecific nature of the NLP tasks they tackle (see Table 2 and Fig. 4). From the compiled publications, it was\nobserved that 20 studies were dedicated to QA, 6 to Text Generation and Summarization, 6 to Information Retrieval\nand Extraction, 5 to Text Analysis and Processing, 4 to SDM, and 5 to Decision Making and Applications, while the\nremaining 6 studies were classified under \"Other Categories.\" This classification is significant as it helps in\nunderstanding the distribution and focus of RAG applications across different NLP tasks. Additionally, since RAG\napplications span various disciplines, further classification (see Table 3 and Fig. 5) reveals that 9 publications were\nrelated to Medical/Biomedical, 2 to Financial, 2 to Educational, 9 to Technology and Software Development, 7 to", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 23}
{"id": "rag_paper_annotated_24", "content": "related to Medical/Biomedical, 2 to Financial, 2 to Educational, 9 to Technology and Software Development, 7 to\nSocial and Communication, and 3 to Literature, with the remaining falling into \"Other Categories\".", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 24}
{"id": "rag_paper_annotated_25", "content": "Table 1. Applications of RAG\n\n\n**No.** **Use case with RAG** **Used datasets / benchmarks** **Application area**\n\n\n1 MIRAGE: Medical information RAG [10] Medical QA datasets Biomedical QA\n2 RAG for improved context accuracy [11] Financial reports Financial QA\n3 Retrieval-augmented Electrocardiography (ECG) [12] Cardiac symptoms and sleep apnea diagnosis Medical QA\n4 Representative Vector Summarization (RVS) [13] PDFs, text documents, spreadsheets, etc. Medical text summarization\n5 Retrieval-augmented controllable reviews [14] Amazon book reviews Book review generation\n\n\n\n```\n### Figure - Number of Publications Over the Years\n![Publications Trend](rag_paper.pdf-3-0.png)\n\n**Caption:** The figure illustrates the trend of publications over the years from 2020 to 2024. There is a significant increase in publications in 2023, followed by a decrease in 2024.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 25}
{"id": "rag_paper_annotated_26", "content": "**Caption:** The figure illustrates the trend of publications over the years from 2020 to 2024. There is a significant increase in publications in 2023, followed by a decrease in 2024.\n\n**Description:**\n- The x-axis represents the year from 2020 to 2024.\n- The y-axis represents the number of publications.\n- In 2020, there was 1 publication.\n- From 2020 to 2022, the number of publications increased steadily to 6 in 2022.\n- In 2023, there was a peak of 28 publications.\n- In 2024, the number of publications decreased to 16.\n- The data is presented as a line graph showing the publication trend over time.\n```\n_Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790\b_ 3785", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 26}
{"id": "rag_paper_annotated_27", "content": "6 Retrieval-augmented knowledge graph reasoning [15] Commonsense QA and OpenBookQA. Commonsense QA\n7 Answers from table corpus via RAG [16] Wikipedia data Table QA\n8 LiVersa: a liver disease specific LLM using RAG [17] Liver Diseases Medical QA\n9 Almanac: RAG for clinical medicine [18] Guidelines and treatment recommendations. Clinical decision-making\n10 Assessment of tutoring practices [19] Dialogue transcripts from a middle-school. Educational decision making\n11 Handling out of domain scenarios [20] Life science, earth science, etc. lessons. Textbook QA\n12 Automated form filling [21] Request forms for IT projects Enterprise search\n13 Financial sentiment analysis [22] Twitter financial news and FiQA datasets Sentiments classification\n14 Frontline health worker capacity building [23] Pregnancy-related guidelines Health education QA\n15 Self-BioRAG: a framework for biomedical text [24] Biomedical instruction sets Biomedical Informatics", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 27}
{"id": "rag_paper_annotated_28", "content": "15 Self-BioRAG: a framework for biomedical text [24] Biomedical instruction sets Biomedical Informatics\n16 Hybrid RAG for real-time composition assistance [25] WikiText-103, Enron Emails, etc. Writing speed and accuracy\n17 RAG-Fusion to obtain product information [26] Product datasheets Technical information QA\n18 Commit message generation for code intelligence [27] MCMD dataset SDM\n19 FloodBrain: Flood disaster reporting [28] ReliefWeb reports Humanitarian assistance\n20 Rich answer encoding [29] MSMARCO QA and WoW dataset. Generative QA\n21 Text-to-image generator [30] COCO and WikiImages datasets. Realistic images generation\n22 Code completion framework [31] CodeXGLUE and CodeNet datasets. SDM\n23 Complex story generation framework [32] IMDB movie details dataset Generate stories\n24 TRAC: Trustworthy retrieval augmented chatbot [33] Natural Question dataset Natural QA\n25 Clinfo.ai using scientific literature [34] PubMed dataset Medical QA", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 28}
{"id": "rag_paper_annotated_29", "content": "24 TRAC: Trustworthy retrieval augmented chatbot [33] Natural Question dataset Natural QA\n25 Clinfo.ai using scientific literature [34] PubMed dataset Medical QA\n26 RealGen for controllable traffic scenarios [35] nuScenes dataset Critical traffic scenarios\n27 Zero-shot disease phenotyping [36] Clinical notes Identifying diseases\n28 RAP-Gen for automatic program repair [37] TFix, Defects4J, etc. datasets SDM\n29 Code4UIE : retrieval-augmented code generation [38] ACE04, ACE05, CoNLL03, etc. datasets Information extraction\n30 RAP: retrieval-augmented planning [39] ALFWorld, Webshop, etc. datasets Decision-making\n31 RIGHT for mainstream hashtag recommendation [40] Twitter and Weibo data. Retrieval-enhanced hashtags\n32 RAUCG for counter narrative generation for hate speech MultitargetCONAN dataset Combating hate speech", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 29}
{"id": "rag_paper_annotated_30", "content": "[41]\n\n\n\n33 Weakly-supervised scientific document classification\n\n[42]\n\n\n\n33 Weakly-supervised scientific document classification AGNews and MeSH datasets. Scientific documents\n\n[42] classification\n\n34 rT5 for Chinese entity description generation [43] XunZi and MengZi datasets. Entity description generation\n35 RSpell: domain adaptive Chinese spelling check [44] CSC dataset Text error correction\n36 XRICL: cross-lingual retrieval-augmented in-context XSPIDER and XKAGGLE-DBQA datasets. Text-to-SQL translation\nlearning for cross-lingual text-to-SQL semantic parsing\n\n[45]\n\n\n\nXSPIDER and XKAGGLE-DBQA datasets. Text-to-SQL translation\n\n\n\n37 SELF-RAG: learning to retrieve, generate, and\ncritique through self-reflection [46]\n\n\n\n37 SELF-RAG: learning to retrieve, generate, and Open-Instruct processed data. Open-domain QA and fact\ncritique through self-reflection [46] verification", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 30}
{"id": "rag_paper_annotated_31", "content": "37 SELF-RAG: learning to retrieve, generate, and Open-Instruct processed data. Open-domain QA and fact\ncritique through self-reflection [46] verification\n\n38 ChatDOC with enhanced PDF structure recognition [47] Academic papers, financial reports, Professional knowledge QA\ntextbooks, and legislative materials\n\n\n\nProfessional knowledge QA\n\n\n\n39 G-Retriever for textual graph understanding [48] GraphQA (ExplaGraphs, SceneGraphs and\nWebQSP)\n\n\n\nChat with graphs\n\n\nMulticultural enterprise QA\n\n\n\n40 Enhancing multilingual information retrieval in\nmixed Human Resources (HR) environments [49]\n\n\n\nHR standard operating procedures and\nQuality Assurance (QA) documents", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 31}
{"id": "rag_paper_annotated_32", "content": "40 Enhancing multilingual information retrieval in\nmixed Human Resources (HR) environments [49]\n\n\n\nHR standard operating procedures and\nQuality Assurance (QA) documents\n\n\n\n41 Differentiable RAG [50] User-clicked logs E-commerce search (query\nintent classification)\n42 RAG to elevate low-code developer skills [51] Caspio and Power automate data SDM\n43 UniMS-RAG: a unified multi-source RAG [52] DuLeMon and KBP datasets Personalized dialogue\nsystems\n44 RAG QA for event argument extraction [53] ACE 2005 and WikiEvent datasets Event argument (answer)\nextraction\n45 FABULA: retrieval-augmented narrative construction OntoNotes and Pile datasets Intelligence report\n\n[54] generation\n\n\n\n45 FABULA: retrieval-augmented narrative construction OntoNotes and Pile datasets Intelligence report\n\n[54] generation", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 32}
{"id": "rag_paper_annotated_33", "content": "[54] generation\n\n\n\n45 FABULA: retrieval-augmented narrative construction OntoNotes and Pile datasets Intelligence report\n\n[54] generation\n\n46 Time-Aware Adaptive Retrieval (TA-ARE) [55] RetrievalQA dataset Short-form open-domain\nQA\n47 Cash transaction booking via RAG [56] Cash Management Software (CMS) Automated cash transaction\ntransactions.\n\n\n\n47 Cash transaction booking via RAG [56] Cash Management Software (CMS) Automated cash transaction\ntransactions. booking\n\n48 Retrieval-Augmented Thought Process (RATP) [57] Boolq and emrQA datasets. QA with private data\n49 ATLANTIC for interdisciplinary science [58] S2ORC dataset Science QA and scientific\ndocument classification\n50 Writing documents for clinical trials [59] FDA guidance database, ClinicalTrials.gov, Clinical-related writing\nand AACT database.\n\n51 QA RAG model [60] FDA Q&A datasets Pharma industry regulatory\ncompliance QA\n\n\n\nClinical-related writing", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 33}
{"id": "rag_paper_annotated_34", "content": "51 QA RAG model [60] FDA Q&A datasets Pharma industry regulatory\ncompliance QA\n\n\n\nClinical-related writing\n\n\n3786 _Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790_\n\n\n**4.** **Discussion**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 34}
{"id": "rag_paper_annotated_35", "content": "The classification of RAG applications according to the specific NLP tasks they target holds significant\nimportance for several reasons. Firstly, it offers valuable insights into the distribution and focus of RAG applications\nacross various tasks within the field of NLP. By quantifying the number of studies dedicated to each task,\nresearchers gain a deeper understanding of where efforts and resources are predominantly concentrated within the\nRAG domain. By analyzing the distribution of RAG applications, researchers can discern prevailing trends in\nresearch interest and identify emerging areas of importance. The classification of RAG applications based on\ndiscipline offers valuable insights into its widespread adoption across various domains. This classification not only\nprovides a comprehensive understanding of RAG\u2019s applicability but also underscores its potential to revolutionize\nvarious domains, thereby contributing significantly to the advancement of NLP technologies.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 35}
{"id": "rag_paper_annotated_36", "content": "various domains, thereby contributing significantly to the advancement of NLP technologies.\nWhile this survey offers a comprehensive overview of RAG applications across various NLP tasks and\ndisciplines, it also has its limitations. 1) Given that RAG technology is still emerging, the majority of RAG-based\nstudies are available in pre-print formats on platforms like arXiv, lacking peer review. This raises questions about\ntheir authenticity. 2) Additionally, the survey overlooks the technical implementation details and challenges\nassociated with using RAG technology alongside open-source LLMs. Organizations may find RAG implementation\ncostly if they do not opt for open-source LLM architectures, especially considering the expense of querying the\nLLM via Application Programming Interface (API). 3) Furthermore, the performance of RAG concerning the\nvolume and variety of datasets has not been discussed. Deploying RAG with large datasets of varying structures", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 36}
{"id": "rag_paper_annotated_37", "content": "volume and variety of datasets has not been discussed. Deploying RAG with large datasets of varying structures\n(e.g., structured, semi-structured, or non-structured) may lead to processing delays, warranting further exploration\nbefore selecting a RAG with LLM integrated solution for organizational deployment.\n4) Additionally, this survey did not cover the diverse range of RAG architectures and technologies available for\nintegration with different LLMs. Future work should delve into these options to discuss how various RAG solutions\ncan be adapted with LLMs for different NLP tasks and applications. 5) Furthermore, the survey did not address the\naccuracy of information obtained from RAG with LLM solutions. It is essential to explore the reliability of these\nsystems and assess the organizations\u2019 dependency on their generated responses. LLMs often generate responses with\nhigh confidence, making it challenging to evaluate the accuracy of the information provided. 6) While the survey", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 37}
{"id": "rag_paper_annotated_38", "content": "high confidence, making it challenging to evaluate the accuracy of the information provided. 6) While the survey\nprimarily focuses on task-based and discipline-based applications of RAG, there is a need for further research to\nexplore ethical considerations associated with its usage, especially when dealing with sensitive datasets. For\nexample, in the biomedical domain, RAG has the potential to accidentally expose private information to analysts,\nraising concerns about data privacy and security. Additionally, in the legal domain, RAG may mistakeably reveal\nprivileged information during document analysis, potentially violating client confidentiality and attorney-client\nprivilege. Therefore, future studies should delve deeper into these ethical implications to ensure responsible and\nethical use of RAG technology across various domains.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 38}
{"id": "rag_paper_annotated_39", "content": "**5.** **Conclusion**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 39}
{"id": "rag_paper_annotated_40", "content": "This article offers a thorough examination of the applications of RAG with LLMs, showcasing their potential to\ndrive digital transformation across diverse industries. Initially, it gathers the latest publications on RAG from online\nrepositories. These publications are then classified based on task-oriented and discipline-oriented criteria. A notable\ntrend observed is the increasing number of research papers on RAG deposited in open-access sources, particularly\nsince 2023. However, many works remain unpublished or are in the preprint stage, awaiting review by various\njournals. A significant portion of these studies primarily focus on the task of QA in NLP. Conversely, there is a\nnoticeable gap in research exploring Entity Linking, an essential NLP task that contributes to knowledge graph\ndevelopment. Addressing this gap could unlock numerous applications in the realm of linked data. Regarding", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 40}
{"id": "rag_paper_annotated_41", "content": "development. Addressing this gap could unlock numerous applications in the realm of linked data. Regarding\ndisciplines, the majority of research applications are concentrated in the fields of Medical/Biomedical and\nTechnology and Software Development. In contrast, disciplines such as Business and Agriculture receive\ncomparatively less attention. Future research endeavors should aim to bridge this gap by addressing the specific\nneeds of these underrepresented disciplines.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 41}
{"id": "rag_paper_annotated_42", "content": "_Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790\b_ 3787\n\n\nTable 2. Task-based classification of RAG applications. The detailed categories are derived from the \"Application area\"\ncolumn of Table 1. These categories are assigned based on a thorough comprehension of the study\u2019s context.\n\n\n\n**1) Question Answering (QA)**\n\n\n - Biomedical QA [1]\n\n\n - Financial QA [2]\n\n\n - Medical QA [3]\n\n\n - Commonsense QA [6]\n\n\n - Textbook QA [11]\n\n\n - Health education QA [14]\n\n\n - Technical product information QA [17]\n\n\n - Natural QA [24]\n\n\n - Professional knowledge QA [38]\n\n\n\n\n- Multicultural enterprise QA [40]\n\n\n- Open-domain QA and fact verification [46]\n\n\n- Short-form open-domain QA [46]\n\n\n- Generative QA and informative conversations [29]\n\n\n- Pharma industry regulatory compliance QA [51]\n\n\n- Science QA and document classification [49]\n\n\n- Clinical-related writing [50]\n\n\n- Personalized dialogue systems [43]\n\n\n\n**4) Text Analysis and Processing**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 42}
{"id": "rag_paper_annotated_43", "content": "- Science QA and document classification [49]\n\n\n- Clinical-related writing [50]\n\n\n- Personalized dialogue systems [43]\n\n\n\n**4) Text Analysis and Processing**\n\n\n- Sentiments classification [13]\n\n\n- Text error correction [35]\n\n\n- Text-to-SQL translation [36]\n\n\n- Scientific documents classification [33]\n\n\n- Combating online hate speech [32]\n\n\n**5) Software Development and**\n**Maintenance**\n\n\n- Code intelligence [18]\n\n\n- Code completion [22]\n\n\n- Automatic program repair [28]\n\n\n- Elevate low-code developer skills [42]\n\n**6) Decision Making and Applications**\n\n\n- Clinical decision-making [9]\n\n\n- Educational decision making [10]\n\n\n- Decision-making applications [30]\n\n\n- Automated cash transaction booking [47]\n\n\n- Intelligence report generation [45]\n\n\n**7) Other Categories:**\n\n\n- Editing and crafting diverse behaviors,\nincluding critical traffic scenarios [26]\n\n\n- Identifying diseases [27]\n\n\n- Chat with graphs [39]\n\n\n\n**2) Text Generation and Summarization**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 43}
{"id": "rag_paper_annotated_44", "content": "- Editing and crafting diverse behaviors,\nincluding critical traffic scenarios [26]\n\n\n- Identifying diseases [27]\n\n\n- Chat with graphs [39]\n\n\n\n**2) Text Generation and Summarization**\n\n\n- Medical text summarization [4]\n\n\n- Book review generation [5]\n\n\n- Biomedical Informatics [15]\n\n\n- Generate stories with complex plots [23]\n\n\n- Generate realistic and faithful images [21]\n\n\n- Entity description generation [34]\n\n**3) Information Retrieval and Extraction**\n\n\n- Table QA [7]\n\n\n- Enterprise search [12]\n\n\n- Retrieval-enhanced hashtags [31]\n\n\n- Information extraction [29]\n\n\n- Event argument (answer) extraction [44]\n\n\n- E-commerce search (query intent classification) [41]\n\n\n\n**Task: (Count of Publications)**\n\n\nQuestion Answering (QA): (20)\n\n\nText Generation and Summarization: (6)\n\n\nInformation Retrieval and Extraction: (6)\n\n\nText Analysis and Processing: (5)\n\n\nSoftware Development and Maintenance: (4)\n\n\nDecision Making and Applications: (5)\n\n\nOther Categories: (6)", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 44}
{"id": "rag_paper_annotated_45", "content": "Information Retrieval and Extraction: (6)\n\n\nText Analysis and Processing: (5)\n\n\nSoftware Development and Maintenance: (4)\n\n\nDecision Making and Applications: (5)\n\n\nOther Categories: (6)\n\n\nFig. 4. Task-based classification of RAG applications with count of publications. The word cloud is generated based on the publication counts\nlisted under various headings in Table 2.\n\n\n\n```\n### Figure - Categories of Natural Language Processing\n![NLP Categories](E:\\Python Stuff\\MAS-for-multimodal-knowledge-graph\\markdown_outputs\\images\\rag_paper.pdf-6-0.png)\n\n**Caption:** The figure outlines various categories within Natural Language Processing, highlighting key areas of research and application. Question Answering is presented as a distinct and important category. Other categories include text analysis and generation.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 45}
{"id": "rag_paper_annotated_46", "content": "**Description:**\n- The figure displays a hierarchical structure of NLP categories.\n- \"Text Analysis and Processing\" and \"Other Categories\" are listed at the top level.\n- \"Information Retrieval and Extraction\" is a primary category, with \"Question Answering (QA)\" as a subcategory.\n- \"Software Development and Maintenance,\" \"Text Generation and Summarization,\" and \"Decision Making and Applications\" are listed as further subcategories.\n```\n3788 _Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790_\n\n\nTable 3. Discipline-based classification of RAG applications. The detailed categories are derived from the \"Application area\"\ncolumn of Table 1. These categories are assigned based on a thorough comprehension of the study\u2019s context.\n\n\n\n**1) Medical / Biomedical**\n\n\n- Biomedical QA [1]\n\n\n- Medical QA [3]\n\n\n- Medical text summarization [4]\n\n\n- Health education QA [14]\n\n\n- Identifying diseases [27]\n\n\n- Clinical decision-making [9]\n\n\n- Clinical-related writing [50]", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 46}
{"id": "rag_paper_annotated_47", "content": "- Medical QA [3]\n\n\n- Medical text summarization [4]\n\n\n- Health education QA [14]\n\n\n- Identifying diseases [27]\n\n\n- Clinical decision-making [9]\n\n\n- Clinical-related writing [50]\n\n\n- Science QA and scientific document classification [49]\n\n\n- Pharma industry regulatory compliance QA [51]\n\n**2) Financial**\n\n\n- Financial QA [2]\n\n\n- Automated cash transaction booking [47]\n\n**3) Educational**\n\n\n- Educational decision making [10]\n\n\n- Textbook QA [11]\n\n**4) Technology and Software Development**\n\n\n- Table QA [7]\n\n\n- Technical product information QA [17]\n\n\n- Software development and maintenance [18, 22, 28, 42]\n\n\n- Generative QA and informative conversations [20]\n\n\n- Information extraction [29]\n\n\n- Text error correction [35]\n\n\n- Text-to-SQL translation [36]\n\n\n- Personalized dialogue systems [43]\n\n\n- Event argument (answer) extraction [44]\n\n\n\n**5) Social and Communication**\n\n\n- Commonsense QA [6]\n\n\n- Sentiments classification [13]\n\n\n- Combating online hate speech [32]", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 47}
{"id": "rag_paper_annotated_48", "content": "- Event argument (answer) extraction [44]\n\n\n\n**5) Social and Communication**\n\n\n- Commonsense QA [6]\n\n\n- Sentiments classification [13]\n\n\n- Combating online hate speech [32]\n\n\n- Retrieval-enhanced hashtags [31]\n\n\n- Humanitarian assistance [19]\n\n\n- Chat with graphs [39]\n\n\n- Multicultural enterprise QA [40]\n\n**6) Literature**\n\n\n- Book review generation guided by reference documents [5]\n\n\n- Enhance user writing speed and accuracy [16]\n\n\n- Generate stories with complex plots [23]\n\n**7) Other Categories**\n\n\n- Enterprise search [12]\n\n\n- Generate realistic and faithful images [21]\n\n\n- Decision-making applications [30]\n\n\n- Open-domain question answering and fact verification [37]\n\n\n- Professional knowledge QA [38]\n\n\n- Intelligence report generation [45]\n\n\n- Short-form open-domain QA [46]\n\n\n- Question answering with private data [48]\n\n\n**Discipline: (Count of Publications)**\n\n\nMedical / Biomedical: (9)\n\n\nFinancial: (2)\n\n\nEducational: (2)\n\n\nTechnology and Software Development: (9)", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 48}
{"id": "rag_paper_annotated_49", "content": "- Question answering with private data [48]\n\n\n**Discipline: (Count of Publications)**\n\n\nMedical / Biomedical: (9)\n\n\nFinancial: (2)\n\n\nEducational: (2)\n\n\nTechnology and Software Development: (9)\n\n\nSocial and Communication: (7)\n\n\nLiterature (3)\n\n\nOther Categories: (8)\n\n\n\n```\n### Figure - Categories of Research Topics\n![Research Topic Categories](E:\\Python Stuff\\MAS-for-multimodal-knowledge-graph\\markdown_outputs\\images\\rag_paper.pdf-7-0.png)\n\n**Caption:** The figure displays a word cloud representing various research categories. Each color corresponds to a distinct category of research topics.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 49}
{"id": "rag_paper_annotated_50", "content": "**Caption:** The figure displays a word cloud representing various research categories. Each color corresponds to a distinct category of research topics.\n\n**Description:**\n- The word cloud visually represents different research categories.\n- \u201cTechnology and Software Development\u201d is the largest word, indicating its prominence.\n- \u201cMedical/Biomedical\u201d and \u201cSocial and Communication\u201d are also prominent categories, represented by distinct colors.\n- \u201cFinancial\u201d, \u201cEducational\u201d, \u201cLiterature\u201d, and \u201cOther Categories\u201d are smaller words indicating less frequent categories.\n\nFig. 5. Discipline-based classification of RAG applications with count of publications. The word cloud is generated based on the publication\ncounts listed under various headings in Table 3.\n**Acknowledgements**\nThe authors thank the French Government and the National Research Agency (ANR) for their funding.\n\n\n**References**", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 50}
{"id": "rag_paper_annotated_51", "content": "**References**\n\n\n[1] Roumeliotis KI, Tselikas ND, & Nasiopoulos DK. (2024). \u201cLLMs in e-commerce: a comparative analysis of GPT and LLaMA models in\nproduct review evaluation,\u201d _Natural Language Processing Journal_ : **1-6** :100056.\n\n[2] Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). \u201cLanguage Models are Few-Shot\nLearners,\u201d _Advances in Neural Information Processing Systems_ **33** (NeurIPS 2020).\n\n\n[3] OpenAI, R. (2023). \u201cGpt-4 technical report,\u201d arxiv 2303.08774. View in Article: **2** ( **5** ).\n\n\n_Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790\b_ 3789\n\n\n[4] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., ... & Wang, H. (2023). \u201cRetrieval-augmented generation for large language models: A\nsurvey,\u201d arXiv preprint arXiv:2312.10997.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 51}
{"id": "rag_paper_annotated_52", "content": "[4] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., ... & Wang, H. (2023). \u201cRetrieval-augmented generation for large language models: A\nsurvey,\u201d arXiv preprint arXiv:2312.10997.\n\n\n[5] Kandpal, N., Deng, H., Roberts, A., Wallace, E., & Raffel, C. (2023). \u201cLarge language models struggle to learn long-tail knowledge,\u201d In\nInternational Conference on Machine Learning. PMLR: 5696-15707.\n\n\n[6] Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020). \u201cRetrieval-augmented generation for knowledgeintensive nlp tasks,\u201d _Advances in Neural Information Processing Systems_ **33** : 9459-9474.\n\n\n[7] Li, H., Su, Y., Cai, D., Wang, Y., & Liu, L. (2022). \u201cA survey on retrieval-augmented text generation,\u201d arXiv preprint arXiv:2202.01110.\n\n\n[8] Mialon, G., Dess\u00ec, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., ... & Scialom, T. (2023). \u201cAugmented language models: a\nsurvey,\u201d arXiv preprint arXiv:2302.07842.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 52}
{"id": "rag_paper_annotated_53", "content": "[8] Mialon, G., Dess\u00ec, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., ... & Scialom, T. (2023). \u201cAugmented language models: a\nsurvey,\u201d arXiv preprint arXiv:2302.07842.\n\n\n[9] Zhao, R., Chen, H., Wang, W., Jiao, F., Do, X. L., Qin, C., ... & Joty, S. (2023). \u201cRetrieving multimodal information for augmented\ngeneration: A survey,\u201d arXiv preprint arXiv:2303.10868.\n\n\n[10] Xiong, G., Jin, Q., Lu, Z., & Zhang, A. (2024). \u201cBenchmarking retrieval-augmented generation for medicine,\u201d arXiv preprint\narXiv:2402.13178.\n\n\n[11] Jimeno Yepes, A., You, Y., Milczek, J., Laverde, S., & Li, L. (2024). \u201cFinancial Report Chunking for Effective Retrieval Augmented\nGeneration,\u201d arXiv e-prints, arXiv-2402.\n\n\n[12] Yu, H., Guo, P., & Sano, A. (2023). \u201cZero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation,\u201d\nIn _Machine Learning for Health (ML4H)_ PMLR: 650-663.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 53}
{"id": "rag_paper_annotated_54", "content": "[12] Yu, H., Guo, P., & Sano, A. (2023). \u201cZero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation,\u201d\nIn _Machine Learning for Health (ML4H)_ PMLR: 650-663.\n\n\n[13] Manathunga, S. S., & Illangasekara, Y. A. (2023). \u201cRetrieval Augmented Generation and Representative Vector Summarization for large\nunstructured textual data in Medical Education,\u201d arXiv preprint arXiv:2308.00479.\n\n\n[14] Kim, J., Choi, S., Amplayo, R. K., & Hwang, S. W. (2020). \u201cRetrieval-augmented controllable review generation,\u201d In Proceedings of the\n28th International Conference on Computational Linguistics: 2284-2295.\n\n\n[15] Sha, Y., Feng, Y., He, M., Liu, S., & Ji, Y. (2023). \u201cRetrieval-augmented Knowledge Graph Reasoning for Commonsense Question\nAnswering,\u201d _Mathematics_ 11(15): 3269; https://doi.org/10.3390/math11153269.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 54}
{"id": "rag_paper_annotated_55", "content": "[16] Pan, F., Canim, M., Glass, M., Gliozzo, A., & Hendler, J. (2022). \u201cEnd-to-End Table Question Answering via Retrieval-Augmented\nGeneration,\u201d arXiv preprint arXiv:2203.16714.\n\n\n[17] Ge, J., Sun, S., Owens, J., Galvez, V., Gologorskaya, O., Lai, J. C., ... & Lai, K. (2023). \u201cDevelopment of a Liver Disease-Specific Large\nLanguage Model Chat Interface using Retrieval Augmented Generation,\u201d medRxiv.\n\n\n[18] Zakka, C., Shad, R., Chaurasia, A., Dalal, A. R., Kim, J. L., Moor, M., ... & Hiesinger, W. (2024). \u201cAlmanac\u2014retrieval-augmented language\nmodels for clinical medicine,\u201d _NEJM AI_ **1** ( **2** ), AIoa2300068.\n\n\n[19] Han, Z. FeiFei, Lin, J., Gurung, A., Thomas, D. R., Chen, E., Borchers, C., Gupta, S., & Koedinger, K. R. (2024). \u201cImproving Assessment of\nTutoring Practices using Retrieval-Augmented Generation,\u201d arXiv preprint arXiv:2402.14594.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 55}
{"id": "rag_paper_annotated_56", "content": "[20] Alawwad, H. A., Alhothali, A., Naseem, U., Alkhathlan, A., & Jamal, A. (2024). \u201cEnhancing Textbook Question Answering Task with\nLarge Language Models and Retrieval Augmented Generation,\u201d arXiv preprint arXiv:2402.05128.\n\n\n[21] Bucur, M. (2023). \u201cExploring Large Language Models and Retrieval Augmented Generation for Automated Form Filling,\u201d (Bachelor's\nthesis, University of Twente).\n\n\n[22] Zhang, B., Yang, H., Zhou, T., Ali Babar, M., & Liu, X. Y. (2023). \u201cEnhancing financial sentiment analysis via retrieval augmented large\nlanguage models,\u201d In Proceedings of the Fourth ACM International Conference on AI in Finance: 349-356.\n\n\n[23] Al Ghadban, Y., Lu, H. Y., Adavi, U., Sharma, A., Gara, S., Das, N., ... & Hirst, J. E. (2023). \u201cTransforming healthcare education:\nHarnessing large language models for frontline health worker capacity building using retrieval-augmented generation,\u201d medRxiv, 2023-12.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 56}
{"id": "rag_paper_annotated_57", "content": "[24] Jeong, M., Sohn, J., Sung, M., & Kang, J. (2024). \u201cImproving Medical Reasoning through Retrieval and Self-Reflection with RetrievalAugmented Large Language Models,\u201d arXiv preprint arXiv:2401.15269.\n\n\n[25] Xia, M., Zhang, X., Couturier, C., Zheng, G., Rajmohan, S., & Ruhle, V. (2023). \u201cHybrid retrieval-augmented generation for real-time\ncomposition assistance,\u201d arXiv preprint arXiv:2308.04215.\n\n\n[26] Rackauckas, Z. (2024). \u201cRAG-Fusion: A New Take on Retrieval-Augmented Generation,\u201d arXiv preprint arXiv:2402.03367.\n\n\n[27] Shi, E., Wang, Y., Tao, W., Du, L., Zhang, H., Han, S., ... & Sun, H. (2022). \u201cRACE: Retrieval-Augmented Commit Message\nGeneration,\u201d arXiv preprint arXiv:2203.02700.\n\n\n[28] Colverd, G., Darm, P., Silverberg, L., & Kasmanoff, N. (2023). \u201cFloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented\nGeneration with an LLM,\u201d arXiv preprint arXiv:2311.02597.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 57}
{"id": "rag_paper_annotated_58", "content": "[28] Colverd, G., Darm, P., Silverberg, L., & Kasmanoff, N. (2023). \u201cFloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented\nGeneration with an LLM,\u201d arXiv preprint arXiv:2311.02597.\n\n\n[29] Huang, W., Lapata, M., Vougiouklis, P., Papasarantopoulos, N., & Pan, J. (2023). \u201cRetrieval Augmented Generation with Rich Answer\nEncoding,\u201d In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the AsiaPacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers): 1012-1025.\n\n\n[30] Chen, W., Hu, H., Saharia, C., & Cohen, W. W. (2022). \u201cRe-imagen: Retrieval-augmented text-to-image generator,\u201d arXiv preprint\narXiv:2209.14491.\n\n\n[31] Lu, S., Duan, N., Han, H., Guo, D., Hwang, S. W., & Svyatkovskiy, A. (2022). \u201cReacc: A retrieval-augmented code completion\nframework,\u201d arXiv preprint arXiv:2203.07722.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 58}
{"id": "rag_paper_annotated_59", "content": "[31] Lu, S., Duan, N., Han, H., Guo, D., Hwang, S. W., & Svyatkovskiy, A. (2022). \u201cReacc: A retrieval-augmented code completion\nframework,\u201d arXiv preprint arXiv:2203.07722.\n\n\n[32] Wen, Z., Tian, Z., Wu, W., Yang, Y., Shi, Y., Huang, Z., & Li, D. (2023). \u201cGrove: a retrieval-augmented complex story generation\nframework with a forest of evidence,\u201d arXiv preprint arXiv:2310.05388.\n\n\n3790 _Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781\u20133790_\n\n\n[33] Li, S., Park, S., Lee, I., & Bastani, O. (2023). \u201cTRAC: Trustworthy Retrieval Augmented Chatbot,\u201d arXiv preprint arXiv:2307.04642.\n\n\n[34] Lozano, A., Fleming, S. L., Chiang, C. C., & Shah, N. (2023). \u201cClinfo. ai: An open-source retrieval-augmented large language model system\nfor answering medical questions using scientific literature,\u201d In Pacific symposium on Biocomputing 2024: 8-23.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 59}
{"id": "rag_paper_annotated_60", "content": "[35] Ding, W., Cao, Y., Zhao, D., Xiao, C., & Pavone, M. (2023). \u201cRealGen: Retrieval Augmented Generation for Controllable Traffic\nScenarios,\u201d arXiv preprint arXiv:2312.13303.\n\n\n[36] Thompson, W. E., Vidmar, D. M., De Freitas, J. K., Pfeifer, J. M., Fornwalt, B. K., Chen, R., ... & Miotto, R. (2023). \u201cLarge Language\nModels with Retrieval-Augmented Generation for Zero-Shot Disease Phenotyping,\u201d arXiv preprint arXiv:2312.06457.\n\n\n[37] Wang, W., Wang, Y., Joty, S., & Hoi, S. C. (2023). \u201cRap-gen: Retrieval-augmented patch generation with codet5 for automatic program\nrepair,\u201d In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software\nEngineering: 146-158.\n\n\n[38] Guo, Y., Li, Z., Jin, X., Liu, Y., Zeng, Y., Liu, W., ... & Cheng, X. (2023). \u201cRetrieval-augmented code generation for universal information\nextraction,\u201d arXiv preprint arXiv:2311.02962.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 60}
{"id": "rag_paper_annotated_61", "content": "[38] Guo, Y., Li, Z., Jin, X., Liu, Y., Zeng, Y., Liu, W., ... & Cheng, X. (2023). \u201cRetrieval-augmented code generation for universal information\nextraction,\u201d arXiv preprint arXiv:2311.02962.\n\n\n[39] Kagaya, T., Yuan, T. J., Lou, Y., Karlekar, J., Pranata, S., Kinose, A., ... & You, Y. (2024). \u201cRAP: Retrieval-Augmented Planning with\nContextual Memory for Multimodal LLM Agents,\u201d arXiv preprint arXiv:2402.03610.\n\n\n[40] Fan, R. Z., Fan, Y., Chen, J., Guo, J., Zhang, R., & Cheng, X. (2023). \u201cRIGHT: Retrieval-augmented Generation for Mainstream Hashtag\nRecommendation,\u201d arXiv preprint arXiv:2312.10466.\n\n\n[41] Jiang, S., Tang, W., Chen, X., Tanga, R., Wang, H., & Wang, W. (2023). Raucg: Retrieval-augmented unsupervised counter narrative\ngeneration for hate speech. arXiv preprint arXiv:2310.05650.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 61}
{"id": "rag_paper_annotated_62", "content": "[41] Jiang, S., Tang, W., Chen, X., Tanga, R., Wang, H., & Wang, W. (2023). Raucg: Retrieval-augmented unsupervised counter narrative\ngeneration for hate speech. arXiv preprint arXiv:2310.05650.\n\n\n[42] Xu, R., Yu, Y., Ho, J., & Yang, C. (2023). \u201cWeakly-supervised scientific document classification via retrieval-augmented multi-stage\ntraining,\u201d In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval: 25012505.\n\n\n[43] Hu, M., Zhao, X., Wei, J., Wu, J., Sun, X., Li, Z., ... & Zhang, Y. (2023). \u201crT5: A Retrieval-Augmented Pre-trained Model for Ancient\nChinese Entity Description Generation,\u201d In International Conference on NLP and Chinese Computing. Cham: Springer: 736-748.\n\n\n[44] Song, S., Lv, Q., Geng, L., Cao, Z., & Fu, G. (2023). \u201cRSpell: Retrieval-augmented Framework for Domain Adaptive Chinese Spelling\nCheck,\u201d In CCF International Conference on Natural Language Processing and Chinese Computing. Cham: Springer: 551-562.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 62}
{"id": "rag_paper_annotated_63", "content": "[45] Shi, P., Zhang, R., Bai, H., & Lin, J. (2022). \u201cXricl: Cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql\nsemantic parsing,\u201d arXiv preprint arXiv:2210.13693.\n\n\n[46] Asai, A., Wu, Z., Wang, Y., Sil, A., & Hajishirzi, H. (2023). \u201cSelf-rag: Learning to retrieve, generate, and critique through selfreflection,\u201d arXiv preprint arXiv:2310.11511.\n\n\n[47] Lin, D. (2024). \u201cRevolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition,\u201d arXiv preprint\narXiv:2401.12599.\n\n\n[48] He, X., Tian, Y., Sun, Y., Chawla, N. V., Laurent, T., LeCun, Y., ... & Hooi, B. (2024). \u201cG-Retriever: Retrieval-Augmented Generation for\nTextual Graph Understanding and Question Answering,\u201d arXiv preprint arXiv:2402.07630.\n\n\n[49] Ahmad, S. R. (2024). \u201cEnhancing Multilingual Information Retrieval in Mixed Human Resources Environments: A RAG Model\nImplementation for Multicultural Enterprise,\u201d arXiv preprint arXiv:2401.01511.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 63}
{"id": "rag_paper_annotated_64", "content": "[50] Zhao, C., Jiang, Y., Qiu, Y., Zhang, H., & Yang, W. Y. (2023). \u201cDifferentiable Retrieval Augmentation via Generative Language Modeling\nfor E-commerce Query Intent Classification,\u201d In Proceedings of the 32nd ACM International Conference on Information and Knowledge\nManagement: 4445-4449.\n\n\n[51] Nakhod, o. Using retrieval-augmented generation to elevate low-code developer skills. https://doi.org/10.15407/jai2023.03.126\n\n\n[52] Wang, H., Huang, W., Deng, Y., Wang, R., Wang, Z., Wang, Y., ... & Wong, K. F. (2024). \u201cUniMS-RAG: A Unified Multi-source\nRetrieval-Augmented Generation for Personalized Dialogue Systems,\u201d arXiv preprint arXiv:2401.13256.\n\n\n[53] Du, X., & Ji, H. (2022). \u201cRetrieval-augmented generative question answering for event argument extraction,\u201d arXiv preprint\narXiv:2211.07067.\n\n\n[54] Ranade, P., & Joshi, A. (2023). \u201cFABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction,\u201d arXiv\npreprint arXiv:2310.13848.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 64}
{"id": "rag_paper_annotated_65", "content": "[54] Ranade, P., & Joshi, A. (2023). \u201cFABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction,\u201d arXiv\npreprint arXiv:2310.13848.\n\n\n[55] Zhang, Z., Fang, M., & Chen, L. (2024). \u201cRetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain\nQuestion Answering,\u201d arXiv preprint arXiv:2402.16457.\n\n\n[56] Zhang, S., Yadav, D., & Jin, T. (2023). \u201cCash transaction booking via retrieval augmented LLM. KDD 2023 Workshop on Robust NLP for\nFinance (RobustFin),\u201d https://www.amazon.science/publications/cash-transaction-booking-via-retrieval-augmented-llm\n\n\n[57] Pouplin, T., Sun, H., Holt, S., & Van der Schaar, M. (2024). \u201cRetrieval-Augmented Thought Process as Sequential Decision Making,\u201d arXiv\npreprint arXiv:2402.07812.\n\n\n[58] Munikoti, S., Acharya, A., Wagle, S., & Horawalavithana, S. (2023). \u201cATLANTIC: Structure-Aware Retrieval-Augmented Language Model\nfor Interdisciplinary Science,\u201d arXiv preprint arXiv:2311.12289.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 65}
{"id": "rag_paper_annotated_66", "content": "[59] Markey, N., El-Mansouri, I., Rensonnet, G., van Langen, C., & Meier, C. (2024). \u201cFrom RAGs to riches: Using large language models to\nwrite documents for clinical trials,\u201d arXiv preprint arXiv:2402.16406.\n\n\n[60] Kim, J., & Min, M. (2024). \u201cFrom RAG to QA-RAG: Integrating Generative AI for Pharmaceutical Regulatory Compliance Process,\u201d arXiv\npreprint arXiv:2402.01717.", "metadata": {"source": "rag_paper_annotated.md"}, "chunk_index": 66}
